# 1 클라우드 네이티브

- 일반적으로 클라우드 네이티브란 클라우드 컴퓨팅을 활용하여 "퍼블릭, 프라이빗 및 하이브리드 클라우드와 같은 현대적이고 동적인 환경에서 확장 가능한 애플리케이션 을 구축하고 실행" 하는 소프트웨어 개발 방식을 의미한다.
- 2015년에 창설된 리눅스 재단 산하의 오픈소스 운영 기구로, 클라우드 네이티브 애플리케이션을 위한 다양한 오픈소스 프로젝트들을 주도하여 진행하는 CNCF(Cloud Native Computing Foundation)에서는 클라우드 네이티브를, 컨테이너화 가능한 오픈소스 소프트웨어 스택을 사용하는 것을 의미한다고 정리하고 있다.
- 이러한 클라우드 네이티브를 기반으로 개발된 애플리케이션들은 선언적 코드를 통해 배포되는 컨테이너(Container), 마이크로서비스(Microservice), 서버리스(Serverless) 기능 및 불변의 인프라(Immutable Infrastructure)와 같은 공통 기술 요소들을 포함 하고 있다.
- 클라우드 네이티브 애플리케이션은 상호운용성과 이식성을 향상 시킬 수 있는 여러 가지 특징을 지니고 있다.

  

## 1.1 클라우드 네이티브 기술 특징

### 1.1.1  Container

- 클라우드 네이티브 애플리케이션을 위하 여 필수적으로 가장 먼저 도입 해야하는 기술은 컨테이너 기술이라고 할 수 있 다. 
- CNCF 에서도 Cloud Native Trail Map* 을 통해 가장 첫 번째로 Containerization 을 언급할 만큼 그 중요성을 강조 하고 있다.
- 컨테이너는 기존 클라우드 환경에서 많이 활용되는 가상 머신(Virtual Machine)처럼 애플리케이션과 관련된 라이브러리나 종속되는 항목들을 패키지로 묶어 서비스 구동을 위한 격리된 환경을 제공한다는 점에서 유사한 점이 있다. 
- 가상머신은 하드웨어 자원을 하이퍼바이져라는 미들웨어를 통해 가상화시켜 가상화된 컴퓨팅 자원을 제공하는 반면, 컨테이너는 운영체제 수준에서 가상화를 수행하여 다수의 컨테이너를 운영체제 커널에서 직접 구동한다. 
- 컨테이너는 운영체제 커널을 공유하여 훨씬 가볍고 구동이 빠르며, 운영체제 전체 부팅보다 메모리를 훨씬 적게 차지하게 된다.
- 컨테이너 기술은 운영체제와 독립적으로 분리되어 애플리케이션을 실행할 수 있도록 지원하므로, 동일한 컨테이너 런타임만 사용한다면 어떤 클라우드 환경에서든 컨테이너를 자유롭게 이식하여 실행시킬 수 있다.

![img](.\assets\clip_image076.gif)

 

[그림 2-2] 가상머신 VS 컨테이너



### 1.1.2  Docker Container

- 가상머신 체계에서 가상화를 위해 하이퍼바이져가 하는 역할을 컨테이너 체계에서는 컨테이너 런타임이 한다고 볼 수 있다. 
- 컨테이너 생성 및 실행을 위한 다양한 컨테이너 런타임이 존재하며 그 중에서도 Docker는 최근까지도 많이 활용되고 있는 오픈소스 기술이다.
- Docker는 컨테이너 정보를 Dockerfile로 관리하고 이 코드를 기반으로 컨테이너 이미지의 복제 및 애플리케이션 배포가 이루어지기 때문에 애플리케이션을 쉽게 다시 빌드하고 배포할 수 있다. 
  -  Docker는 이미지 버전 관리, 레이어 구조를 갖는 이미지 포맷 제공, 도커 이미지 레지스트리, 프로그램이 가능한 다양한 기능의 API를 제공하는 등의 특징을 가지고 있다.
- 동일한 컨테이너 런타임 환경에서는 컨테이너의 이식이 자유롭게 가능하므로 Docker와 같은 활용도가 높은 컨테이너 런타임을 적용하면 이식성을 향상 시킬 수 있다.



## 1.2  MSA(MicroService Architecture)

### 1.2.1  개요

- 대부분의 기업용 애플리케이션은 하나의 통합된 서비스 형태로 개발되어 왔다. 모놀리식(Monolithic) 아키텍쳐라고 불리는 이러한 단순한 애플리케이션의 구조 는 개발과 관리가 용이하다는 장점이 있다.
- 애플리케이션의 종류가 다양해지고 여러 가지 기능을 제공하는 대규모 시스템이 생겨나면서 규모가 커질 경우 복잡도가 증가해 코드의 분석과 통합이 어려워지고 작은 수정사항에도 전체를 빌드 배포해야하는 비효율이 발생하는 등의 개선과 확장이 어렵다는 단점이 발생하게 되었다.
- 확장성에 초점을 맞추어 탄생한 아키텍쳐링 방법이 MSA(MicroService Architecture)이다. 
  - MSA는 이렇게 대용량 웹서비스가 많아짐에 따라 탄생한 아키텍쳐 인데 그 근간은 SOA(Service Oriented Architecture)에 두고 있다. SOA가 엔터 프라이즈 시스템을 중심으로 고안된 아키텍쳐라면, MSA는 SOA 사상에 근간을 두고, 대용량 웹서비스 개발에 맞는 구조로 사상이 경량화되고 대규모 개발팀의 조직 구조에 맞도록 변형된 아키텍쳐이다.
- MSA는 경량화되고 독립적인 여러 개의 서비스를 조합하여 애플리케이션을 구현하는 방식으로 서비스마다 자체 데이터베이스를 가지고 동작할 수 있기 때문에 개발부터 빌드 배포까지 효율적으로 수행할 수 있으며 독립적인 서비스의 형태로 존재하기 때문에 이식성 측면에서 높은 효과를 보인다.
- 각각의 서비스들은 독립적인 서비스로 볼 수 있으며 서로 호환성이 높도록 구현되어 있기 때문에 각각의 서비스 구현 과정에서 공통된 데이터 포맷이나 표준 기반의 API를 동일하게 사용한다면 타 클라우드 서비스와도 높은 상호운용성 수준을 확보할 수 있다.
-  MSA 구성은 기존 모놀로식 구조와 비교해서 결코 심플하지 않다. 하나의 서비스를 잘게 쪼갬으로써, 서비스 간 복잡도가 증가 될 수 있으며, 라우터, Circuit breaker, 각 서비스들의 관리 등 고려해야 할 것들이 기존보다 더 많아질 수도 있다. 그럼에도 불구하고 서비스들을 나누고 권한을 위임하면서, 고가용성, 유연한 스케일링, 빠르고 쉬운 배포 등의 큰 장점들이 있기 때문에 협업 부서가 많거나 규모가 좀 있는 시스템이라면 충분히 고려해 볼 만한 가치가 있다.

 

## 1.3  오픈소스 생태계

### 1.3.1  개요

- 활용도가 높은(또는 여러 애플리케이션에서 활용되는) 오픈소스의 도입은 표준 준용과 함께 상호운용성과 이식성 확보를 위한 대표적인 방법이라고 할 수 있다.
- 최근 들어 클라우드 네이티브 애플리케이션을 구성하기 위하여 필요한 기술들은 다양한 오픈소스*들을 통해 구현되어 있으며, 이러한 오픈소스들이 모여 풍부한 오픈소스 생태계를 구축하고 있다.
  - CNCF에서는 클라우드 네이티브 기술 구현을 위한 백여 가지 오픈소스 프로젝트들이 진행 중
- 풍부한 오픈소스 생태계를 통해 활용도가 높은 오픈소스를 도입한다면 해당 솔루션을 사용한 애플리케이션 간의 상호운용성과 이식성 수준을 향상 시킬 수 있다.



![img](.\assets\image-20220810134110574.png)

[그림 2-3] CNCF Cloud Native Landscape

 

### 1.3.2  쿠버네티스(Kubernetes, K8S)

- 쿠버네티스는 클라우드 네이티브 애플리케이션에서 활용되는 대표적인 오픈소스 중 하나로 이미 산업 표준(De-facto Standard)이라 할 만큼 널리 활용되고 있는 솔루션이다.
- 쿠버네티스는 클라우드 환경의 컨테이너 기반 인프라를 추상화하여 하위에 어떤 클라우드가 있는지 종류에 상관없이 쿠버네티스 상에 애플리케이션을 배포하고 관리가 가능하다. 
  - 최근에는 주요 클라우드 벤더는 관리형 쿠버네티스 서비스(Amazon Kubernetes Service, Google Kubernetes Engine, Azure Kubernetes Service, NCP(Naver Cloud Platform) - Kubernetes Services 등)를 제공하고 있으므로 쿠버네티스 기반으로 구성된 애플리케이션의 경우에는 쿠버네티스 환경만 지원한다면 높은 이식성을 확보할 수 있다.

 

##  1.2. 클라우드 네이티브 애플리케이션 체크리스트

- 오늘날 대부분의 기업에서는 다양한 방식의 클라우드 시스템을 도입하려 하고 있다. 아직 대부분의 조직이나 기업들의 클라우드 성숙도 상태는 그리 높지 않지만 지속적 으로 성장하고 있다. 클라우드 컴퓨팅 기술은 저비용으로 시작이 가능하고, 무제한적인 리소스를 지역과 시간의 제약을 받지 않은 상태에서 자유롭게 제공할 수 있다는 장점을 가지고 매년 큰 규모로 성장하고 있다. 미국의 시장 조사 기관인 가트너(Gartner) 에서는 2020년 클라우드 컴퓨팅 시장은 2,500억 달러에서 2021년에는 3,060억 달러, 그리고 2022년에는 3,640억 달러로 증가할 것이라고 전망하였다. 

- 클라우드를 채택하려는 조직이나 기업의 대부분의 경우가 클라우드 채택을 위해 파악해야 할 자신들의 위치나 최적화된 플랫폼을 달성하기 위해 얼마만큼의 자원을 들여야 하는지 확신하지 못한다. 이번 절에서는 조직이나 기업의 진행 상황을 측정하기 위한 하나의 척도를 알아보기 위한 방법으로, 클라우드 네이티브 성숙도 모델(Cloud Native Maturity Model)에 대해서 알아보고, 클라우드 네이티브 애플리케이션을 구축하기 위해 고려해 봐야할 체크리스트 에 대해서 확인하도록 하자.

- 클라우드 네이티브 아키텍처를 이해하고 구축하는 것은 다양한 기술이 필요하 며, 조직의 생태계를 변경해야 하는 일일 수도 있다. 클라우드 네이티브의 시작은 조직의 애플리케이션을 더 빠르게 배포하고, 더 쉽게 확장하고, 서비스가 중단되는 횟수를 줄이기 위한 비즈니스 결정을 내리는 것에서 시작한다.

- 다음의 클라우드 네이티브 성숙도 모델(Cloud Native Maturity Model, CNMM)을 통해 조직의 현 상황을 파악하고 클라우드 네이티브 환경을 구축해 보도록 하자.

  ◾  CNMM 0: On-Premise

  ◾  CNMM 1: Cloud-Enabled

  ◾  CNMM 2: Cloud-Optimized

  ◾  CNMM 3: Cloud-Native

 

### 1) CNMM 0: On-Premise

기존의 애플리케이션들은 조직 내부와 별도의 데이터센터 등의 장소에 보관되어 사용되는 것이 일반적이었다. 만약 애플리케이션이 조직 외부에 구축되어 있는 경우라면 회사 내에서 액세스하기 위해 별도의 프록시나 방화벽, 또는 사설 네트워크를 구축해야 했다. 최근에는 Amazon, Google, Pivotal, Microsoft 등의 기업이 제공하는 Public 클라우드를 사용하여, 조직의 내부 네트워크를 초과하는 대역폭의 요청이나 리소스 등의 처리가 가능하며, 조직의 데이터센터를 보다 저렴하고 효율적으로 운영하고 있다.

| CNMM 0단계에서의 확인 내용                                   | 예   | 아니오 |
| ------------------------------------------------------------ | ---- | ------ |
| 현재 조직이 가지고 있는 IT 자원의 가변성 및 확장성에 제약이 따른다. |      |        |
| 애플리케이션의 개발 옵션으로 인해 온프레미스에서의 인프라 운영이 복잡해지고 있다. |      |        |
| 서버 가상화를 통해 애플리케이션이 운영되고 있으며, 스크립트와 인스톨러 등의 소프트웨어를 사용하여 애플리케이션을 배포하고 있다. |      |        |
| 개발 환경 → 테스트 환경 → 운영 환경이 수동으로 작업되고 있다. |      |        |
| Puppet, Ansible, Chef와 같은 프로비저닝 도구를 이용하여 애플리 케이션을 배포하고 있다. |      |        |

 

### 2) CNMM 1: Cloud-Enabled

클라우드 기반의 애플리케이션은 조직의 애플리케이션을 단순하게 클라우드 서비스를 지원하는 수준에서 사용되는 단순한 형태의 애플리케이션이다. 실행되는 환경이 온프레미스에서 클라우드로 이전만된 형태이지만, 그래도 클라우드가 가지고 있는 서비스를 사용할 수 있다. 클라우드 네이티브 애플리케이션을 구축하기 위한 첫 번째 단계이기도 하다. 온프레미스의 애플리케이션을 클라우드로 마이그레이션 할 경우, 조직에서는 값 비싼 하드웨어가 불필요하기 때문에, 비용을 상당히 줄일 수 있게 된다.

클라우드 지원 환경을 사용하는 각각의 애플리케이션들은 더 이상 자체 하드웨어에 종속적이지 않게 구축될 수 있다. 기본적으로 동일한 인스턴스에 서로 다른 기술 스택을 이용하여 애플리케이션을 구축할 수 있다.

| CNMM 1단계에서의 확인 내용                                   | 예   | 아니오 |
| ------------------------------------------------------------ | ---- | ------ |
| 애플리케이션을 네트워크로부터 분리할 수 있다.                |      |        |
| 애플리케이션을 스토리지로부터 분리할 수 있다.                |      |        |
| 애플리케이션을 구성하는 각각의 기능을 도메인에 맞춰 서비스 개념으로  분리할 수 있다. |      |        |
| 조직의 인프라스트럭처로부터 애플리케이션을 분리할 수 있다.   |      |        |
| 애플리케이션을 Platform as a Service(PaaS) 또는 컨테이너 가상화 기술을 이용하여 배포할 계획을 가지고 있다. |      |        |



### 3) CNMM 2: Cloud-Optimized

클라우드 최적화 애플리케이션은 조직의 애플리케이션을 클라우드 네이티브 애플리 케이션의 형태로 다시 개발하지 않고, 더 많은 클라우드의 기능과 서비스를 사용할 수 있도록 전환시킨 애플리케이션이다. 이러한 애플리케이션은 기존에 클라우드 기반의 애플리케이션과 새롭게 개발된 클라우드 네이티브 애플리케이션 간의 하이브리드 역할을 하게 되며, 애플리케이션을 구성하는 각각의 서비스가 마이크로 서비스 형태로 개발되고 컨테이너 가상화를 통해 운영하게 된다.

대부분의 조직이 클라우드 최적화 환경에서 애플리케이션을 사용하고 있다. 현 상태 에서도 충분히 클라우드 환경의 장점을 얻을 수 있지만, 완전한 클라우드 네이티브 애플리케이션으로 전환 시 비용을 더욱 절감하고, 성능을 향상할 수 있는지에 대해서 비즈니스 요구 사항을 더 깊게 조사해야 한다.

| CNMM 2단계에서의 확인 내용                                   | 예   | 아니오 |
| ------------------------------------------------------------ | ---- | ------ |
| 클라우드 네이티브 애플리케이션을 구성하는 마이크로서비스들은 서로 간에 종속적이지 않게 설계 되었다. |      |        |
| 클라우드 네이티브 애플리케이션을 구성하는 마이크로서비스들은 상태를 갖지 않는 서비스로 구성되어 있다. |      |        |
| 클라우드 네이티브 애플리케이션을 구성하는 마이크로서비스들은 다른 서비스의 실패에 영향을 받지 않는다. |      |        |
| 서비스의 확장(Scale-out, Scale-up)과 로드밸런서의 사용이 용이하며, 인프라스트럭처에 구애받지 않고, 어디에서나 실행 가능한 형태의 서비스로 구성되었다. |      |        |
| 개발환경 → 테스트 환경 → 운영 환경으로 이어지는 애플리케이션의 배포가 CI/CD를 통한 파이프라인에 의해 자동화 배포되고 있다. |      |        |

 

### 4) CNMM 3: Cloud-Native

조직의 애플리케이션에 대해 효율성 제공, 가용성 확보, 모범 사례 마련을 위하여 처음부터 새롭게 구축되는 단계이며, 클라우드 네이티브의 모든 기능을 충분히 이용하는 환경에서 애플리케이션들이 장치와 플랫폼, 서비스 제공자들 간에 일관되게 동작할 수 있게 한다.

| CNMM 3단계에서의 확인 내용                                   | 예   | 아니오 |
| ------------------------------------------------------------ | ---- | ------ |
| 오케스트레이션 도구를 적극 활용하며, DevOps에 필요한 프로세스, 애플리케이션 개발과 인프라스트럭처의 운영을 효율적으로 관리할 수 있다. |      |        |
| 애플리케이션의 모든 서비스가 마이크로서비스화되고, 각 서비스들은 다른 서비스에 영향을 주지 않으면서 변경되거나, 복구 될 수 있도록 설계 되었다. |      |        |
| 클라우드 네이티브 애플리케이션은 간단한 조작만으로도 다른 클라우드 환경에 배포할 수  있으며, 쉽게 이식할 수 있는 단위로 서비스가 제공된다. |      |        |
| 클라우드 네이티브 애플리케이션에 장애 발생 시 애플리케이션을 다른 컴퓨팅이나 새로운 리소스를 갖는 인스턴스에 자동으로 다시 배포할 수 있다. |      |        |

위에서 소개한 클라우드 성숙도 모델이나 클라우드 네이티브 성숙도 모델을 통해 조직이나 기업의 현재 상황을 파악하고, 각 단계에 포함된 내용을 충족시키면서 다음 단계로 이동하는 것을 권장한다. 클라우드 네이티브 아키텍처로의 전환을 고려하기 이전에 조직의 애플리케이션 중 보안상의 이유로 클라우드로 이전하지 못하는 서비스나 애플리케이션을 파악하고, 온프레미스와 클라우드 운영에 필요한 비용을 비교하는 것도 필요하다.

목표는 클라우드로 이동하는 데 집중하는 것이 아니라, 클라우드의 개념과 각 서비스의 특징에 대해 이해하고 가장 적합한 형태가 어떤 것인지 확인하는 것이다.



 

## 1.2 클라우드 네이티브 애플리케이션 기술

- 클라우드 컴퓨팅 환경이란, 클라우드 공간에 가상화된 공유자원을 사용자의 요구에 따라 할당하고 해제할 수 있는 동적인 컴퓨팅 환경을 말하며, 클라우드에서 제공하는 서비스의 유형에 따라서, Publilc 클라우드, Private 클라우드, Hybrid 클라우드 등의 환경으로 나뉜다.

- 클라우드 컴퓨팅 모델의 장점을 가지고 개발된 애플리케이션을 클라우드 네이티브 애플리케이션이라 하며, 클라우드 네이티브 애플리케이션이 가져야 하는 특징은 다음과 같다.

  ◾  서비스 및 API 기반의 개발을 보다 민첩하게 처리

  ◾  구현된 결과물을 지속적이고 자동으로 배포할 수 있는 시스템 구축

  ◾  개발 및 운영팀과의 효율적인 커뮤니케이션

  ◾  보다 발전된 모듈식 아키텍처의 구성

  ◾  사용자의 요구에 따른 수평적 확장 가능

  ◾  ‘개발 → 테스트 → 프로덕션’과 같은 여러 형태의 운영 및 테스트 환경 지원

  ◾  모든 인프라에서 DevOps의 협업 시스템을 통해 애플리케이션 이식성 제공

 

### 1.2.1  클라우드 네이티브 애플리케이션의 정의

- 클라우드 네이티브 애플리케이션은 기존 및 새로운 소프트웨어 개발 패턴의 조합이라 고 볼 수 있다. 
- 기존 패턴을 소프트웨어 자동화(인프라 및 시스템), API 통합 및 서비스 지향의 아키텍처라고 한다면, 클라우드 네이티브 패턴은 마이크로 서비스 아키텍처, 컨테이너화된 서비스, 분산 관리 및 오케스트레이션으로 구성되어 있다. 
- 클라우드 네이티브 애플리케이션을 성공적으로 개발하려면 클라우드 네이티브 아키텍처에 의해 설계하는 것과 개발된 애플리케이션이 인프라에 미치는 영향을 이해하는 것이 중요하다.



### 1.2.2 클라우드 네이티브 애플리케이션의 특성

- PC 가상화 솔루션을 제공하는 VMWare에서는 DevOps, CI/CD, 마이크로 서비스, 컨테이너 기술을 클라우드 네이티브 애플리케이션을 구성하는 4가지 주요 기술 이라고 소개 하였다. 

- 클라우드 네이티브 애플리케이션은 조직 내 인력과 이들의 협업 프로세스를 자동화하는 것에서 시작되며, DevOps를 도입하여 공통의 목적을 가지고 주기적인 피드백을 통해 개발팀과 운영팀의 협업을 지원할 수 있어야 한다.

 

![img](D:\cloudnative\assets\1-1.jpg)

[그림 3-1] 클라우드 네이티브 애플리케이션 구성요소

 

- 컨테이너 가상화 기술을 도입하면 이상적인 애플리케이션 배포 및 각 서비스에 대한 독립적인 실행 환경을 제공할 수 있으며, 하나의 대규모 릴리스 및 업데이트가 아닌 수많은 마이크로서비스가 탄력적으로 결합된 하나의 컬렉션 형태로 애플리케이션을 쉽게 릴리스 및 업데이트할 수 있게 된다.

- 클라우드 네이티브 애플리케이션의 개발은 아키텍처의 모듈의 독립성, 탄력적인 결합 그리고 독립적인 서비스에 중점을 둔다. 
- 애플리케이션을 구성하는 각 마이크로서비스는 비즈니스 로직을 구현하고 자체 프로세스로 실행되며, 서비스간에 또는 다른 애플리 케이션 간에 애플리케이션 프로그래밍 인터페이스(Application Programming Interfaces, API) 나 메시지 큐잉(Message Queuing) 방식을 통해 커뮤니케이션 하게 된다. 이러한 커뮤니케이션은 마이크로서비스 아키텍처에서 서비스 메쉬 레이어(Service Mesh Layer)를 통해 관리할 수 있다.

  

### 1.2.4  12 Factors

https://12factor.net/ko/

  ![img](.\assets\V9nAWbd-c9635361688ff77f82ccc7b1bdefd891.png)

- 12 Factors란, 클라우드 플랫폼 제공 회사인 헤로쿠(Heroku)라는 기업에서 자사의 클라우드 플랫폼 모델을 사용하는 기업들의 애플리케이션 개발, 운영, 확장 등을 관찰하고, 개발 엔지니어와 개발 회사로부터의 얻은 노하우를 바탕으로 정리한 개발 방법론이자 안내서이다. 
-  클라우드 플랫폼의 일반적인 동적 환경 프로비저닝 요구 사항을 충족하도록 애플리케이션을 이식 가능하게 만드는 것입니다. 
  - **선언적 형식** 을 사용하여 설정을 자동화합니다.
  - 실행 환경 **간 이식성 극대화**
  - **Cloud Platform** 에 배포하기에 적합
  - 민첩성을 극대화하기 위해 지속적인 배포를 가능하게 하여 **개발과 생산 간의 차이 최소화**
  - 도구, 아키텍처 또는 개발 방식을 **크게 변경하지 않고 확장할** 수 있는 능력 .



#### 1)  코드베이스 - 모든 환경에 대한 버전 관리를 받는 단일 코드베이스

> 개정 제어에서 추적되는 하나의 코드베이스, 많은 배포.

**이는 단일 개인 또는 그룹과 함께 애플리케이션의 명확한 소유권을 설정하는 데 도움이 됩니다.** 애플리케이션에는 새로운 기능, 결함 수정 및 기존 기능에 대한 업그레이드로 발전하는 단일 코드베이스가 있습니다. 애플리케이션 소유자는 애플리케이션 수명 동안 다양한 버전을 빌드하고 테스트, 스테이징 및 프로덕션과 같은 여러 환경에 배포할 책임이 있습니다.

이 원칙은 여러 환경에 구축 및 배포할 수 있는 단일 코드베이스를 갖는 것을 옹호합니다. 각 환경에는 데이터베이스, 구성 데이터 및 API URL과 같은 특정 리소스 구성이 있습니다. 이를 달성하려면 모든 환경 종속성을 애플리케이션의 빌드 및 실행 단계에서 지정할 수 있는 형식으로 분리해야 합니다.

이는 선언적 형식을 사용하여 환경 간 이식성을 극대화하는 Twelve-Factor App의 처음 두 가지 목표를 달성하는 데 도움이 됩니다.

**이 원칙에 따라 Spring Boot 애플리케이션의 소스 코드를 포함하는 단일 Git 리포지토리를 갖게 됩니다. 이 코드는 컴파일 및 패키징된 다음 하나 이상의 환경에 배포됩니다.**

[Spring 프로필](https://reflectoring.io/spring-boot-profiles/) 및 [환경별 속성](https://reflectoring.io/profile-specific-logging-spring-boot/) 을 사용하여 런타임 시 특정 환경에 대한 애플리케이션을 구성합니다 .

**특정 환경에 맞게 구성하기 위해 소스 코드를 변경해야** 하거나 개발 및 프로덕션과 같은 다양한 환경에 대해 별도의 리포지토리가 있는 경우 이 규칙을 위반하는 것입니다.



#### 2) 종속성

> 종속성을 명시적으로 선언하고 격리합니다.

**종속성은 애플리케이션 간에 코드를 재사용하기 위한 지침을 제공합니다. 재사용 가능한 코드 자체는 단일 코드베이스로 유지되지만 라이브러리 형태로 패키지화되어 여러 애플리케이션에 배포됩니다.**

애플리케이션의 가장 가능성 있는 종속성은 오픈 소스 라이브러리 또는 다른 팀에서 사내 구축한 라이브러리입니다. 종속성은 호스트 시스템에 설치된 특정 소프트웨어의 형태를 취할 수도 있습니다. 플랫폼의 종속성 관리 도구를 활용하여 외부 파일에 종속성을 선언합니다.

Spring Boot 애플리케이션의 경우 파일에 종속성을 선언 `pom.xml`합니다(또는 `build.gradle`Gradle을 사용하는 경우). `spring-boot-starter-web`다음은 종속성 중 하나로 사용하는 Spring Boot 애플리케이션의 예입니다 .

```xml
    <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
```

이 원칙은 공유 클래스 경로에 라이브러리를 저장하여 애플리케이션 간에 라이브러리를 공유하는 이전 관행에서 발전된 것입니다. 이 접근 방식을 사용하면 호스트 시스템 구성과의 결합이 도입되었습니다.

종속성을 지정하는 선언적 스타일은 이 결합을 제거합니다.

Spring Boot를 사용하는 맥락에서 Maven/Gradle과 같은 종속성 도구를 사용할 때 다음을 얻습니다.

- 애플리케이션이 작동하는 종속성의 특정 버전을 선언하여 **버전 관리**

- 애플리케이션과 종속성을 번들링하여 **격리 .**

  

#### 3) 구성 - 구성 속성의 외부화

> 환경에 구성을 저장합니다.

이상적으로는 환경이 클라우드에서 동적으로 프로비저닝되므로 애플리케이션을 구축하는 동안 사용할 수 있는 정보가 거의 없습니다.

**구성 속성을 환경 변수로 분리하면 코드 변경 없이 애플리케이션을 다른 환경에 쉽고 빠르게 배포할 수 있습니다.**

구성 데이터의 몇 가지 예는 데이터베이스 연결 URL 및 자격 증명, 응용 프로그램이 의존하는 서비스의 URL입니다. 이들은 대부분 환경에 따라 다른 값을 갖습니다. 이것이 애플리케이션과 함께 번들로 제공되는 코드 또는 속성 파일에 하드 코딩되어 있는 경우 다른 환경에 배포하기 위해 애플리케이션을 업데이트해야 합니다.

대신 환경 변수를 사용하여 [구성을 외부화 하는 것이 더 나은 방법입니다. ](https://reflectoring.io/externalize-configuration/)환경 변수의 값은 런타임에 제공됩니다. 애플리케이션이 독립 실행형으로 실행되는 경우 명령줄에서 값을 제공할 수 있습니다.

Spring Boot 애플리케이션의 기본 동작은 환경 변수의 값을 적용하여 속성 파일에 선언된 모든 값을 재정의하는 것입니다. [구성 속성](https://reflectoring.io/spring-boot-configuration-properties/) 을 사용하여 코드에서 구성 매개변수를 사용할 수 있습니다 .



#### 4) 지원 서비스 - 플러그형 데이터 소스 및 대기열

> 지원 서비스를 연결된 리소스로 취급합니다.

**이 원칙은 애플리케이션을 크게 변경하지 않고 지원 서비스 구현을 변경할 수 있는 유연성을 제공합니다.**

플러그 가능성은 RDBMS 데이터 소스를 통해 JPA와 같은 추상화를 사용하고 연결을 구성하기 위해 구성 속성(예: JDBC URL)을 사용하여 가장 잘 달성할 수 있습니다.

이런 식으로 JDBC URL을 변경하여 데이터베이스를 교체할 수 있습니다. 그리고 종속성을 변경하여 기본 데이터베이스를 교체할 수 있습니다. H2 데이터베이스에 대한 종속성의 스니펫은 다음과 같습니다.

```xml
    <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-data-jpa</artifactId>
    </dependency>
    <dependency>
      <groupId>com.h2database</groupId>
      <artifactId>h2</artifactId>
      <scope>runtime</scope>
    </dependency>
```

H2 데이터베이스를 Oracle 또는 MySQL과 같은 다른 RDBMS로 쉽게 교체할 수 있습니다. JPA와 유사하게 메시징에는 JMS를, 메일에는 SMTP를 사용할 수 있습니다.

#### 5) 빌드, 릴리스, 실행 - 개발 워크플로를 위한 컨테이너 활용

> 빌드 및 실행 단계를 엄격하게 분리합니다.

**빌드, 릴리스 및 실행 단계를 별도로 유지해야 합니다. 이 분리는 응용 프로그램 충실도와 무결성을 유지하는 데 중요합니다.**

이러한 단계는 순서대로 발생합니다. 각 단계는 다른 목표를 갖고 다음 단계로 전파되는 출력을 생성합니다.

긴급 수정을 포함한 모든 코드 변경은 빌드 단계에서 발생해야 하며 프로덕션으로 승격되기 전에 설정된 릴리스 주기를 따라야 합니다. 예를 들어 프로덕션 환경에서 작은 수정을 함으로써 이 원칙을 위반하면 빌드 단계로 전파하기 어렵게 만들고 기존 분기를 방해하며 무엇보다도 이 관행을 따르는 데 따른 위험과 전체 비용을 증가시킵니다.

Spring Boot 애플리케이션의 경우 컨테이너용 개발 워크플로를 사용하여 쉽게 달성할 수 있습니다.

- **Build** : 소스 코드를 컴파일하고 Docker 이미지를 빌드합니다.
- **릴리스** : 이미지에 태그를 지정하고 레지스트리에 푸시합니다.
- **실행** : 레지스트리에서 이미지를 가져와 컨테이너 인스턴스로 실행합니다.

컨테이너를 사용하여 애플리케이션을 패키징하고 실행하는 경우 이 Twelve-Factor App 원칙을 준수하기 위해 애플리케이션을 변경할 필요가 없습니다.



#### 6) 프로세스 - 상태 비저장 애플리케이션

> 앱을 하나 이상의 상태 비저장 프로세스로 실행합니다.

**상태 비저장 프로세스는 애플리케이션이 트래픽의 급격한 증가를 처리하기 위해 빠르게 확장하고 시스템에 대한 트래픽이 감소할 때 축소할 수 있는 기능을 제공합니다.** 상태 비저장으로 만들려면 모든 데이터를 애플리케이션 외부에 저장해야 합니다.

Spring Boot 애플리케이션은 호스트 시스템 또는 Docker와 같은 컨테이너 런타임 환경 내부에서 Java 프로세스로 실행됩니다. 이 원칙은 프로세스가 무국적(stateless)이고 무공유(share-no)여야 한다고 주장합니다. 지속해야 하는 모든 데이터는 데이터베이스와 같은 상태 기반 지원 서비스에 저장해야 합니다.

이것은 응용 프로그램 프로세스의 메모리에 사용자 세션 데이터를 캐시하고 동일한 세션의 향후 요청이 동일한 프로세스로 라우팅될 것으로 예상하는 웹 응용 프로그램에서 "고정 세션"을 사용하는 방법에서 전환된 것입니다.

고정 세션은 12 Fattors을 위반하는 것입니다. 세션 상태 데이터는 Memcached 또는 Redis와 같이 시간 만료를 제공하는 데이터 저장소의 애플리케이션 외부에 저장되어야 합니다.



#### 7) 포트 바인딩 - 환경 속성으로 정의된 포트

> 포트 바인딩을 통해 서비스를 내보냅니다.

**포트 바인딩은 특정 포트에 자신을 바인딩하고 해당 포트에서 관심 있는 소비자의 모든 요청을 수신하는 응용 프로그램을 나타냅니다.** 포트는 환경 변수로 선언되어 실행 중에 제공됩니다.

이 원칙에 따라 구축된 애플리케이션은 웹 서버에 의존하지 않습니다. 응용 프로그램은 완전히 독립적이며 독립 실행형으로 실행됩니다. 웹 서버는 라이브러리로 패키지되어 애플리케이션과 함께 번들로 제공됩니다.

포트 바인딩은 마이크로 서비스가 자율적이고 독립적이어야 하는 기본 요구 사항 중 하나입니다.

Spring Boot는 애플리케이션에 Tomcat을 포함하고 포트에 바인딩하고 해당 포트로 들어오는 요청을 수신하여 HTTP를 서비스로 내보냅니다.

`server.port`구성 속성 을 설정하여 포트를 구성할 수 있습니다 . 기본값은 8080입니다.



#### 8) 동시성 - 확장을 지원하는 상태 비저장 애플리케이션

> 프로세스 모델을 통해 확장합니다.

전통적으로 애플리케이션이 용량 한계에 도달할 때마다 해결 방법은 RAM, CPU 및 기타 리소스를 추가하여 용량을 늘리는 것이었습니다(수직 확장이라고 하는 프로세스).

반면 수평적 확장 또는 "확장"은 클라우드 환경의 탄력적인 확장성과 잘 작동하도록 하는 보다 현대적인 접근 방식입니다. **하나의 프로세스를 더 크게 만드는 대신 여러 프로세스를 만든 다음 이러한 프로세스 간에 응용 프로그램의 로드를 분산합니다.**

Spring Boot는 이 요소에 많은 도움이 되지 않습니다. 애플리케이션이 상태 비저장인지 확인해야 하므로 증가된 로드를 지원하기 위해 많은 동시 작업자로 확장할 수 있습니다. 모든 종류의 상태는 애플리케이션 외부에서 관리해야 합니다.

또한 특정 프로세스를 독립적으로 확장하려면 애플리케이션을 여러 개의 더 작은 애플리케이션(예: 마이크로서비스)으로 분할해야 합니다. 확장은 Kubernetes 및 Docker Swarm과 같은 컨테이너 오케스트레이션 시스템에서 처리합니다.



#### 9) 일회용 - 임시 컨테이너 활용

> 빠른 시작 및 단계적 종료로 견고성을 극대화합니다.

**응용 프로그램의 일회용 기능을 사용하면 빠르게 시작하거나 중지할 수 있습니다.**

안정적인 상태가 되어 정상적으로 종료되는 데 오랜 시간이 걸리면 애플리케이션을 빠르게 확장, 배포 또는 복구할 수 없습니다. 애플리케이션의 로드가 증가하고 해당 로드를 처리하기 위해 더 많은 인스턴스를 가져와야 하는 경우 시작 지연은 애플리케이션이 시작되는 동안 요청 거부를 의미할 수 있습니다.

Spring Boot 애플리케이션은 일회용으로 만들기 위해 컨테이너 내부에서 실행되어야 합니다. 컨테이너는 임시적이며 언제든지 시작하거나 중지할 수 있습니다.

따라서 시작 시간을 최소화하고 컨테이너가 중지될 때 애플리케이션이 정상적으로 종료되도록 하는 것이 중요합니다. 종속 리소스의 지연 초기화와 [최적화된 컨테이너 이미지](https://reflectoring.io/spring-boot-docker/) 를 구축하여 시작 시간을 최소화 합니다.



#### 10) Dev/Prod Parity - 한 번 빌드 - 어디든지 실행

> 개발, 준비 및 프로덕션을 가능한 한 유사하게 유지합니다.

**dev/prod 패리티의 목적은 애플리케이션이 변경 없이 이상적으로 모든 환경에서 작동하도록 하는 것입니다.**

환경 간 코드 이동은 전통적으로 개발 속도를 늦추는 주요 요인이었습니다. 이는 개발 및 생산에 사용되는 인프라의 차이에서 비롯되었습니다.

컨테이너를 사용하면 한 번 빌드하고 여러 대상 환경으로 배송할 수 있습니다. 또한 OS를 포함한 모든 종속성을 패키징할 수 있습니다.

Spring Boot 애플리케이션은 Docker 컨테이너에 패키징되어 Docker 레지스트리에 푸시됩니다. Docker 파일을 사용하여 Docker 이미지를 생성하는 것 외에도 Spring Boot는 Cloud-Native 빌드팩을 사용하여 소스에서 OCI 이미지를 빌드 하기 위한 플러그인을 제공합니다.



#### 11) 로그 - 이벤트 스트림으로 로그 게시

> 로그를 이벤트 스트림으로 취급합니다.

애플리케이션은 일련의 이벤트로만 로그를 생성해야 합니다. 클라우드 환경에서는 애플리케이션을 실행하는 인스턴스에 대한 지식이 제한적입니다. 예를 들어 탄력적 확장 중에 인스턴스를 만들고 종료할 수도 있습니다.

**호스트 인스턴스의 파일 시스템에 저장된 로그를 기반으로 하는 애플리케이션 진단 프로세스는 지루하고 오류가 발생하기 쉽습니다.**

따라서 추가 분석을 위해 로그를 저장, 집계 및 다른 시스템으로 전달하는 책임은 기본 클라우드 플랫폼에서 사용할 수 있는 특수 목적 소프트웨어 또는 관측 가능성 서비스에 위임되어야 합니다.

또한 애플리케이션의 로그 방출 프로세스를 단순화하면 코드베이스를 줄이고 애플리케이션의 핵심 비즈니스 가치에 더 집중할 수 있습니다.

Spring Boot는 기본적으로 콘솔에만 기록하고 로그 파일을 작성하지 않습니다. 기본 Logger 구현으로 Logback으로 사전 구성됩니다.

Logback은 로그 어펜더, 필터, 배송업체로 구성된 풍부한 생태계를 가지고 있으므로 많은 모니터링 및 시각화 도구를 지원합니다. 이 모든 것은 [Spring boot에서 로깅을 구성](https://reflectoring.io/springboot-logging/) 하는 데 자세히 설명되어 있습니다 .



#### 12) 관리 프로세스 - API로 구축되고 애플리케이션과 함께 패키징됨

> 관리/관리 작업을 일회성 프로세스로 실행합니다.

대부분의 응용 프로그램은 관리 및 관리를 위해 일회성 작업을 실행해야 합니다. 원래 권장 사항은 python 및 C와 같은 언어에 더 적합한 REPL(Programmatic Interactive Shell) 사용을 강조합니다. 그러나 이것은 현재 개발 관행에 맞게 적절하게 조정되어야 합니다.

관리 작업의 예로는 데이터베이스를 초기화하기 위한 데이터베이스 스크립트 또는 잘못된 레코드를 수정하기 위한 스크립트가 있습니다. Twelve-Factor App의 원래 목표인 최대 이식성 빌드에 따라 이 코드는 애플리케이션과 함께 패키지화되어 함께 릴리스되어야 하며 동일한 환경에서도 실행되어야 합니다.

Spring Boot 애플리케이션에서 관리 기능을 일회성 프로세스로 호출되는 별도의 끝점으로 노출해야 합니다. 일회성 프로세스를 실행하기 위해 기능을 추가하는 것은 빌드, 테스트 및 릴리스 주기를 거칩니다.



#### 1.2.5 결론

| Factor           | 적용방법                                                     |
| ---------------- | ------------------------------------------------------------ |
| 코드베이스       | 모든 환경에 대해 하나의 코드베이스를 사용합니다.             |
| 종속성           | `pom.xml`또는 의 모든 종속성을 선언합니다 `build.gradle`.    |
| 구성             | 환경 변수를 사용하여 구성을 외부화합니다.                    |
| 지원 서비스      | JPA와 같은 추상화를 사용하여 플러그형 서비스를 구축합니다.   |
| 빌드/릴리스/실행 | Docker 이미지를 빌드하고 게시합니다.                         |
| 프로세스         | 상태 비저장 서비스를 구축하고 모든 상태 정보를 애플리케이션 외부(예: 데이터베이스) 외부에 저장합니다. |
| 포트 바인딩      | `server.port`환경 변수 로 포트를 구성 하십시오.              |
| 동시성           | 더 작은 상태 비저장 애플리케이션(마이크로서비스)을 구축합니다. |
| 일회용           | 컨테이너 이미지에 애플리케이션을 패키징합니다.               |
| 개발/제품 패리티 | 컨테이너 이미지를 빌드하고 여러 환경에 제공합니다.           |
| 로그             | 중앙 로그 수집기에 로그를 게시합니다.                        |
| 관리 프로세스    | API 엔드포인트로 일회성 프로세스를 구축합니다.               |



### 1.2.5 15 Factors

2016년에는 클라우드 플랫폼 회사 피보탈(Pivotal)의 엔지니어인 케빈 호프만(Kevin Hoffman)이 최신 트렌드에 맞는 사용자의 요구 사항을 반영하여 헤로쿠의 12 Factors 에 3가지의 요소를 추가하였다15). 새롭게 추가된 내용은 아래와 같다.

13) API 우선(API First): API 설계를 우선하여, 코드를 작성하기 이전에 설계하고자 하는 서비스의 의도와 기능을 명확하게 할 수 있음. API 설계로 Web이나 모바일 뿐만 아니라 API를 이용하려는 다른 서비스간에도 커뮤니케이션 가능

14) 관측(Telemetry): 애플리케이션 성능 모니터링, 애플리케이션이 처리하는 초당 HTTP 요청의 평균 개수 등과 같이 비즈니스에 의미 있는 예측 분석을 위해 이벤트 및 데이터 수집

15) 인증과 권한(Authentication and Authorization): 애플리케이션의 리소스에 대한 모든 요청에 대해 누가 요청을하고 있는지, 해당 사용자가 적절한 역할을 가지고 작업을 수행할 권한을 부여할지 여부를 결정

케빈 호프만은 3가지의 새로운 내용을 추가하면서 기존 12 Factors의 우선순위를 다음과 같이 변경하는 것을 제안하였다.

1) 코드 베이스(One Codebase, One Application)

2) API 우선(API First)

3) 종속성(Dependency Management)

4) 빌드, 릴리스, 실행(Design, Build, Release, Run)

5) 설정(Configuration, Credentials)

6) 로그(Logs)

7) 폐기 가능(Disposability)

8) 벡엔드 서비스(Backing Services)

9) 개발, 프로덕션 환경 일치(Environment Parity)

10) 관리 프로세스(Administrative Processes)

11) 포트 바인딩(Port Binding)

12) 무상태 프로세스(Stateless pProcesses)

13) 동시성(Concurrency)

14) 관측(Telemetry)

15) 인증과 권한(Authentication and Authorization)

 

## 1.3 모놀리스와 클라우드 네이티브 애플리케이션의 차이점

 <img src=".\assets\image-20220810135438142.png" alt="image-20220810135438142" style="zoom:150%;" />

[그림 3-2] 모놀리스와 마이크로서비스 아키텍처의 차이16)

  

### 1.3.1  모놀리스 아키텍처

- 모놀리스 아키텍처에 의해 개발되는 애플리케이션의 대부분은 장기간에 걸쳐 순차적 으로 진행되는 폭포수(waterfall) 개발 방식으로 구축된다. 애플리케이션 자체가 하나의 구성으로 이뤄져 있는 경우가 대부분이며 일반적으로 다음과 같이 3개의 주요 부분으 로 구성되었다. 

  ◾ 클라이언트 사이드 UI(Front-end): HTML 페이지와 사용자 단말기의 브라우저 에서 실행되는 자바스크립트와 같은 프로그래밍 언어

  ◾  데이터베이스(Database): 애플리케이션에서 사용되는 데이터가 저장되는 저장소, 일반적으로 관계형 데이터베이스를 사용하며, 사용자의 요구사항에 의해 도출된 도메인에 의해 여러 개의 테이블로 구성

  ◾  서버 사이드 애플리케이션(Server side application, Back-end): 클라이언트의 요청에 따라, 비즈니스 로직을 실행하며 데이터베이스와의 연동 작업을 통해, 사용자의 요청 UI에게 결과 값이나 뷰(View) 페이지를 전달(예, 사용자가 웹 브라우저를 이용하는 경우에 HTML 페이지를 위한 뷰 생성)

- 위에서 언급한 3개의 주요 부분을 하나의 애플리케이션에 구현한 것을 모놀리스 애플리케이션이라 한다. 즉, 클라이언트 측의 UI와 서버 사이드 애플리케이션과 데이터베이스 관련 작업을 처리하는 로직을 하나의 구조에 포함하여 작성된 애플리 케이션을 말한다.

- 구현된 애플리케이션을 배포하기 위해서는 먼저, 개발자의 컴퓨터에서 단위 테스트를 실행하고, 테스트 환경에서 사용자 테스트를 수행한 다음, 최종 프로덕션 환경에 배포하게 된다. 이러한 배포 과정은 배포 파이프라인(Deploy Pipeline)을 통해 자동화 시킬 수 있으며, 여러 인스턴스들 앞에 로드 밸런서(Load Balancer)를 두어 사용자의 요청을 분산 처리하여 실행할 수도 있다.

- 모놀리스 애플리케이션은 시스템 또는 서비스 간에 긴밀하게 결합(coupling)되어 개발 되었다. 사용자 인터페이스 및 다양한 애플리케이션 서비스, 데이터 액세스 코드 및 기타 구성 요소들이 기술 환경에 상관없이 결합되어, 대규모의 다목적 애플리케이션 형태로 구축되었다.

- 모놀리스 아키텍처로 구현된 단일 애플리케이션은 시스템을 구축하기 쉽다는 장점을 가지고 있지만, 애플리케이션의 작은 부분을 변경할 경우라도 전체 애플리케이션을 다시 빌드해야 한다. 
- 애플리케이션을 운영하는 시간이 길어질수록 단순화된 모듈 구조를 유지하기 어려워지며, 특정한 모듈의 변경하려고 해도, 관련이 없는 전체 애플리케이션을 다시 배포 해야 한다. 
- 모놀리스 애플리케이션의 인프라는 애플리케이션에 필요한 최대 용량을 예측하여 사전에 사용할 수 있는 리소스가 미리 결정되어 준비되기 때문에, 애플리케이션이 운영되고 있는 시스템의 성능을 높이기 위한 스케일링(Scaling) 작업에서도, 필요한 부분만큼의 자원을 늘리는 것이 아니라, 수직적 확장(Scale up)을 통해 서버의 하드웨어 용량을 높이는 확장이 이루어져야 하는 단점을 가지고 있었다.

 

### 1.3.2  마이크로서비스 아키텍처

- 마이크로서비스 아키텍처는 소프트웨어 애플리케이션을 독립적으로 배치 가능하도록 서비스를 조합하고 설계하는 개발 방법을 말한다. 마이크로서비스의 창시자인 제임스 루이스(James Lewis)와 마틴 파울러(Martin Fowler)는 마이크로 서비스에 대해 다음과 같이 정의하였다.

> “간단히 말해서 마이크로 서비스 아키텍처 스타일은 단일 애플리케이션을 작은 서비스들의 모음으로 개발하려는 접근 방식으로, 각각의 서비스는 자신만의 프로세스로 실행되고 HTTP 리소스 API와 같은 경량 메커니즘을 사용하여 통신한다. 이러한 서비스는 비즈니스 기능을 중심으로 구축되며 완전히 자동화된 배포 시스템을 통해 독립적으로 배포할 수 있다. 이러한 서비스들은 중앙 집중식 관리를 최소로 하고 있으며, 다양한 프로그래밍 언어로 개발되고 다른 데이터 저장 기술을 사용한다.”

위에서 언급된 내용 중 핵심적인 사항을 살펴보면, 다음과 같이 정의 내릴 수 있다.

​	◾  적절하게 나뉜 작은 서비스

​	◾  독립적인 프로세스로 운영

​	◾  비즈니스 중심으로 구축되고 독립적인 배포가 가능

​	◾  중앙 집중 관리의 최소화

​	◾  다른 언어와 다른 데이터 저장 기술로 작성

- 마이크로서비스 아키텍처 스타일은 하나의 애플리케이션을 작은 서비스 군의 조합으로 구축하는 방법을 말하며, 개별 서비스는 독립적인 프로세스로 실행되며, HTTP 프로토콜을 이용하는 리소스(Resource) API 등을 통해 통신하게 된다.
-  서비스는 비즈니스 수행 능력에 맞게 구분되며(DDD), 자동화된 매커니즘을 통해 관리된다. 최소의 중앙 통제적인 관리를 받으며, 각각의 서비스는 서로 다른 프로그래밍 언어와 다른 데이터 저장 기술을 통해 개발될 수도 있다.



# 3. 네이티브 클라우드 기술스택

## 3.1.  클라우드 네이티브 아키텍처

### 3.1.1  클라우드 네이티브 아키텍처와 기술

- 클라우드 컴퓨팅 환경에서 확장 가능한 애플리케이션을 개발하고 운영하기 위한 기술을 통틀어 클라우드 네이티브 기술이라 하며, 클라우드 네이티브 기술을 이용하여 구현되는 애플리케이션 및 서비스를 위한 설계나 계획을 클라우드 네이티브 아키텍처라 한다.

- 클라우드 네이티브 기술의 대표적인 예로 컨테이너, 서비스 메쉬(Service Mesh), 마이크로 서비스(MicroService), 불변의 인프라스트럭쳐(Immutable Infrastructure), 선언적 API (Declarative API) 등이 있으며, 클라우드 네이티브 기술들을 이용해 서비스 하고자 하는 애플리케이션에 대해 적은 리소스의 사용, 회복성, 관리능력 및 느슨하게 연결된 모듈 등의 효과를 제공할 수 있을 뿐만 아니라, 자동화된 인프라의 구성으로 시스템의 변경 및 개선 사항을 최소한의 노력으로 더 자주 배포할 수 있다.

- CNCF에서는 클라우드 네이티브 아키텍처가 다음과 같은 속성을 갖도록 구성되어야 한다고 정의 하였다.

  ◾  애플리케이션 또는 프로세스는 컨테이너 가상화 기술에 의해 분리된 단위로 실행

  ◾  애플리케이션을 구성하는 프로세스는 리소스 사용을 개선하고 유지보수 비용을 줄이기 위해 중앙 오케스트레이션 프로세스에 의해 동적으로 관리

  ◾  애플리케이션 또는 서비스(마이크로서비스)는 명시적으로 기술된 종속적인 각 항목들과 느슨하게 결합

 

### 3.1.2 클라우드 네이티브 아키텍처의 기술 스택

- 클라우드 네이티브 아키텍처를 구성하는 각각의 기술 스택들은 애플리케이션을 보다 빠르게 개발하고, 관리하기 쉽도록 모니터링 기술을 지원하며, 클라우드 상에 배포되는 시간을 단축하여, 더 자주 배포하는 것을 목표로 한다. 
- CNCF의 TOC(Technical Oversight Committee) 대표인 Ken Owens는 이러한 클라우드 네이티브 관련 기술 스택들 간의 호환성과 표준화를 위해 다음과 같은 클라우드 네이티브 참조 아키텍처를 제시하였다.

 ![img](.\assets\clip_image115.jpg)

[그림 4-1] 클라우드 네이티브 참조 아키텍처

1) Application Definition/Development: 컨테이너 네이티브 애플리케이션을 구현하는데 필요한 메타데이터, 설정, 도구, 컨테이너 이미지 관리 도구 등

2) Orchestration & Management: 컨테이너 오케스트레이션(Kubernetes, Docker Swarm 등) 도구를 활용한 컨테이너 배포, Logging & Monitoring, Service Discovery 등

3) Runtime: 컨테이너 실행 표준(OCI), 컨테이너 네트워킹(Container Networking Interface Project), Storage(Volume Driver) 등

4) Provisioning: 컨테이너 환경을 고려한 DevOps의 배포 도구와 프로비저닝 등

5) Infrastructure: Bare Metal, Public Cloud 환경에서의 호환성을 유지

위에서 설명한 클라우드 네이티브 참조 아키텍처에서는 제일 먼저 비즈니스 도메인에 맞는 실행 환경과 애플리케이션을 설계 및 개발한 다음, 컨테이너 가상화 기술에 의해 배포하고 관리 도구를 사용해 애플리케이션의 상태와 개선 사항을 주기적으로 확인하도록 하고 있다.

​                 ![텍스트 상자: 애플리케이션 설계 → 개발 → 컨테이너에 배포 → 관리](.\assets\clip_image001.png)    



#### 3.1.2.1  Cloud Native Landscape

https://landscape.cncf.io/

- CNCF에서는 클라우드 네이티브 참조 아키텍처를 바탕으로 클라우드 네이티브화를 실현하기 위한 Open Source Service(이하 OSS)나 서비스 기술 목록인 Cloud Native Landscape와 단계별 클라우드 네이티브 구축을 위한 Cloud Native TrailMap를 공개하였다.

- Cloud Native Landscape 프로젝트를 통해 공개된 클라우드 네이티브 아키텍처를 위한 기술 스택은 다음과 같다.

  ◾  Application Definition and Development

  ​	\- Database

  ​	\- Streaming & Messaging

  ​	\- Application Definition & Image Build

  ​	\- Continuous Integration & Delivery

  ◾  Orchestration & Management

  ​	\- Scheduling & Orchestration

  ​	\- Coordination & Service Discovery

  ​	\- Remote Procedure Call

  ​	\- Service Proxy

  ​	\- API Gateway

  ​	\- Service Mesh

  ◾  Runtime

  ​	\- Cloud Native Storage

  ​	\- Container Runtime

  ​	\- Cloud Native Network

  ◾  Provisioning

  ​	\- Automation & Configuration

  ​	\- Container Registry

  ​	\- Security & Compliance

- Key Management

  ◾  Platform

  ​	\- CloudFoundry

  ​	\- OpenShift

  ​	\- RANCHER

  ◾  Observability and Analysis

  ​	\- Monitoring: Prometheus

  ​	\- Logging: Fluentd

  ​	\- Tracing: JAEGER

  ​	\- Chaos Engineering: Gremlin

<img src=".\assets\image-20220810140046458.png" alt="image-20220810140046458" style="zoom:150%;" />



[그림 4-2] Cloud Native Landscape

 

#### 3.1.2.2  Cloud Native Trail Map

- Cloud Native TrailMap에서는 Cloud Native Landscape 프로젝트의 수많은 기술 스택 중에 클라우드 네이티브 애플리케이션 구축에 필요한 기술 및 개발, 운영에 권장되는 프로세스를 소개하고 있다.

![Cloud Native Trail Map infographic](.\assets\CNCF_TrailMap_latest-1.png)

[그림 4-3] Cloud Native TrailMap

 

1) Containerization

​	\- 일반적으로 Docker 컨테이너로 수행

​	\- 다양한 크기의 애플리케이션과 종속성에 관련된 내용을 컨테이너화

​	\- 애플리케이션을 단계별로 분할에 적합한 부분부터 분할하면서 Microservice로 전환

2) CI/CD

​	\- CI/CD(Continuous Integration/Continuous Delivery)를 설정하여 소스 코드를 변경하면 새 컨테이너가 자동으로 빌드, 테스트 및 스테이징 환경에 배포되어 최종적으로 프로덕션에 배포되도록 구성

​	\- 롤아웃, 롤백 및 테스트에 대한 자동화 설정

3) Orchestration & Application Definition

​	\- Docker 컨테이너의 표준화 오케스트레이션 도구인 Kubernetes 사용

​	\- Kubernetes를 이용하여 배포할 호스팅 플랫폼 또는 설치 프로그램을 선택

​	\- Kubernetes에서는 복잡한 애플리케이션의 정의, 설치 및 업그레이드를 위한 도구 (Helm Chart 등) 사용 가능

4) Observability & Analysis

​	\- 모니터링, 로깅 및 추적을 위한 솔루션

​	\- CNCF 프로젝트에서 Prometheus(모니터링), Fluentd(로깅) 및 Jaeger(추적) 제공

5) Service Proxy, Discovery & Mesh

​	\- 서비스 검색과 상태 확인, 라우팅 및 로드 밸런싱

​	\- 애플리케이션의 구성 요소 간 데이터통신을 위한 아키텍처를 지원

6) Networking, Policy & Security

​	\- 보다 유연한 네트워크 구성을 위해 Calico, Flannel 또는 Weave Net과 같은 CNI(Container Network Interface) 호환 네트워크 프로젝트 사용

​	\- CNCF 프로젝트 중 권한 부여 및 승인 제어에서 데이터 필터링에 이르기까지 다양한 용도로 사용되는 범용 정책엔진을 위해 OPA(Open Policy Agent)나 클라우드 네이티브의 이상 탐지를 위한 Falco 서비스 사용 가능

7) Distributed Database & Storage

​	\- 단일 데이터베이스 뿐만 아니라, 보다 탄력성 있고 확장성이 필요한 대규모의 데이터베이스 서비스 사용 고려 

\- Kubernetes에서는 스토리지 오케스트레이터로 Rook과 같은 스토리지 솔루션 세트 사용

8) Stream & Messaging

​	\- JSON-REST 방식 보다 더 높은 호환성이나 성능이 필요한 경우 범용 RPC 프레임워크인 gRPC 또는 NATS를 사용

​	\- CNCF 프로젝트의 NATS는 요청/응답, 게시/구독 및 부하 분산 대기열을 포함하는 다중 모달 메시징 시스템을 제공

9) Container Registry & Runtime

​	\- 컨테이너 생성을 위한 이미지 정보가 저장되어 있는 레포지토리의 모음

​	\- CNCF 프로젝트에서 OCI 스펙을 따르는 containerd 및 CRI-O 사용 가능

10) Software Distribution

​	\- 안전한 소프트웨어 배포

​	\- CNCF 프로젝트의 업데이트 프레임워크인 Notary 사용 가능

 

#### 3.1.2.3  Cloud Native TrailMap의 적용

- 클라우드 네이티브 애플리케이션을 위해 반드시 Cloud Native TrailMap을 따라야 하는 것은 아니다. 
- 어디까지나 참조사항으로, 각 단계에 필요한 서비스들은 벤더들의 제품을 선택하거나 직접 구현할 수 있다. 특히, Cloud Native TrailMap의 3단계 이후부터는 기업의 상황에 따라 선택해야 한다. 애플리케이션과 회사의 규모에 따라 달라져야 하며, 작고 간단한 애플리케이션에 Observability나 Service Mesh와 같은 기능은 필요하지 않을 수 있다.
- 기업에 적합한 클라우드 네이티브 애플리케이션 구축을 위해서 Cloud Native TrailMap 자체는 매우 훌륭한 지침이 될 수 있지만, 여기에는 “어떤 한 가지 기술이나 솔루션을 포함한 클라우드 네이티브”이라는 의미가 아니라, “자신에게 맞는 것을 지속적으로 구현해 나가는 것”이라는 의미로 해석해야 한다.





# 2. 클라우드 네이티브 애플리케이션

 CNCF가 제시한 클라우드 네이티브 참조 아키텍처를 바탕으로 애플리케이션 구축에 필요한 기술에 대해 소개하려고 한다.

## 2.1  마이크로서비스의 특징

- 일반적으로 하나의 클라우드 네이티브 애플리케이션은 다수의 마이크로서비스로 구성된다.

-  마이크로서비스 아키텍처는 기본적으로 마이크로서비스마다 고유한 프로그래밍 언어, 데이터베이스 및 스토리지를 가지고 있다. 

- 각 마이크로서비스가 가지는 서비스의 특성에 따라 프로그래밍 언어가 선택되고, 다른 마이크로서비스가 관리하는 데이터 베이스와 스토리지에 직접 액세스할 수 없도록 설계하기 때문에, 서비스간의 통신과 데이터베이스에 엑세스하기 위해서는 직접 엑세스하는 방식이 아닌 공개 API를 이용 하여 통신하는 것을 권장한다. 이러한 마이크로서비스의 특징을 정리하면 다음과 같다.

  ◾  분리된 프로세스: 개별 마이크로서비스는 별도의 프로세스에 의해 실행되어, 서비스간의 의존성을 작게 할 수 있다.

  ◾  API 통신: 마이크로서비스 구축을 위해 서로 다른 프로그래밍 언어를 이용하여 개발될 수 있으며, 각 마이크로서비스 간의 통신은 API를 통해 이뤄지게 된다.

  ◾  독립적인 배포: 각 서비스마다 별도의 개발 및 유지 관리 계획을 세울 수 있으며, 서비스의 규모를 작게 하여 프로그램의 복잡성을 줄여 개발 유지 보수에 필요한 비용을 절감할 수 있다.

- 애플리케이션의 신규 개발에 있어서, 반드시 마이크로서비스 아키텍처로 시작해야 한다는 것은 아니다. 전통적인 방식의 모놀리스 아키텍처 스타일로 애플리케이션을 개발하는 것이 효율적일 수도 있고, 서비스를 세분화 하여 마이크로서비스 아키텍처 스타일로 개발하는 것이 효율적일 수 있다. 또는, 초기 애플리케이션을 모놀리식 애플리케이션 방식으로 모듈화하고, 거기에 따른 서비스에 대한 문제 및 개선점이 요구될 때 해당 모듈을 마이크로서비스로 분할하는 방식으로 전환하는 등 사용자의 요구사항 및 도메인 모델에 따라, 설계 방식을 달리해야 한다.

- 마이크로서비스 아키텍처를 선택하기 전에 이러한 문제를 충분히 인식한 다음, 사용자 요구사항에 따른 도메인 설계와 서비스 경계를 구분해야하고, 그에 따른 시스템 구성을 해야 한다. 마이크로서비스에 대한 이러한 단점이나 복잡성에도 불구하고, 마이크로서비스 아키텍처는 기존의 단일 애플리케이션 개발 방식의 문제점 해결이나 고객의 새로운 요구사항, 애플리케이션의 개선 및 이슈 등에 따르게 대응할 수 있다는 장점으로 새로운 개발 아키텍처로써 빠르게 전파되고 있다.

 

## 2.2  클라우드 네이티브 애플리케이션 구축 시 고려 사항

- 마이크로서비스 아키텍처를 이용하여 애플리케이션을 구축할 경우에 고려해야 할 가장 중요한 점은 사용자의 요구사항에 따른 기능을 어떻게 분할하고 어떤 마이크로서비스 에 할당하느냐에 대한 것이다. 사용자의 요구사항에 따른 각 기능을 너무 세밀하게 분할하면 시스템의 오버헤드가 커지고, 반대로 마이크로 서비스를 너무 크게 분할하면 마이크로서비스의 장점을 충분히 사용할 수 없게 되며, 각 서비스에 대해 감시/모니터링 해야 할 대상이 늘어남에 따라 애플리케이션 운영에 대한 복잡성이 늘어나게 된다.

- 클라우드 네이티브 애플리케이션 구현을 위한 과정은 기업이나 조직에 따라 달라져야 한다. 애자일 개발 방식이나 IT 자동화를 지원하는 툴을 도입한다고 해서 클라우드 네이티브화되고, 서비스 접근 방식의 속도가 빨라지는 것이 아니다. 필요한 클라우드 네이티브의 기술과 특징을 살펴보고, 기업에 맞는 최선의 선택을 해야 한다. 클라우드 네이티브 애플리케이션을 구축하기 위해서는 다음과 같은 5가지 요소를 고려해 봐야 한다.

  1) 애플리케이션 설계: 구축하려는 서비스들의 사용자 요구사항에 대한 경계 설정과 마이크로 서비스로의 전환에 따른 설계

  2) API 설계: 표준화된 방법을 통한 내부 및 외부 리소스에 대한 액세스 방식에 대한 설계

  3) 운영 관리: 애플리케이션 관리를 위한 로그 및 모니터링 정보에 대한 관리

  4) DevOps: 개발에서부터 운영까지의 애플리케이션 라이프 사이클에 대한 자동화 빌드와 배포

  5) 테스트: 품질 보증을 위한 테스트

 

### 2.2.1  애플리케이션 설계

클라우드 네이티브 애플리케이션뿐만 아니라, 모든 애플리케이션의 가장 큰 요구 사항 중 하나는 속도에 대한 부분이다. 사용자(또는 고객)의 요구사항에 맞는 애플리케이션 기능을 빠르게 제공하고 고객의 에러 및 이슈에 대해 수정해야하고, 이를 다시 시스템 에 반영하는 과정을 지속적으로 반복해야 한다.

클라우드 네이티브 애플리케이션은, 비디오 스트리밍 제공 업체인 Netflix와 E-commerce 클라우드 서비스의 대표적인 회사인 아마존에서 시작된 마이크로 서비스라는 개발 방법으로 대표될 수 있다. 마이크로서비스는 애플리케이션을 구성 하는 서비스의 구조와 경계를 변경하여 개발 뿐만 아니라, 통합 및 테스트를 수행하는 부담을 줄이고, 실행 가능한 배포 모델의 단위를 작게 하였다. 전통적인 방식에서의 커다란 단일 실행 파일 대신 클라우드 네이티브에서의 애플리케이션은 마이크로서비스 단위로 애플리케이션을 구성하고, 해당 마이크로 서비스가 단일 애플리케이션과 같이 개별적으로 실행될 수 있도록, 기능적 구성 요소를 세분화하여 개발하고, 배포할 수 있도록 하였다. 이러한 마이크로서비스 아키텍처를 통해 애플리케이션의 다른 부분에는 영향을 주지 않고 개별적으로 나뉜 각 기능 구성 요소를 업데이트하고 배포함으로써, 기존의 모놀리식 아키텍처가 가지고 있던 많은 문제를 줄일 수 있게 되었다.

모든 마이크로서비스의 실행 파일은 개별적으로 작동하기 때문에 각 마이크로 서비스는 포함된 기능을 적합한 스케줄에 따라 독립적으로 업데이트될 수 있다. 예를 들어 하나의 마이크로서비스가 비즈니스 요구사항이 자주 변경되는 기능(예: 전자 상거래 에서 사용자 프로모션 제공 등)을 제공하는 경우, 마이크로 서비스는 자주 변경되지 않는 애플리케이션의 다른 부분에는 영향을 주지 않는 상태로 필요한 서비스에 대해 변경하고 독립적으로 배포할 수 있다. 또한, 마이크로서비스 방식의 개발 방식에서는 전체적인 오버 헤드가 줄어들기 때문에, 각 서비스에 대한 배포 시간을 단축시킬 수 있다. 마이크로서비스 아키텍처로 개발하게 되면 특정 기능과 관련된 서비스만 변경하기 때문에, 변경에 따른 시간과 리소스 낭비를 줄일 수 있게 된다. 뿐만 아니라, 검증에 관해서도 전체 애플리케이션의 기능을 검증해야 하는 것이 아니라, 특정 마이크로 서비스와 관련된 기능만 검증하면 되기 때문에, 서비스에 대한 테스트가 간소화되어, 더 자주 테스트하고, 더 자주 개선되고, 더 자주 배포할 수 있는 환경을 구축할 수 있게 된다.

마이크로서비스 아키텍처로 전환하기 위한 방법으로는, 애플리케이션의 전체 기능을 개별 서비스로 분할하는 방법(하향식)과 여러 개의 개별 마이크로서비스를 연결하여 완성된 서비스가 하나의 완전한 애플리케이션처럼 사용되는 방법(상향식)을 고려할 수 있다. 세분화된 마이크로서비스는 빠른 기능 반복 및 통합에 필요한 노력을 감소하게 하는 것이 가능하지만, 애플리케이션에 대한 모니터링과 같은 관리의 복잡성을 가져오기도 한다. 반대로, 단순화된 마이크로 서비스는 애플리케이션 모니터링 및 관리를 단순화할 수는 있지만, 집계나 상태 확인을 위해 여러 서비스간에 통합이 빈번하게 발생하여, 마이크로서비스의 장점을 제대로 살리지 못하는 경우도 있을 수 있다.

애플리케이션의 기능을 분할하기 위한 또 한 가지 방법으로 기본적인 서비스만을 위한 독립적인 마이크로서비스를 만드는 것을 고려해 볼 수 있다. 예를 들어 사용자 인증 및 권한에 관련된 기능은 일반적으로 다른 애플리케이션과 독립적이지만, 여러 애플리케이션에 걸쳐 자주 사용되기 때문에, 자체 마이크로서비스로 구축하는 것이 좋다.

 

### 2.2.2  API

마이크로서비스 아키텍처에서 서비스 경계로 구분된 각각의 서비스간의 데이터 교환 방법은 아키텍처 설계 시 가장 중요하게 고려해야 할 내용 중 한가지이다. 서비스를 요청하는 클라이언트는 또 다른 마이크로서비스나 브라우저, 스마트 디바이스와 같은 장치일 수 있으며, 애플리케이션은 이러한 다양한 사용자들의 요청에 대한 적절한 응답을 해야 한다. 가장 대표적으로 사용되는 데이터 포맷으로는 XML과 JSON이 있으며, 이러한 포맷을 사용하는 RESTful API는 서비스간의 통신을 위해 가장 일반적인 사용되는 통신 방식이다.

개념적으로 API는 매우 간단하지만 실제로 API를 사용하여 실행 가능한 연결 메커니즘으로 만들기 위해서는 다음의 요소가 필수적으로 포함 되어 있어야 한다.

◾  API 버전 관리

◾  서비스 제한

◾  Circuit Breaker

◾  데이터 캐싱

 

### 2.2.3  운영 설계

기존 환경의 시스템 운영에서의 가장 큰 문제 중 하나는 새로운 코드 릴리스를 실제 운영 환경(프로덕션)으로 옮길 때 발생하는 오버 헤드이다. 마이크로 서비스를 이용하게 되면 개발, 테스트, 운영 등으로 실행환경이 분할되어 있을 뿐만 아니라, 새로운 코드의 변경 사항도 서비스 단위로 분리되어 개발되고, 업데이트 되기 때문에, 변경 사항을 위한 빌드를 위해 전체 애플리케이션을 재배포 하지 않아도 된다. 또한 코드 변경을 이전 상태로 복귀하는 프로세스도 쉽게 구현할 수 있다.

대부분의 마이크로서비스 환경에는 각 마이크로서비스마다 기능에 대한 중복성이 있을 수 있다. 이것은 기존의 기능을 완전하게 종료하지 않더라도, 다른 마이크로서비스가  대체하여 실행할 수 있음을 의미한다. 새 코드를 실행한 다음, 새로운 기능을 점차적으로 테스트하기 위해, 일부 마이크로서비스만을 종료할 수 있다. 전체 마이크로서비스가 정상적으로 계속 작동하는 상태에서 부분적으로 각 서비스에 대한 업데이트를 수행할 수 있게 된다.

새로운 애플리케이션의 아키텍처에는 IT 조직이 마이크로서비스 기반의 애플리 케이션을 처리할 수 있는 새로운 모니터링 및 관리 시스템을 준비해야 한다. 마이크로 서비스로 구성된 전체 애플리케이션은 이전보다 더 많은 실행 파일이 실행될 수 있으며, 이에 따라 모니터링 및 관리 시스템은 더 많은 데이터 소스를 통합하고 운영 담당자가 이해할 수 있고 유용하게 사용할 수 있도록 관리 모니터링 도구가 준비되어 야 한다.

 

### 2.2.4  데브옵스(DevOps)

오늘날의 IT 시스템은 개발, 애플리케이션 구축, QA, 운영 등을 포함하여 애플리케이션 각 수명주기를 책임지는 조직이나 팀 등에 의해 개발 및 운영되고 있다.대부분의 IT 조직에서는 각 팀들 간에 내부 최적화에 중점을 둔 고유 한 프로세스를 가지고 있을 수 있다. 한 팀에서 다른 팀으로 프로젝트의 결과물이 전달되면, 각 팀은 새로운 실행 환경에 따른 완전히 새로운 애플리케이션의 실행 파일(결과물)을 만들어 버리는 경우도 있고, 작업의 결과물을 전달 받은 조직에서 기존에 추가된 작업에 대해 수정작업을 해야 하는 경우도 있다. 이러한 IT 구조는 빠른 배포 및 빈번한 업데이트가 필요한 IT 서비스의 생태계에서 매우 긴 배포 시간을 유발하고 결과적으로 사용자 요구사항의 반영이나 시스템의 개선을 더디게 하는 요인이 될 수 있다.

DevOps는 이러한 IT 팀 간의 장벽을 없애려는 시도이며, 수동 프로세스를 자동화로 대체하여 업무 개선 및 운영에 효율성을 가져오기 위한 방법론이다. DevOps에서의 목표는 개발자가 코드를 작성 또는 수정하는 시점과 코드를 프로덕션에 배치하는 시점 사이의 시간을 최대한 줄이는 것이다.

DevOps는 애플리케이션의 전체 수명주기에 걸쳐 각 작업의 소요 시간을 식별하여 프로세스를 적용하는 방법과 특정한 작업이나 그룹에서 작업 소요 시간이 오래 걸리는 부분을 파악하여 프로세스를 개선하는 방법으로 시작할 수 있다.

 

### 2.2.5  테스트

대부분의 IT 조직에서의 검증과 테스트 작업은 담당하는 QA 그룹은 직원 수가 적거나 리소스가 부족한 경우가 많기 때문에, 애플리케이션 기능이 올바르게 작동하는지에 대한 테스트를 위한 작업도 부분적이고 수동적인 기능 테스트 밖에 할 수 없는 경우가 많다. IT조직은 배포 직전까지 QA를 수행하는데, 이러한 문제점으로 인해 최종 애플리케이션을 재작업 하거나, 만족스럽지 못한 코드를 배포하는 경우도 종종 발생 한다. 이러한 방식은 비즈니스를 기능을 지원하는 부가적인 애플리케이션에는 수용될 수 있지만 완전한 비즈니스 애플리케이션을 위해서는 허락 될 수 없다.

애플리케이션의 품질은 나중에 해야할 일로 미루면 안 되는 매우 중요한 사항이다. QA 테스트는 개발 프로세스의 핵심 부분이어야 하며 프로세스가 초기에 수행되어 애플리케이션에서 발생하는 문제를 애플리케이션의 패닉 상태나 애플리케이션 중단을 유발하기 전에 식별하여 해결해야만 한다. 이를 위해서 애플리케이션 개발의 수명주기 초기에 테스트를 수행하면서 개발하는 TDD(Test Driven Development, 테스트 주도 개발)를 도입하기도 한다.

애플리케이션의 각 기능들의 테스트 코드에 대한 개발 책임은 새로운 기능을 작성하는 개발자가 처리해야 하며, 새 코드가 개발 완료 되는 즉시 테스트 코드가 호출될 수 있는 자동화된 테스트 실행 환경을 구축해야 한다. 개발자가 코드를 버전 컨트롤 시스템에 체크인 할 때, 코드 저장소에는 개발자가 작업한 코드 부분과 관련된 모든 기능 테스트를 자동으로 시작하는 시스템이 준비되어 있어야 한다.

기능 테스트가 개발자 중심으로 전환됨으로 인해 QA 그룹은 다음과 같은 중요한 세 가지 테스트에 집중할 수 있다.

◾  통합 테스트(Integration Test): 애플리케이션의 종단 간 테스트를 처리하며, 애플리케이션의 모든 부분을 테스트한다. 통합 테스트는 새로운 기능이 구현 될 때 새로운 코드가 실수로 기존 기능을 손상시키지 않는지 검증해 주며, 초기 코드 체크인시 이 테스트를 자동화하여 프로덕션에서 예기치 않은 오류를 방지할 수 있다. 통합 테스트 환경을 구현하려면 자동화된 테스트 기능, 전용 테스트 리소스 및 테스트 코드에 대한 개발 투자가 필요하다.

◾  고객 테스트(User Accepted Test): 애플리케이션은 해당 애플리케이션이 가장 많이 사용되는 사용자의 환경을 중심으로 테스트되어야 한다. 예를 들어 모바일 애플리케이션의 경우 가장 일반적이고 널리 사용되는 모든 모바일 디바이스에서 애플리케이션을 테스트하는 것이 중요하다. 많은 IT 조직은 테스트 목적으로

가능한 한 충분한 디바이스에서 테스트를 하려 하지만, 새로운 디바이스에 대한 모든 테스트를 하기에는 자원이 부족하기 때문에, 포괄적이고 많은 테스트를 지원하고, 충분한 리소스를 포함하는 테스트 전용 프레임워크를 사용한다.

◾  성능/부하 테스트(Stress Test): 기본적으로 클라우드 네이티브 애플리케이션은 불규칙적인 트래픽에 대해 리소스를 탄력적으로 제공해야 한다. 일부 기능은 많은 트래픽을 처리할 수 없거나 애플리케이션이 탄력적인 리소스를 사용하는 데에 적합하지 않게 설계되었기 때문에, 많은 애플리케이션에서 장애가 발생하거나 클라우드 환경에서는 성능이 저하될 수도 있다. 이러한 트래픽에 대한 문제는 자동스케일링(Auto Scaling) 기능으로 리소스의 확장 및 축소에 대한 동적인 대응이 가능해야하고, 탄력적인 리소스 제공에 대한 성능 및 부하(스트레스) 테스트를 거쳐, 애플리케이션의 장애 또는 성능 저하를 방지해야 한다.



## 2.3 애플리케이션 아키텍처

레이어드 아키텍처(Layered Architecture )에 대해 설명하고 최근의 마이크로서비스 설계자들이 마이크로서비스 내부구조를 유연하게 가져가기 위해 적용하고 있는 헥사고널 아키텍처(Hexagonal Architecture )와 클린 아키텍처(Clean Architecture)가 있다

### 2.3.1 레이어드 아키텍처

레이어드 아키텍처(계층 형 아키텍처:Layered Architecture)를 구성하는 레이어는 많은 사람들이 혼동하는 물리적인 티어(Tier)의 개념과 달리 논리적인 개념이다. 티어는 물리적인 장비, 서버 컴퓨터 등의 물리 층을 의미하고 레이어는 티어 내부의 논리적인 분할을 의미한다. 아래 그림과 같이 물리적인 서버 티어의 레이어(이하:계층)를 프레젠테이션(Presentation) , 비지니스 로직(Business Logic), 데이터 액세스(Data Access) 3개의 논리적인 계층으로 구분할 수 있다.

![티어와 레이어](.\assets\MSA_3.2.png)

계층은 설계자들이 복잡한 시스템을 분리할 때 흔히 사용하는 패턴 중 하나로 어플리케이션이 내부에서 처리하는 관심사를 논리적으로 구분한다. 다음은 마틴 파울러가 그의 책 ‘엔터프라이즈 애플리케이션 아키텍처 패턴(Enterprise Application Architecture Pattern)’ 에서 구분한 레이어드 아키텍처 패턴 전형적인 유형이다. 아키텍트가 의도하는 방향에 따라 여러가지로 구분 가능하나 일반적으로 **프레젠테이션, 비즈니스 로직, 데이터 액세스**의 3계층으로 구분하는 경향이 일반적이다.

![전통적인3계층 아키텍처](.\assets\MSA_3.3.png)

프레젠테이션 층의 관심사는 화면 표현 및 전환 처리이고 비즈니스 로직층의 관심사는 비즈니스 개념 및 규칙, 흐름 제어이며 데이터 액세스 층의 관심사는 데이터 처리이다.

레이어드 아키텍처는 레이어 간 응집성을 높이고 의존도를 낮추기 위해 몇 가지의 규칙들을 가지고 있는데 다음과 같다.

- 상위 계층이 하위 계층을 호출하는 단 방향성을 유지한다.
- 상위 계층은 하위의 여러 계층을 모두 알 필요 없이 바로 밑의 근접 계층만 활용한다.
- 상위 계층이 하위 계층에 영향을 받지 않게 구성해야 한다.
- 하위 계층은 자신을 사용하는 상위 계층을 알지 못하게 구성해야 한다.
- 계층 간의 호출은 인터페이스를 통해 호출하는 것이 바람직하다. (구현 클래스에 직접 의존하지 않음으로써 약한 결합을 유지해야 한다.)

![레이어드 아키텍처 규칙](.\assets\MSA_3.4.png)

특히 인터페이스를 통한 의존성 분리는 인터페이스를 구현하는 구현체를 다양하게 해주는 다형성을 추구함으로써 제어 흐름을 간접적으로 전환하게 해준다. 아래 그림을 보면 상위 계층은 직접적으로 하위 계층을 호출하지 않고 추상적인 인터페이스를 의존한다. 이럴 경우 하위레이어는 추상적 인터페이스를 만족하는 다양한 방식의 구현체를 선택적으로 적용할 수 있다.

![인터페이스 호출을 통한 다형성 추구](.\assets\MSA_3.5.png)

이러한 방식은 로버트 C 마틴이 정의한 객체지향의 원칙의 **의존성 역전 원칙(Dependency Inversion Principle)** 을 만족하는 것처럼 보인다. 의존성 역전의 원칙은 ‘유연성이 극대화된 시스템’이란 소스 코드 의존성이 추상에 의존하며 구체에는 의존하지 않아야 한다’라고 말하기 때문이다.

그렇지만 **개방 폐쇄의 원칙(OCP: Open-Closed Principle)** 까지 살펴본다면 문제가 있다. OCP는 소프트웨어 개체는 확장에는 열려 있어야 하고 변경에는 닫혀 있어야 한다는 원칙이다. 이는 개체의 행위는 확장할 수 있어야 하지만 이때 개체를 변경해서는 안된다는 말이다.

그러나 계층 방식은 인터페이스를 통해 의존성을 낮춘다 해도, 일반적으로 추상적인 인터페이스가 각 계층의 제일 상위에 위치하는 구조로 제어의 흐름(Flow of Control)이 상위에서 하위로 흐르게 되고 이에 따른 소스코드의 의존성은 제어의 흐름을 따르게 된다. 따라서 하위 계층의 유형이 추가되어 확장될 때 닫혀 있어야 할 상위계층이 의존을 받을 수 밖에 없다.

프레젠테이션, 비지니스로직, 데이터 액세스 의 3계층으로 살펴보면 제일 마지막에 있는 데이터 액세스 계층이 변경되었을 때 비지니스로직 계층이 변경되면 안되는데 위의 그림을 보면 비지니스로직 계층의 클래스가 데이터 액세스 계층에 존재하는 인터페이스를 의존하기 때문에 데이터 계층의 영향을 받게 된다.

문제는 데이터 엑세스 인터페이스 위치이다. 데이터 엑세스 인터페이스는 데이터 엑세스 계층에 존재한다. 일면 당연해 보이지만 그런 방식은 항상 하위 계층에 의존해야 한다. 그렇지만 어플리케이션에서는 비지니스 로직이 핵심이라고 하였다. 즉 문제 중심 영역이다. 그렇기 때문에 비지니스 로직을 보통 고수준 영역이라고 하고 프레젠테이션 계층 및 데이터 액세스 계층을 저수준 영역이라고 한다. 고수준 영역은 문제 중심 영역이므로 보호를 받아야 하고 따라서 저수준 영역의 변경, 확장에 영향을 받지 않아야 한다. 그러나 위에서처럼 일반적인 레이어드 아키텍처의 규칙만을 따르면 고수준 영역이 저수준영역에 의존하게 되고 영향을 받게 된다.

여기서 의존성의 역전 원칙(DIP)적용의 필요성이 생긴다. DIP는 데이터 액세스 계층에서 정의한 인터페이스의 위치를 경계 넘어 비지니스로직 계층으로 이동시킨다. 그러면 데이터 액세스 계층의 구현체는 비지니스 로직의 계층의 인터페이스를 바라볼 수 밖에 없다.

즉 데이터 액세스 계층이 구현해야 할 인터페이스를 아래 그림과 같이 보다 고수준의 비지니스 로직 계층에서 정의하게 함으로써 기존에 위에서 아래로 흘렀던 의존관계를 역전시키고 고수준이 저수준의 변경에 영향을 받지 않도록 해 주는 것이다.

![의존관계 역전의 적용](https://engineering-skcc.github.io/assets/images/msa/MSA_3.6.png)

### 2.3.3 헥사고날 아키텍처

허나 레이어드 아키텍처에 DIP를 적용해도 한계가 존재한다. 프레젠테이션 계층 와 데이터 액세스 계층을 보통 저수준 계층으로 정의한다고 했는데 현대 어플리케이션의 활용은 이러한 2가지 계층 말고도 다양한 인터페이스를 필요로 한다. 즉 어플리케이션을 호출하는 시스템의 유형과 어플리케이션과 상호작용하는 다양한 저장소가 존재한다. **헥사고날 아키텍처(육각형, Hexagonal Architecture)** 는 이러한 문제점을 해결할 수 있다.

헥사고날 아키텍처는 엘리아스 쿡번(Alistair Cockburn )이 제시한 아키텍처로 **‘ 포트 엔 어댑터 아키텍처(ports and adapters architecture)’** 라고도 부른다. 아래 그림을 통해 간단히 살펴보면 고수준의 비지니스 로직을 표현하는 내부 영역과 인터페이스 처리를 담당하는 저수준의 외부 영역으로 나눈다.

**내부 영역** 은 순수한 비지니스로직을 표현하는 기술 독립적인 영역이다.그리고 외부영역과 연계되는 포트를 가지고 있다.

**외부 영역** 은 외부에서 들어오는 요청을 처리하는 인 바운드 어댑터(Inbound Adapter)와 비지니스 로직에 의해 호출되어 외부와 연계되는 아웃바운드(Outbound Adapter) 어댑터로 구성된다.

헥사고널의 가장 큰 특징은 고수준의 내부 영역이 이런 어댑터에 전혀 의존하지 않게 한다는 것이다. 그것을 가능하게 하는 것이 내부 영역에 구성되는 **포트**이다. 포트는 인 바운드 / 아웃 바운드 포트로 구분되는데, 인 바운드 포트는 내부 영역 사용을 위해 표출된 API이며, 외부 영역의 인 바운드 어댑터가 호출한다. 아웃바운드 포트는 내부 영역이 외부를 호출하는 방법을 정의한다. 여기서 DIP 원칙과 같이 아웃바운드 포트가 외부의 아웃바운드 어댑터를 호출하여 외부 시스템과 연계하는 것이 아니라 아웃바운드 어댑터가 아웃바운드 포트에 의존하여 구현된다.

외부영역에 존재하는 **어댑터** 의 종류를 살펴보면 인 바운드 어댑터는 REST API를 발행하는 컨트롤러, 웹 페이지를 구성하는 스프링 MVC 컨트롤러, 커맨드 핸들러, 이벤트 메시지 구독 핸들러 등이 될 수 있고, 아웃바운드 어댑터는 데이터 액세스 처리를 담당하는 DAO , 이벤트 메시지를 발행하는 클래스, 외부 서비스를 호출하는 프록시 등이 될 수 있다.

![헥사고날 아키텍처의 포트 와 어답터](https://engineering-skcc.github.io/assets/images/msa/MSA_3.7.png)

### 2.3.4 클린 아키텍처

클린 아키텍처(Clean Architecture)는 로버트 C 마틴이 제안한 아키텍처로 헥사고널 아키텍처의 아이디어와 매우 유사하다. 앞서 언급한 것처럼 로버트는 소프트웨어는 행위적/구조적 두 종류의 가치를 가지며 구조적 가치가 더 중요하다고 말한다. 왜냐하면 소프트웨어를 부드럽게 만드는 것이 구조적 가치이기 때문이다. 그렇다면 소프트웨어를 부드럽게 유지하는 방법은 무엇일까? 즉 구조 중에 선택할 수 있는 것을 가능한 오랫동안 열어두는 것이다. 특히 열어둬야 할 선택사항은 바로 중요치 않은 세부사항이다.

마틴은 아래 그림같이 클린 아키텍처를 여러 겹의 둘러싸인 영역으로 표현하며 엔티티, 유스케이스, 그 외 세부사항으로 구분한다.

제일 중앙에는 **엔티티** 가 있다. 업무 규칙은 사업적으로 수익을 얻거나 비용을 줄일 수 있는 규칙 또는 절차를 말한다. 이런 업무 규칙은 수동으로 처리할 수 있지만 시스템으로도 자동화 할 수 있다. 예를 들면 쇼핑몰의 물건을 사고 파는 규칙, 은행의 이자 계산 규칙 ,도서대여 시스템의 대여/반납 규칙 등 모든 시스템에는 해당 도메인의 업무를 규정하는 핵심 업무 규칙들이 존재한다. 그리고 핵심업무규칙은 보통 데이터를 요구한다. 따라서 핵심 규칙과 데이터는 본질적으로 결합되어 있기 때문에 객체로 쉽게 만들 수 있다. 이런 유형을 ‘엔티티’ 객체 라 한다.

그 다음 엔티티를 감싸는 객체는 **유스케이스**이다. 유스케이스는 자동화된 시스템을 사용하는 처리 절차를 기술한다. 유스케이스는 애플리케이션에 특화된 업무 규칙을 표현하며 엔티티 내부의 핵심 업무 규칙을 호출하며 시스템을 사용하는 흐름을 담는다. 이때 엔티티 같은 고수준은 저수준의 유스케이스를 알게 하면 안된다.
엔티티는 간단한 객체 여야 하며 프레임워크 데이터베이스 또는 여타 복잡한 것에 의존되어서는 안되고 유스케이스 객체을 통해서만 엔티티를 조작해야 한다.

그리고 그 다음 유스케이스를 감싸고 있는 모든 영역들은 **세부사항** 이다. 세부사항은 입출력 장치, 저장소, 웹 시스템, 서버, 프레임워크, 통신 프로토콜이 될 수 있으며, 세부사항과 유스케이스 관계를 의존관계 역전의 법칙을 이용하여 플러그인처럼 유연하게 처리해야 한다. 이런 명확한 결합의 분리는 테스트 성 및 개발 독립성, 배포 독립성 강화할 수 있다.

![클린 아키텍처](https://engineering-skcc.github.io/assets/images/msa/MSA_3.8.png)





--------------------











  

# 3. Spring 



## 3.1. 스프링(Spring)이란?

### 3.1.1 스프링의 개념

![image](.\assets\spring_logo.png)

Spring은 무엇일까요? 스프링은 **자바 기반의 웹 어플리케이션을 만들 수 있는 프레임워크**입니다. spring.io 사이트에서 확인하면 **스프링 프레임워크는 현대 자바 기반의 엔터프라이즈 어플리케이션을 위한 프로그래밍 및 Configuration Model 제공한다**라고 언급하고 있습니다.

Python을 이용한 Django, Ruby를 이용한 Ruby on Rails, Javascript를 이용한 Node.js 기반의 웹 서버 개발과 같이 Java 개발자들은 Spring을 사용하여 웹 서비스를 만들 수 있습니다. Spring 은 수많은 국내 기업과 해외 기업에서 매우 많은 서비스를 만들 때 사용되고 있습니다. 자바 백엔드 개발자는 웹 애플리케이션을 개발할 때, 대부분 스프링을 사용한다고 합니다. 스프링의 구조는 아래와 같은 구조로 이루어져있습니다.

![image](https://melonicedlatte.com/assets/images/2021_3Q/spring_architect.png)





### 3.1.2 스프링의 특징

Spring의 특징들은 아래와 같습니다.

- Spring은 자바 객체와 라이브러리들을 관리해주며, 톰캣과 같은 WAS 가 내장되어 있어 자바 웹 어플리케이션을 구동할 수 있습니다.

- Spring은 경량 컨테이너로 자바 객체를 직접 Spring 안에서 관리합니다. 객체의 생성 및 소멸과 같은 생명 주기(Life cycle)을 관리하며, Spring 컨테이너에서 필요한 객체를 가져와 사용합니다.

- Spring의 가장 큰 특징으로 IOC와 DI 가 많이 언급됩니다. IOC와 DI의 간단한 개념은 아래와 같습니다.

  - ```plaintext
  제어의 역전 (IOC, Inversion Of Control)
    ```

    - 일반적으로 처음에 배우는 자바 프로그램에서는 **각 객체들이 프로그램의 흐름을 결정하고 각 객체를 직접 생성하고 조작하는 작업(객체를 직접 생성하여 메소드 호출)을 했습니다**. 즉, 모든 작업을 사용자가 제어하는 구조였습니다. 예를 들어 A 객체에서 B 객체에 있는 메소드를 사용하고 싶으면, B 객체를 직접 A 객체 내에서 생성하고 메소드를 호출합니다.
  - 하지만 **IOC가 적용된 경우, 객체의 생성을 특별한 관리 위임 주체에게 맡깁니다.** 이 경우 **사용자는 객체를 직접 생성하지 않고, 객체의 생명주기를 컨트롤하는 주체는 다른 주체**가 됩니다. 즉, 사용자의 제어권을 다른 주체에게 넘기는 것을 IOC(제어의 역전) 라고 합니다.
    
  - 요약하면 Spring의 Ioc란 `클래스 내부의 객체 생성 -> 의존성 객체의 메소드 호출`이 아닌, `스프링에게 제어를 위임하여 스프링이 만든 객체를 주입 -> 의존성 객체의 메소드 호출` 구조입니다. 스프링에서는 모든 의존성 객체를 스프링이 실행될때 만들어주고 필요한 곳에 주입해줍니다.
    
  - ```plaintext
  의존성 주입 (DI, Dependency Injection)
    ```
  
    - 어떤 객체(B)를 사용하는 주체(A)가 객체(B)를 직접 생성하는게 아니라 **객체를 외부(Spring)에서 생성해서 사용하려는 주체 객체(A)에 주입시켜주는 방식**입니다. 사용하는 주체(A)가 사용하려는 객체(B)를 직접 생성하는 경우 의존성(변경사항이 있는 경우 서로에게 영향을 많이 준다)이 높아집니다. 하지만, 외부(Spring)에서 직접 생성하여 관리하는 경우에는 A와 B의 의존성이 줄어듭니다.



## 3.2. Spring Boot란

![image](.\assets\spring_boot_logo.png)

`스프링 부트(Spring Boot)`는 **스프링(Spring)을 더 쉽게 이용하기 위한 도구**라고 볼 수 있습니다. 스프링 이용하여 개발을 할 때, 이것저것 세팅을 해야 될 요소들이 많습니다. 여러가지를 세팅해야되는 진입 장벽이 존재하여 Spring 을 처음 배우려는 사람들은 중도에 그만두는 경우가 많다고 합니다. Spring Boot는 매우 간단하게 프로젝트를 설정할 수 있게 하여, Spring 개발을 조금 더 쉽게 만들어주는 역할을 하고 있습니다.

![image](.\assets\spring_boot2.png)

위의 구조에서 나온 것과 같이 User는 스프링을 사용하기 위해서 이것저것 다양한 설정을 직접 해줘야된다는 문제점이 있습니다. 개발자가 실행환경이나 의존성 관리 등의 인프라 관련 등에 쓰는 에너지가 소요됩니다. 프로그래밍을 하는 데 있어 매우 중요한 **비즈니스를 만들기 위한 프로그래밍**에 조금 더 에너지를 투입할 수 있게 Spring의 많은 부분을 자동화하였고, 많은 개발자들이 현재 Spring Boot을 이용하여 개발을 진행하고 있습니다.





### 3.2.3 PSA(Portable Service Abstraction)란?

**Spring은 Spring Triangle이라고 부르는 핵심 3대요소를 제공해준다. 이는 각각 IoC , AOP , PSA를 일컫는다.**

![](https://blog.kakaocdn.net/dn/lWkuv/btq9MEmLHyN/q6A6PnOdfE6L5AwdXjaOl0/img.png)



PSA란 **환경의 변화와 관계없이 일관된 방식의 기술로의 접근 환경을 제공하는 추상화 구조**를 말합니다**.**

이는 POJO 원칙을 철저히 따른 Spring의 기능으로 Spring에서 동작할 수 있는Library들은

POJO원칙을 지키게끔 PSA형태의 추상화가 되어있음을 의미합니다.

> #### "잘 만든 인터페이스 하나가 열 클래스 부럽지 않다"
>

PSA가 적용된 코드라면 나의 코드가 바뀌지 않고, 다른 기술로 간편하게 바꿀 수 있도록 확장성이 좋고, 기술에 특화되어 있지 않는 코드를 의미합니다.

Spring은 **Spring Web MVC, Spring Transaction, Spring Cache 등의 다양한 PSA를 제공**합니다.



#### 3.2.3.1 Spring Web MVC

**일반적인 서블릿의 형태**

> Servlet을 사용하려면 HttpServlet을 상속받고 doGet(), doPost() 등 오버라이딩하여 사용해야 한다.

```java
public class CocoServlet extends HttpServlet {
 
	// GET
	@Override
	protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
		super.doGet(req, resp);
	}
	
	// POST
	@Override
	protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
		super.doPost(req, resp);
	}
}
```

**Spring Web MVC의 형태**

```java
@Controller
class OwnerController {
 
 do something..
 
@GetMapping("/owners/new")
@LogExecutionTime
public String initCreationForm(Map<String, Object> model) {
	Owner owner = new Owner();
	model.put("owner", owner);
	return VIEWS_OWNER_CREATE_OR_UPDATE_FORM;
}
 
@PostMapping("/owners/new")
@LogExecutionTime
public String processCreationForm(@Valid Owner owner, BindingResult result) {
	if (result.hasErrors()) {
		return VIEWS_OWNER_CREATE_OR_UPDATE_FORM;
	}
	else {
		this.owners.save(owner);
		return "redirect:/owners/" + owner.getId();
	}
}
 
do something..
 
} // end OwnerController
```

일반 클래스에 **@Controller** 어노테이션을 사용하면 **요청을 매핑할 수 있는 컨트롤러 역할을 수행하는 클래스**가 됩니다.

그 클래스에서는 **@GetMapping**과 **@PostMapping** 어노테이션을 사용해서 요청을 매핑할 수 있습니다.

- 서블릿을 Low level 로 개발하지 않고도, Spring Web MVC를 사용하면 이렇게 서블릿을 간편하게 개발할 수 있습니다. 그 이유는 뒷단에 spring이 제공해주는 여러 기능들이 숨겨져 있기 때문입니다.
- 즉, HttpServlet을 상속받고 **doGet(), doPost()**를 구현하는 등의 작업을 하지 않아도 되는 것입니다.

**Service Abstraction(서비스 추상화)의 목적 중 하나가 이러한 편의성을 제공하는 것입니다.**

- 또한, Spring Web MVC는 코드를 거의 그대로 둔 상태에서 톰캣이 아닌 다른 서버로 실행하는 것도 가능합니다.
  - 프로젝트의 spring-boot-starter-web 의존성 대신 spring-boot-starter-webflux 의존성을 받도록 바꿔주기만 하면 **Tomcat이 아닌 netty 기반으로 실행하게 할 수 있습니다.**

이렇게 Spring Web MVC는 @Controller, @RequestMapping 과 같은 어노테이션과 뒷단의 여러가지 복잡한 인터페이스들

그리고 기술들을 기반으로 하여 사용자가 **기존 코드를 거의 변경하지 않고**, 웹 기술 스택을 간편하게 바꿀 수 있도록 해줍니다.



#### 3.2.3.2  Spring Transaction

Low level로 트랜잭션 처리를 하는 간단한 예제 코드를 보겠습니다.

```java
 try (Connection conn = DriverManager.getConnection(
             "jdbc:coco://127.0.0.1:5432/test", "coco", "password");
             Statement statement = conn.createStatement();
             ) {
             
             //start transaction block
             conn.setAutoCommit(false); //default true
             
             String SQL = "INSERT INTO Employees " +
             			  "VALUES (101, 20, 'Rita', 'Tez')";
             stmt.executeUpdate(SQL);
             
             String SQL = "INSERTED INT Employees " +
             			  "VALUES (107, 22, 'Kita', 'Tez')";
             stmt.executeUpdate(SQL);
             
             // end transaction block, commit changes
             conn.commit();
             
             // good practice to set it back to default true
             conn.setAutoCommit(true);
             
             } catch(SQLException e) {
             	
                System.out.println(e.getMessage());
                conn.rollback();
             }
```

conn.setAutoCommit(false);을 하여 자동커밋을 막아주고, 오류 없이 진행된다면 conn.commit();으로 커밋 될 것 입니다.

하지만, 2번째 SQL문에 INSERTED INT 의 오타로 인해 커밋 되지 않고 catch문으로 가게되어

conn.rollback();으로 롤백 하는 코드입니다.

위의 코드와 같이 Low level로 트랜잭션 처리를 하려면 명시적으로 setAutoCommit()과 **commit(), rollback()**을 호출해야 합니다.

하지만 Spring이 제공하는 **@Transactional** 어노테이션을 사용하면 단순하게 메소드에 어노테이션을 붙여줌으로써트랜잭션 처리가 간단하게 이루어집니다.

```java
@Transactional(readOnly = true)
Employees findById(Integer id);
```

이 또한 PSA로써 다양한 기술 스택으로 구현체를 바꿀 수 있습니다.

예를들어, JDBC를 사용하는 DatasourceTransactionManager, JPA를 사용하는 JpaTransactionManager,

Hibernate를 사용하는 HibernateTransactionManager를 유연하게 바꿔서 사용할 수 있습니다. 

즉, **기존 코드는 변경하지 않은 채로 트랜잭션을 실제로 처리하는 구현체를 사용 기술에 따라 바꿀 수 있는 것**입니다.



#### 3.2.3.3 Spring Cache

Cache도 마찬가지로 JCacheManager, ConcurrentMapCacheManager, EhCacheCacheManager와 같은

여러가지 구현체를 사용할 수 있습니다.

```java
@Transactional
@Cacheable("users")
List<User> findAllUser();
```

사용자는 **@Cacheable** 어노테이션을 붙여줌으로써 구현체를 크게 신경쓰지 않아도 필요에 따라 바꿔 쓸 수 있습니다.

Spring은 이렇게 **특정 기술에 직접적 영향을 받지 않게끔 객체를 POJO 기반으로 한번씩 더 추상화한 Layer를 갖고 있으며,**

**이를통해 일관성있는 Service Abstraction(서비스 추상화)를 만들어 냅니다.**

덕분에 코드는 더 견고해지고 기술이 바뀌어도 유연하게 대처할 수 있게 됩니다.



### 3.2.4 Spring Boot Auto Configuration 

Spring Boot에서 제공하는 auto configuration을 설정하는 방법과 그 원리에 대해서 간략히 설명합니다.https://sda.dveamer.com/fullstars.html#partner=AF7892314)

Spring Boot는 Spring과 마찬가지로 component-scan을 통해 component들을 찾고 bean 생성을 진행합니다. 그 과정에서 우리가 설정한 bean들이 생성됩니다. 예를들면, @Controller, @RestController, @Service, @Repository 그리고 @Configuration에 등록한 @Bean 과 같은 설정들이죠. 그리고 그 과정에서 Spring Boot에서 미리 작성해둔 auto configuration에 의해 추가적인 bean들도 함께 생성됩니다.

Spring에서는 ThreadPoolTaskExecutor를 사용하기 위해서는 우리가 해당 bean을 등록해야했지만 Spring Boot에서는 등록하지 않아도 해당 bean이 자동으로 생성되기 때문에 사용할 수 있게됩니다.

#### 3.2.4.1 @EnableAutoConfiguration

@EnableAutoConfiguration은 auto configuration 기능을 사용하겠다는 설정입니다. @EnableAutoConfiguration을 설정하지 않는다면 auto configuration 을 사용하지 못하게 됩니다. 일반적으로 아래와 같이 @ComponentScan과 함께 사용됩니다.

```
package com.dveamer.sample

@SpringBootConfiguration
@ComponentScan("com.dveamer.sample")
@EnableAutoConfiguration
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
```

@ComponentScan에 입력된 com.dveamer.sample 값은 component scan를 시작할 패키지 위치입니다. com.dveamer.sample 하위 모든 패키지를 component scan 범위로 잡겠다는 설정입니다. package 위치를 입력하지 않는다면 com.dveamer.sample.Application이 놓여진 패키지(com.dveamer.sample)가 기본 값으로 사용됩니다. 여러 패키지 위치를 scan 대상으로 설정하는 것도 가능합니다.

글의 시작점에서 설명했듯이 component scan을 통해서 모은 component들의 정보와 Spring Boot가 spring.factories 파일에 사전에 정의한 AutoConfiguration 내용에 의해 bean 생성이 진행됩니다.



#### 3.2.4.5 Auto Configuration Filters & Conditions

Spring Boot가 미리 정의해둔 AutoConfiguration 정보는 `spring-boot-autoconfigure/META-INF/spring.factories`에서 혹은 [spring.factories](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/resources/META-INF/spring.factories)에서 확인 가능합니다.

`org.springframework.boot.autoconfigure.EnableAutoConfiguration`에 상당히 많은 AutoConfigruation이 등록되어있는 것을 확인할 수 있습니다.

```
...(생략)

# Auto Configure
org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\
org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\
org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\
org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\
org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\
org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\
org.springframework.boot.autoconfigure.cloud.CloudServiceConnectorsAutoConfiguration,\
org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\
org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\
org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\
org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\
org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\
org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\
org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveDataAutoConfiguration,\
...(생략)
```

각 AutoConfigruation들은 필요한 상황에만 자신이 실행될 수 있도록 @Conditional, @Condition과 같은 annotation들로 설정이 되어있습니다. 그 annotation 을 기반으로 필터링이 먼저 이뤄지고 필터링되지 않은 AutoConfigruation을 가지고 작업이 진행됩니다.

@Condition, @Conditional 은 Sprig 4.0부터 추가된 annotation이고 Spring Boot auto configuration 과정에서 사용되는 또 다른 annotation들도 [autoconfigure-condition](https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/autoconfigure/condition/)에서 확인 가능합니다.

또한 [@Profile](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/context/annotation/Profile.html), [@Lazy](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/context/annotation/Lazy.html)와 같은 Spring에서 제공하는 다른 annotation들도 Spring Boot auto configuration에 활용됩니다.



#### 3.2.4.6 Auto Configuration Import Filters

Spring Boot는 [spring.factories](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/resources/META-INF/spring.factories) 정보를 가지고 auto configruation을 진행합니다.

그리고 그 내용 중에 AutoConfigurationImportFilter 관련 설정이 있으며 아래와 같은 3개의 필터가 적용 된 것을 확인할 수 있습니다.

```properties
spring.factories
...(생략)
# Auto Configuration Import Filters
org.springframework.boot.autoconfigure.AutoConfigurationImportFilter=\
org.springframework.boot.autoconfigure.condition.OnBeanCondition,\
org.springframework.boot.autoconfigure.condition.OnClassCondition,\
org.springframework.boot.autoconfigure.condition.OnWebApplicationCondition

...(생략)
```

해당 필터들은 각 AutoConfiguration이 가진 @Conditional을 가지고 조건 만족여부를 체크 합니다. 그리고 조건이 맞지 않을 경우 해당 AutoConfiguration이 동작하지 않도록 제외 시키는 역할을 수행합니다.

- [org.springframework.boot.autoconfigure.condition.OnBeanCondition](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/condition/OnBeanCondition.java)

  특정 bean들의 존재유무에 대해서 다루는 필터입니다.

  대상 : @ConditionalOnBean, @ConditionalOnMissingBean, @ConditionalOnSingleCandidate

- [org.springframework.boot.autoconfigure.condition.OnClassCondition](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/condition/OnClassCondition.java)

  특정 class들의 존재유무에 대해서 다루는 필터입니다.

  대상 : @ConditionalOnClass, @ConditionalOnMissingClass

- org.springframework.boot.autoconfigure.condition.OnWebApplicationCondition](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/condition/OnWebApplicationCondition.java)

  WebApplicationContext의 존재유무에 대해서 다루는 필터입니다.

  대상 : @ConditionalOnWebApplication, @ConditionalOnNotWebApplication

  

#### 3.2.4.7 @ConditionalOnMissingBean

[@ConditionalOnMissingBean](https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/autoconfigure/condition/ConditionalOnMissingBean.html)은 특정 bean이 사전에 생성되지 않은 경우 조건이 만족됩니다. @Bean과 함께 사용된다면 이미 생성된 bean이 없을 때 해당 bean을 생성한다는 의미로 보시면 됩니다.

우리가 특정 bean을 생성하도록 설정해놨다면, 일반적으로 AutoConfiguration의 bean생성 순서가 마지막에 오도록 AutoConfiguration이 잘 짜여져있기 때문에 우리가 설정한 bean이 먼저 생성되고 해당 AutoConfiguration은 필터링 되어 중복생성되는 상황을 막습니다. 우리가 해당 bean을 설정하지 않았다면 AutoConfiguration에서는 해당 bean을 자동 생성하게 됩니다.

ThreadPoolTaskExecutor bean을 생성하는 [TaskExecutionAutoConfiguration.java](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/task/TaskExecutionAutoConfiguration.java)를 예로 들어보겠습니다.

```java
TaskExecutionAutoConfiguration.java
...(생략)
@Configuration(proxyBeanMethods = false)
public class TaskExecutionAutoConfiguration {

    /**
     * Bean name of the application {@link TaskExecutor}.
     */
    public static final String APPLICATION_TASK_EXECUTOR_BEAN_NAME = "applicationTaskExecutor";

    ...(생략)

    @Lazy
    @Bean(name = { APPLICATION_TASK_EXECUTOR_BEAN_NAME,
        AsyncAnnotationBeanPostProcessor.DEFAULT_TASK_EXECUTOR_BEAN_NAME })
    @ConditionalOnMissingBean(Executor.class)
    public ThreadPoolTaskExecutor applicationTaskExecutor(TaskExecutorBuilder builder) {
        return builder.build();
    }

}
```

@Lazy가 걸려있기 때문에 Spring Boot 기동시에 생성되지 않고 ThreadPoolTaskExecutor가 필요한 상황에서 bean이 생성이 요청됩니다. Executor.class와 같은 class type인 bean이 이미 생성되지 않은 경우에 @ConditionalOnMissingBean 조건이 만족되고 bean생성이 진행됩니다. 즉, 우리가 아래와 같은 Executor bean을 생성하는 설정을 해뒀다면 우리가 설정한 bean이 생성되고 TaskExecutionAutoConfiguration 에 의해서는 bean생성이 이뤄지지 않습니다. 반대로 우리가 Executor bean 등록을 설정하지 않았더라도 필요한 상황이되면 해당 bean이 생성되게 됩니다.

```java
CustomizedAsyncConfig.java
...(생략)

@Configuration
public class CustomizedAsyncConfig {

    @Bean(name = "threadPoolTaskExecutor")
    public Executor threadPoolTaskExecutor() {
        ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor();
        taskExecutor.setCorePoolSize(3);
        taskExecutor.setMaxPoolSize(30);
        taskExecutor.setQueueCapacity(10);
        taskExecutor.setThreadNamePrefix("Executor-");
        taskExecutor.initialize();
        return taskExecutor;
    }
}
```



#### 5.2.4.8 @ConditionalOnBean

[@ConditionalOnBean](https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/autoconfigure/condition/ConditionalOnBean.html)은 특정 bean이 이미 생성되어있는 경우에만 조건이 만족됩니다. 작업을 위해 필수적으로 필요한 bean이 미리 생성되어있는지 체크할 때 사용할 수 있습니다.

예를들어, JdbcTemplate를 생성하기 위해서는 DataSource가 필요합니다. 아래의 JdbcTemplate bean 생성 설정은 @ConditionalOnBean이 함께 사용되어 dataSource라고 정의된 bean이 존재할 때만 JdbcTemplate bean을 생성합니다. 만약에 dataSource가 존재하지 않는다면 JdbcTemplate을 만들 수도 없을 뿐더러 만들 필요가 없기 때문에 auto configuration 과정에서 JdbcTemplate을 bean 생성을 진행하지 않습니다.

```java
    @Bean 
    @ConditionalOnBean(name={"dataSource"}) 
    public JdbcTemplate jdbcTemplate(DataSource dataSource) {
        returnnew JdbcTemplate(dataSource); 
    }
```

참고로, 실제 [JdbcTemplateAutoConfiguration.java](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/JdbcTemplateAutoConfiguration.java)은 @ConditionalOnBean을 사용하지는 않습니다.



#### 3.2.4.9 @ConditionalOnClass

[@ConditionalOnClass](https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/autoconfigure/condition/ConditionalOnClass.html)은 classpath에 특정 class가 존재할 때만 조건이 만족됩니다. 작업을 위해 필수적으로 필요한 의존성이 등록되어있는지 체크할 때 사용할 수 있습니다.

[H2ConsoleAutoConfiguration.java](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/h2/H2ConsoleAutoConfiguration.java)을 예로들어 좀 더 자세히 살펴보겠습니다. 브라우저에서 접근 가능한 H2 DB 콘솔 화면을 자동으로 구성하는 내용입니다.

```java
H2ConsoleAutoConfiguration.java
package org.springframework.boot.autoconfigure.h2;

...(생략)

@Configuration(proxyBeanMethods = false)
@ConditionalOnWebApplication(type = Type.SERVLET)
@ConditionalOnClass(WebServlet.class)
@ConditionalOnProperty(prefix = "spring.h2.console", name = "enabled", havingValue = "true", matchIfMissing = false)
@AutoConfigureAfter(DataSourceAutoConfiguration.class)
@EnableConfigurationProperties(H2ConsoleProperties.class)
public class H2ConsoleAutoConfiguration {

    private static final Log logger = LogFactory.getLog(H2ConsoleAutoConfiguration.class);

    @Bean
    public ServletRegistrationBean<WebServlet> h2Console(H2ConsoleProperties properties, ObjectProvider<DataSource> dataSource) {

        ...(생략)

        String path = properties.getPath();
        String urlMapping = path + (path.endsWith("/") ? "*" : "/*");
        ServletRegistrationBean<WebServlet> registration = new ServletRegistrationBean<>(new WebServlet(), urlMapping);

        ...(생략)

        return registration;
    }

}
```

WebServlet.java 파일이 classpath에 존재해야지만 @ConditionalOnClass의 조건이 만족됩니다. 결국 WebServlet.java를 가진 spring-boot-stater-web 과 같은 의존성이 추가되어있는 상황에서만 H2ConsoleAutoConfiguration은 동작하게 됩니다.

그 외 다른 조건들의 의미는 다음과 같습니다.

- @ConditionalOnWebApplication : servlet 타입의 web application 일 경우
- @ConditionalOnProperty : 프로퍼티에 spring.h2.console.enabled=true가 있는 경우
- @AutoConfigureAfter : DataSourceAutoConfiguration 이 먼저 진행 된 후에 처리 됩니다.
- @EnableConfigurationProperties : [H2ConsoleProperties](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/h2/H2ConsoleProperties.java)를 이용해서 관련 프로퍼티 정보를 읽어옵니다.

위의 조건들 모두가 만족된다면 ServletRegistrationBean bean이 생성되고 브라우저로 /h2-console 에 접근하면 console을 사용할 수 있게 됩니다. 그리고 이 모든 과정은 auto configuration에 의해서 진행되고 아래와 같은 H2에 대한 의존성 주입과 프로퍼티 설정만으로도 H2 web console을 사용할 수 있게 된 것입니다.

```
pom.xml
    ...(생략)
    <dependency>
        <groupId>com.h2database</groupId>
        <artifactId>h2</artifactId>
    </dependency>
    ...(생략)
application.properties
...(생략)
spring.h2.console.enabled=true
```



#### 3.2.4.10 Disabling Specific Auto-configuration Classes

만약 특정 AutoConfiguration을 사용하지 않으려고 한다면 아래와 같이 exclude 설정을 하면 됩니다.

```
import org.springframework.boot.autoconfigure.*;
import org.springframework.boot.autoconfigure.jdbc.*;
import org.springframework.context.annotation.*;

@Configuration
@EnableAutoConfiguration(exclude={DataSourceAutoConfiguration.class})
public class MyConfiguration {
    ...(생략)
}
```

#### References

- [using-boot-disabling-specific-auto-configuration](https://docs.spring.io/spring-boot/docs/current/reference/html/using-boot-auto-configuration.html#using-boot-disabling-specific-auto-configuration)



#### 3.2.4.11 @SpringBootApplication

@SpringBootApplication는 @ComponentScan과 @EnableAutoConfiguration을 포함하고 있습니다.

아래의 Application.java는 @SpringBootApplication 설정만 했지만 component scan과 auto configuration이 이뤄집니다.

```
Application.java
package com.dveamer.sample

@SpringBootApplication
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
```

즉, 우리는 프로젝트의 최상단에 Application.java를 위치시키고 @SpringBootApplication 설정해두면 앞으로 프로젝트에 추가할 configuration 관련 정보들이 모두 유효하도록 설정됩니다.



## 3.3 Spring Boot를 활용한 아키텍처 구성

잘 만들어진 마이크로서비스는 인터페이스나 기반 요소가 사용자의 요구 사항 혹은 수용 능력에 영향을 받아 변경된다고 하더라도 애플리케이션의 주요 동작(도메인 로직 혹은 비즈니스 로직)에는 아무런 영향을 주지 않아야 하며 도메인 로직을 견고하게 유지하며 소프트웨어의 지속 가능성을 높일 수 있는 아키텍처로 구성되어야 한다.



여러분께서 맡고 있는 애플리케이션은 분명히 변합니다. 반드시 바뀌고 필히 확장됩니다. 그럴 때마다 포트와 어댑터 아키텍처는 여러분이 어디를 수정해야 할지 직관적으로 알려주고, 무엇을 바꿔야 할지 고민할 시간을 줄여주기도 하며, 수정사항을 쉽게 적용할 수 있게 해줄 겁니다. 특히 인터페이스를 바꾸거나 저장소 또는 미들웨어를 바꿔야 할 때 업무 로직 속에서 관련 코드를 찾아 헤매는 어마어마한 시간과 어댑터를 하나 만들어서 추가하는 찰나의 차이는 정말 정말 클 것이라고 생각합니다. 기회가 된다면 포트와 어댑터 아키텍처에 한 번 관심을 가져주시고 실무에 적용해 보시기 바랍니다.



### 3.3.1 포트와 어댑터 

포트는 바로 인터페이스이다. 예를 들면 클래스의 메서드 시그니처나 Java의 인터페이스가 바로 포트라고 할 수 있습니다. 다음으로 어댑터는, 디자인 패턴에도 있듯이 클라이언트에 제공해야 할 인터페이스를 따르면서도 내부 구현은 서버의 인터페이스로 위임하는 것입니다. 설명이 조금 추상적인데요. 이해를 돕기 위해 예제 코드와 함께 더 살펴보겠습니다. 아래 코드는 책이나 DVD 같은 대여물의 대여와 반납을 관리하는 애플리케이션의 일부분입니다.

```java
public class TotalRentalServiceImpl implements TotalRentalService {
 
    private final CustomerRepository customerRepository;
    private final RentalRepository rentalRepository;
    private final InventoryService inventoryService;
    private final RentalHistoryRepository rentalHistoryRepository;
 
    public TotalRentalServiceImpl(CustomerRepository customerRepository,
                                  RentalRepository rentalRepository,
                                  InventoryService inventoryService,
                                  RentalHistoryRepository rentalHistoryRepository) {
        this.customerRepository = customerRepository;
        this.rentalRepository = rentalRepository;
        this.inventoryService = inventoryService;
        this.rentalHistoryRepository = rentalHistoryRepository;
    }
 
    @Override
    public RentalHistory rent(RentalTarget target) {
        Customer borrower = customerRepository.find(target.customerId())
                                              .orElseThrow(() -> new NotFoundException(target.customerId()));
        Rental rental = rentalRepository.find(target.rentalId())
                                        .orElseThrow(() -> new NotFoundException(target.rentalId()));
        Item rentedItem = inventoryService.rent(rental, borrower)
                                          .orElseThrow(AlreadyRentedException::new);
        RentalHistory history = RentalHistory.of(UUID.randomUUID().toString(),
                                                 RentalSpec.of(borrower, rental),
                                                 rentedItem);
        rentalHistoryRepository.save(history);
        return history;
    }
}
```

이 서비스는 `TotalRentalService`를 구현하여 `RentalHistory rent(RentalTarget)`라는 인터페이스를 제공하고 있습니다. 만약 MVC 패턴을 채택했다면 이 서비스의 `rent()`를 사용하는 것은 컨트롤러입니다. 컨트롤러는 다시 HTTP를 통한 인터페이스를 클라이언트에게 제공하여 클라이언트가 `TotalRentalService`를 이용할 수 있도록 중간 역할을 합니다. 이를 그림으로 나타내면 다음과 같습니다.

![img](.\assets\1657785410947.png)그림] 클라이언트와 애플리케이션의 통신 간 컨트롤러의 위치와 역할

 

이때 `TotalRentalService`는 인터페이스를 제공하므로 포트이며, 위 코드에선 `rent()`가 포트가 됩니다. 컨트롤러는 클라이언트의 HTTP API 요청을 받아 `rent()`라는 인터페이스를 연결해주고 있으므로 어댑터입니다. 이렇게 외부에서 요청해야 동작하는 포트와 어댑터를 주요소(primary)라고 하며, 포트와 어댑터에 따라 주포트 혹은 주어댑터라고도 부릅니다.

한편 `TotalRentalService`의 구현체는 내부적으로 `CustomerRepository`나 `RentalRepository`, `InventoryService` 인터페이스를 사용합니다. 만약 `Repository`가 데이터의 영속을 위해 Redis를 사용한다면 아래 그림과 같이 표현할 수 있습니다.

![img](.\assets\1657785452997.png)그림] 애플리케이션과 기반 요소의 통신 간 Repository의 위치와 역할

 

`Repository`나 `Service`는 `TotalRentalService`가 사용할 인터페이스를 제공하고 있기 때문에 포트입니다. 위 코드의 `rentalRepository.find()`나 `inventoryService.rent()`를 예로 들 수 있습니다. 그리고 Repository가 Redis와 프로토콜을 이용해 통신하고 있다면 `RedisRepository`와 같은 구현체가 있을 겁니다. 이 구현체는 Repository라는 인터페이스를 따르면서 내부적으로 Redis 프로토콜과 연결해 주므로 어댑터입니다. 이렇듯 애플리케이션이 호출하면 동작하는 포트와 어댑터를 부요소(secondary)라고 합니다. 역시 부포트 또는 부어댑터라고 부를 수 있습니다.

아래는 포트와 어댑터 아키텍처를 따른 소프트웨어와 인터페이스, 기반 요소와의 관계를 표현한 그림입니다. 

![img](.\assets\1657785510912.png)그림 3. 포트와 어댑터의 추상적인 개념

 

앞서 설명드렸던 요소들이 모두 담겨 있는 위 그림을 통해 서로 간의 의존 관계를 파악할 수 있습니다. 먼저 어댑터가 애플리케이션과는 겹치지 않고 포트와 겹쳐 있는 모습으로 미루어 보아 어댑터가 애플리케이션을 직접 참조하지 않고 포트에 의존하고 있다는 것을 알 수 있습니다. 여기서 포트는 변경이 잦은 어댑터와 애플리케이션의 결합도를 낮추는 역할을 합니다. 애플리케이션은 핵심 로직에 가까우므로 결합도를 낮추는 것이 매우 중요합니다. 또한 애플리케이션은 도메인에 의존하지만 도메인은 애플리케이션과 어댑터에 전혀 의존하지 않습니다. 따라서 애플리케이션이나 어댑터가 변경되어도 핵심 로직인 도메인은 아무런 영향을 받지 않습니다.

다음으로 어댑터를 사용하는 쪽을 살펴보겠습니다. 주요소 쪽의 HTTP와 RPC는 각각의 어댑터를 통해 애플리케이션을 이용합니다. 그러나 각각의 어댑터는 결국 하나의 포트를 사용합니다. 만약 웹소켓이 필요하다면 웹소켓 어댑터를 새로 만들어서 추가하면 됩니다. 이렇게 새로운 어댑터를 추가하는 동안 포트가 애플리케이션과 도메인을 보호합니다. 반면에 부요소 쪽에는 애플리케이션이 이용하는 기반 요소들이 있습니다. 위 그림에서는 저장소로 MySQL을 사용하고 있는 것을 확인할 수 있습니다. 앞서 주요소 쪽에서 본 것과 다르게 기반 요소의 포트와 어댑터는 일반적으로 1:1 관계입니다. 이것은 하나의 포트에 여러 어댑터가 있다거나 새로 추가될 일은 거의 없다는 뜻입니다. 그러나 기존에 사용하던 어댑터가 교체될 가능성은 충분합니다. 예를 들어 빠른 속도가 필요하다면 MySQL을 Redis로 교체할 수 있겠죠. 이때 Redis의 어댑터를 포트의 인터페이스에 준해서 만들고, 교체하면 됩니다. 이때도 역시 포트가 애플리케이션과 도메인을 보호합니다.

잠깐 Spring 얘기를 해 보겠습니다. Spring Data JPA를 쓸 때 보통 인터페이스는 만들지만 구현체는 만들지 않습니다. Spring Data JPA가 만들어 주기 때문이죠. 그래서 Spring Data JPA에 익숙하신 분들은 포트와 어댑터를 구분하는 데에 조금 어려움을 겪을 수도 있습니다. 하지만 겁내지 마세요. 여러분이 포트만 만들면, 어댑터는 Spring Data JPA가 만들어 준다는 것만 기억하고 있으면 됩니다. 만약 Spring Data Redis를 도입하더라도 먼저 만들어 둔 Repository들은 인터페이스, 즉 포트이므로 거의 손댈 일이 없을 겁니다. 대신 Spring Data Redis가 Redis와 통신하는 어댑터를 만들어 주겠죠. 이것 또한 포트와 어댑터 아키텍처라고 할 수 있습니다.



### 3.3.2 포트와 어댑터 아키텍처 구성

애플리케이션의 코드를 조직하기 위해 흔히 패키지나 네임스페이스 등을 활용합니다. 포트와 어댑터 아키텍처는 패키지 조직에도 영향을 미치는데요. 앞에서 살펴봤던 코드를 이용해 패키지 구조를 하나 소개하겠습니다.

```java
public class TotalRentalServiceImpl implements TotalRentalService {
 
    private final CustomerRepository customerRepository;
    private final RentalRepository rentalRepository;
    private final InventoryService inventoryService;
    private final RentalHistoryRepository rentalHistoryRepository;
 
    // ...
 
    public RentalHistory rent(RentalTarget target) {
        // ...
        return history;
    }
}
```



```markup
└── com
    └── linecorp
        └── rentalapp
            ├── application
            │   ├── AlreadyRentedException.java
            │   ├── NotFoundException.java
            │   ├── RentalTarget.java
            │   ├── TotalRentalService.java
            │   └── TotalRentalServiceImpl.java
            ├── domain
            │   ├── model
            │   │   ├── customer
            │   │   │   ├── Customer.java
            │   │   │   └── CustomerRepository.java
            │   │   ├── history
            │   │   │   ├── RentalHistory.java
            │   │   │   └── RentalHistoryRepository.java
            │   │   └── rental
            │   │       ├── Item.java
            │   │       ├── Rental.java
            │   │       └── RentalRepository.java
            │   └── service
            │       └── rental
            │           └── InventoryService.java
            │
            ├── infrastructure
            └── interfaces
```

이 구조는 포트와 어댑터 아키텍처에 반드시 필요한 형태는 아닙니다. 하지만 아키텍처를 따르다 보면 자연스럽게 이와 비슷한 형태를 갖추게 됩니다. 위 패키지 구조에서 `domain`엔 주로 업무 로직을 포함하는 클래스들이 들어섭니다. `application`은 주로 유스케이스(usecases)가 작성된 클래스를 포함합니다. 이 계층엔 업무 로직이 거의 없고, `domain`의 여러 업무 로직을 조합하는 역할을 합니다. `interfaces`는 클라이언트와 약속한 통신 방식의 어댑터를 포함합니다. 이곳에 포함되는 어댑터는 주어댑터이며, 주로 MVC의 컨트롤러나 RPC 서비스 등입니다. `infrastructure`는 기반 요소, 즉 다른 서비스를 사용하는 어댑터를 포함합니다. 이곳에 포함되는 어댑터는 부어댑터입니다. 예를 들면 Kafka나 Redis, MySQL 또는 다른 서비스의 API를 사용하는 구현체가 포함되는 패키지입니다.

이러한 구성이 생소한 분들이 많을 거라고 생각합니다. 이해를 돕기 위해 제가 흔히 봤던 패키지 구조를 하나 소개하겠습니다.

```markup
└── com
    └── linecorp
        └── sally
            ├── controller
            │   ├── MembershipController.java
            │   └── StoreController.java
            ├── dto
            │   ├── RegisterRequest.java
            │   ├── RegisterResponse.java
            │   ├── StoreRequest.java
            │   ├── StoredItemDto.java
            │   └── UserDto.java
            ├── entity
            │   ├── User.java
            │   ├── Item.java
            ├── persistence
            │   ├── ItemRepository.java
            │   └── UserRepository.java
            └── service
                ├── InventoryService.java
                ├── MembershipService.java
                ├── TotalRentalService.java
                └── TotalRentalServiceImpl.java
```

위 패키지 구조는 어떤가요? 먼저 `controller`의 `MembershipController`와 `StoreController`는 서로 전혀 참조하지 않을 것 같지만 같은 패키지에 들어 있습니다. `persistence`의 `ItemRepository`와 `UserRepository`도 서로 참조할 것 같지 않습니다. 패키지는 서로 연관이 있는 클래스를 한 데 모으고 응집도를 높이는 역할을 해야 합니다. 그러므로 패키지 조직만 잘해도 응집도가 높은 패키지 구조([참고](https://en.wikipedia.org/wiki/Package_principles))를 작성할 수 있습니다. 이 패키지 구조를 포트와 어댑터 아키텍처를 따른 패키지 구조로 리팩터링한다면 어떻게 될까요? 코드를 보고 리팩터링 한 것은 아니지만, 이름으로 어림짐작했을 때 아래와 같은 형태로 바꿀 수 있을 것입니다.

```markup
└── com
    └── linecorp
        └── sally
            ├── application
            │   ├── impl
            │   │   └── TotalRentalServiceImpl.java
            │   ├── InventoryService.java
            │   └── TotalRentalService.java
            ├── domain
            │   ├── item
            │   │   ├── Item.java
            │   │   └── ItemRepository.java
            │   └── member
            │       ├── MembershipService.java
            │       ├── User.java
            │       └── UserRepository.java
            └── interfaces
                ├── common
                │   ├── StoredItemDto.java
                │   └── UserDto.java
                ├── member
                │   ├── MembershipController.java
                │   ├── RegisterRequest.java
                │   └── RegisterResponse.java
                └── store
                    ├── StoreController.java
                    └── StoreRequest.java
```



`RegisterRequest`와 `RegisterResponse`는 아마도 `MembershipController`외에는 사용할 것 같지 않습니다. 그렇다면 같은 패키지에 넣어둡니다. 이렇게 하면 `RegisterRequest`와 `RegisterResponse`의 접근 제어자를 패키지 수준으로 제한할 수 있습니다. 접근 제어자를 제한해 놓으면 두 클래스는 다른 패키지에서 전혀 관심 가질 필요가 없다는 의도를 명확히 표현할 수 있습니다. 또 클래스가 격리되므로 불필요한 의존성을 막거나 불특정 다수에게 참조될 위험성을 미연에 방지할 수 있습니다. 패키지 구조를 바꿈으로써 우리는 응집도를 높이고 모듈화라는 패키지 본연의 기능을 극대화할 수 있습니다.



### 3.3.3 포트와 어댑터 아키텍처 적용 사례

사례를 하나씩 짚어보면서 어떤 경우에 어떻게 해야 포트와 어댑터 아키텍처를 지켜 나갈 수 있는지 알아보겠습니다. 예제 코드를 다시 볼까요?

```java
public class TotalRentalServiceImpl implements TotalRentalService {
 
    // ...
 
    public RentalHistory rent(RentalTarget target) {
        // ...
        return history;
    }
}
```

Java

애플리케이션에 속하는 이 서비스는 `rent()` 메서드를 실행하기 위해 `RentalTarget` 객체를 요구하고 있습니다. 이는 인터페이스, 즉 이 메서드를 호출하는 클라이언트와의 약속입니다. 종종 어댑터인 컨트롤러의 매개변수가 그대로 애플리케이션이나 도메인 쪽으로 넘어오는 사례가 있습니다. 컨트롤러가 아래와 같이 호출하는 경우입니다.

```java
public class RentalController {
     
    private final TotalRentalService totalRentalService;
 
    // ...
    public Response<RentalHistoryView> rent(@RequestBody RentParam param) {
        // ...
        totalRentalService.rent(param); // 애플리케이션이 어댑터를 알게 되는 상황
        // ...
    }
}
```

`totalRentalService.rent()`에 `param`을 넣는 것을 보니 `rent()`의 시그니처는 `RentalHistory rent(RentParam param)`입니다. 클라이언트와 컨트롤러 사이의 인터페이스가 컨트롤러와 애플리케이션 간의 인터페이스로 스며 들었습니다. 이런 상황은 포트와 어댑터가 구분되어 있다고 할 수 없습니다. 클라이언트의 인터페이스가 애플리케이션까지 변경할 수 있습니다. 결합도가 높은 상황이죠. 여기에 RPC 서비스를 새로 붙여서 애플리케이션에 연동한다고 생각해 봅시다. RPC 서비스는 주로 [IDL](https://ko.wikipedia.org/wiki/인터페이스_정의_언어)을 사용하고 [DTO](https://ko.wikipedia.org/wiki/데이터_전송_객체)를 별도로 생성합니다. 아마 `RentParam`을 사용하지 않을 테지만, 애플리케이션을 사용하기 위해 RPC 서비스에선 굳이 `RentParam`을 생성하여 매개변수로 사용해야 합니다. 이때 HTTP 어댑터인 컨트롤러에서 요구 사항이 변경되어 `RentParam`을 변경해야 한다면, 애플리케이션뿐만 아니라 RPC 서비스까지 변경해야 합니다.

포트와 어댑터 아키텍처에선 어댑터가 애플리케이션을 일방적으로 알고 있기 때문에 어댑터가 애플리케이션에 맞춰야 합니다. 아래는 `RentParam`을 `RentalTarget`으로 변경하여 메서드를 호출하는 예제입니다.

```java
public class RentalController {
     
    private final TotalRentalService totalRentalService;
    // ...
 
    public Response<RentalHistoryView> rent(@RequestBody RentParam param) {
        // ...
        totalRentalService.rent(param.toRentTarget());
        // ...
    }
}
```

부포트와 어댑터 역시 크게 다르지 않습니다. 예제 코드의 다른 부분을 살펴보겠습니다.

```java
public class TotalRentalServiceImpl implements TotalRentalService {
 
    private final CustomerRepository customerRepository;
    private final RentalRepository rentalRepository;
    private final InventoryService inventoryService;
    private final RentalHistoryRepository rentalHistoryRepository;
 
    // ...
 
    public RentalHistory rent(RentalTarget target) {
        //...
 
        Item rentedItem = inventoryService.rent(rental, borrower)
                                          .orElseThrow(AlreadyRentedException::new);
        // ...
        return history;
    }
}
```

`inventoryService`에 `HttpInventoryService`라는 어댑터를 주입했다고 가정해 봅시다. 우리는 흔히 네트워크를 통해 하나의 서비스에서 다른 서비스를 호출하며 이때 주로 HTTP 인터페이스를 사용합니다. 그런데 처음 서비스를 연동할 때에는 API가 추가되거나 변경된다고만 생각할 뿐, 연동하는 서비스 자체가 바뀔 거라는 생각은 잘 하지 않습니다. 그래서 연동한 서비스의 DTO를 바로 반환하는 일이 종종 있습니다. 아래 코드를 보겠습니다.

```java
public class HttpInventoryService implements InventoryService {
    // ...
 
    @Override
    public Optional<StoredItem> rent(Rental rental, Customer borrower) {
        // ... HTTP 통신
        // ... JSON 역직렬화
        return Optional.of(storedItem);    
    }
}
```

`HttpInventoryService`는 HTTP를 이용해 받아 온 JSON을 역직렬화하여 `StoredItem` 객체를 만듭니다. 예제와 같이 애플리케이션 계층에서 사용하는 `Item`이 아니라 외부 `InventoryService`에서 얻어 온 StoredItem을 반환하는 경우가 많습니다. 그런데 어느 날 `InventoryService`를 고도화하여 향상된 `InventoryService`가 출시되었고, 모든 클라이언트에게 API를 변경할 것을 요구했습니다. 만약 포트와 어댑터 아키텍처대로 설계했다면, 어댑터를 하나 더 생성하여 `HttpInventoryService`를 대체하면 됩니다. 하지만 새로 생성한 어댑터에서는 더 이상 `StoredItem`을 사용할 수 없습니다. 향상된 `InventoryService`에서 제공하는 JSON의 구조가 아래와 같이 변경되었기 때문이죠.

```json
// 기존 JSON
{ "itemId": "ID", "itemStatus": "AVAILABLE", "rentalId": "RID", rentalName": "NAME" }
// 향상된 JSON
{ "item": { "id": "ID", "status": "AVAILABLE" }, "rental": { "id": "RID", "name": "NAME" } }
```

이렇게 되면 DTO를 변경해야 하고, 결국 애플리케이션 영역에 있는 `TotalRentalService`에도 영향을 줍니다. 이를 방지하기 위해서는 주어댑터와 마찬가지로 부어댑터가 부포트를 준수하면 됩니다.

```java
public class HttpInventoryService implements InventoryService {
    // ...
 
    @Override
    public Optional<Item> rent(Rental rental, Customer borrower) {
        // ... HTTP 통신
        // ... JSON 역직렬화
        return Optional.of(storedItem.toItem());
    }
}
```

포트와 어댑터 아키텍처를 따랐다면 향상된 `InventoryService`가 JSON 구조를 바꿨다고 해도 걱정할 필요 없습니다. 담고 있는 요소가 변경되지 않는 이상, 새로운 어댑터를 추가하는 것만으로도 기반 요소 변경에 쉽게 대응할 수 있습니다. 새로 추가된 어댑터는 여전히 JSON을 역직렬화하여 `Item` 객체를 만들 수 있고, 데이터를 애플리케이션에 제공할 수 있습니다.

이해를 돕기 위해 단순한 예제를 사용하여 설명했습니다. 하지만 주고받는 데이터 형태에만 신경 써선 안됩니다. 가령 MyBatis를 쓰고 있다고 해서 Repository의 인터페이스를 `queryList()`와 같이 작성하면 이 인터페이스는 애플리케이션이 아니라 MyBatis에 의존하게 됩니다. 저장소를 Redis로 바꾸게 되면 `queryList()`는 어색한 인터페이스로 남습니다. 이 메서드를 `commandList()`로 바꿔야 할 것 같지만 그러기 위해선 애플리케이션이나 도메인 영역을 함께 변경해야겠죠. 따라서 인터페이스 자체를 어느 한쪽에 치우치게 설계하지 말고 도메인 관점에서 도메인이 필요로 하는 인터페이스를 설계해야 합니다.



### 3.3.4 테스트

포트와 어댑터 아키텍처로 만든 애플리케이션은 테스트하기가 매우 쉽습니다. 업무 로직을 포트가 감싸고 있기 때문에 모의 어댑터를 붙여 애플리케이션을 쉽게 구동해 볼 수 있어서 단순하게 테스트할 수 있습니다. 위에서 봤던 예제를 다시 소환해 보겠습니다.

```java
public class TotalRentalServiceImpl implements TotalRentalService {
 
    private final CustomerRepository customerRepository;
    private final RentalRepository rentalRepository;
    private final InventoryService inventoryService;
    private final RentalHistoryRepository rentalHistoryRepository;
 
    public TotalRentalServiceImpl(CustomerRepository customerRepository,
                                  RentalRepository rentalRepository,
                                  InventoryService inventoryService,
                                  RentalHistoryRepository rentalHistoryRepository) {
        this.customerRepository = customerRepository;
        this.rentalRepository = rentalRepository;
        this.inventoryService = inventoryService;
        this.rentalHistoryRepository = rentalHistoryRepository;
    }
 
    @Override
    public RentalHistory rent(RentalTarget target) {
        Customer borrower = customerRepository.find(target.customerId())
                                              .orElseThrow(() -> new NotFoundException(target.customerId()));
        Rental rental = rentalRepository.find(target.rentalId())
                                        .orElseThrow(() -> new NotFoundException(target.rentalId()));
        Item rentedItem = inventoryService.rent(rental, borrower)
                                          .orElseThrow(AlreadyRentedException::new);
        RentalHistory history = RentalHistory.of(UUID.randomUUID().toString(),
                                                 RentalSpec.of(borrower, rental),
                                                 rentedItem);
        rentalHistoryRepository.save(history);
        return history;
    }
}
```

위 애플리케이션 서비스는 네 개의 포트를 이용하고 있습니다. 세 개의 Repository와 하나의 Service는 내부가 어떻게 구성되어 있는지 모릅니다. 저장소로 MySQL을 사용할 수도 있고 Redis를 사용할 수도 있습니다. Service는 RPC를 이용할 수도, HTTP를 이용할 수도 있습니다. 하지만 그런 사항들을 몰라도 애플리케이션 서비스를 실행하는 데에는 아무런 문제가 없습니다. 아래는 의사 코드로 테스트 코드를 작성한 것입니다.

```markup
@Test
fun `rent should return a history`() {
    val customer = Customer("CUSTOMER_ID")
    val rental = Rental("RENTAL_ID")
    val item = Item()
    var saved: RentalHistory
 
    // 모의 어댑터를 준비합니다.
    val customerRepository = CustomerRepository {
        override fun find(id) = customer
    }
    val rentalRepository = RentalRepository {
        override fun find(id) = rental
    }
    val inventoryService = InventoryService {
        override fun rent(rental, customer) = item
    }
    val rentalHistoryRepository = RentalHistoryRepository {
        override fun save(history) {
            saved = history
        }
    }
 
    // 테스트할 객체를 준비하고
    val service: TotalRentalService = TotalRentalServiceImpl(customerRepository, rentalRepository, inventoryService, rentalHistoryRepository)
 
    // 테스트할 대상을 실행합니다.
    val result = service.rent(RentalTarget("CUSTOMER_ID", "RENTAL_ID"))
 
    // 결과를 검증합니다.
    assertNotNull(result)
    assertNotNull(saved)
    assertSame(result, saved)
    assertEquals(customer, result.borrower)
    assertEquals(rental, result.rental)
    assertEquals(item, result.rentedItem)
}
```

단위 테스트는 Whitebox 테스트이므로 각각의 모의 어댑터를 실행했을 때 어떻게 동작하고 어떤 값을 반환하는지 예상할 수 있습니다. 그러므로 모의 어댑터에 기대하는 동작을 정의하고 실제 서비스를 실행한 다음, 기대했던 결과와 일치하는지 확인할 수 있습니다.

그런데 이때 애플리케이션의 저장소로 MySQL을 사용했고 Repository가 MySQL에 강하게 결합하고 있다면 어떻게 될까요? 같은 코드를 테스트하기 위해선 개발 장비에 MySQL을 설치하고 애플리케이션이 동작할 수 있는 스키마로 테이블을 생성한 뒤 모의 데이터까지 삽입하고 나서야 테스트를 실행할 수 있습니다. 물론 모의 테스트 프레임워크를 사용하면 결합도 높은 클래스라도 쉽게 모의 객체를 만들어 주긴 합니다. 하지만 그렇다고 하더라도 클래스의 결합도가 높다면 단위 테스트를 할 때 'MySQL 쿼리에 오류가 있으면 어떡하지?'와 같은 고민을 하게 될 수 있겠죠. 그런 일이 늘어나면 결국 단위 테스트는 통합 테스트라는 산으로 가게 됩니다. 포트와 어댑터 아키텍처로 설계하면 이런 고민을 하지 않아도 됩니다. 업무 로직은 포트만 알면 됩니다.



## 3.2 Spring Cloud Gateway

Spring Cloud Gateway는 Spring 및 Java 위에 API 게이트웨이를 빌드하기 위한 라이브러리를 제공한다. 여러 기준에 따라 요청을 라우팅하는 유연한 방법을 제공할 뿐만 아니라 보안, 탄력성 및 모니터링과 같은 교차 문제에 중점둔다.

> API Gateway로써 쉽게 Endpoint의 요청을 받고 API Service에게 라우팅 해주는 서버다.

Spring Cloud Gateway는 Spring Reactive 생태계 위에 구현된 API Gateway이다. 게이트웨이 핸들러 매핑을 사용하여 들어오는 요청을 적절한 대상으로 라우팅하는 간단하고 효과적인 방법을 제공한다.
그리고 Spring Cloud Gateway는 `Netty`를 사용하여 non-blocking 요청 처리를 제공한다.

### 3.2.1 핵심 요소

- 라우트(Route) : 라우트는 목적지 URI, 조건자 목록과 필터의 목록을 식별하기 위한 고유 ID로 구성된다. 라우트는 모든 조건자가 충족됐을 때만 매칭된다

  > 대상 URI, 조건부 집합(Predicates), 각종 필터들로 이루어진 요청을 라우팅할 대상들이라고 생각하자.

- 조건자(Predicates) : 각 요청을 처리하기 전에 실행되는 로직, 헤더와 입력된 값 등 다양한 HTTP 요청이 정의된 기준에 맞는지를 찾는다.

  > Java 8의 Function Predicate로, 라우팅에 필요한 조건이다. 예로 path = /abc 같은 조건이나, request header의 특정 키-값도 조건으로 사용할 수 있다.

- 필터(Filters) : HTTP 요청 또는 나가는 HTTP 응답을 수정할 수 있게한다. 다운스트림 요청을 보내기전이나 후에 수정할 수 있다. 라우트 필터는 특정 라우트에 한정된다.

  > Spring Framework의 WebFilter 인스턴스이다. Filter에서는 요청 전후로 요청/응답을 추가/수정 할 수 있다.

### 3.2.2 동작 원리

![img](https://velog.velcdn.com/images%2Fjeb1225%2Fpost%2Fb4a8b2a9-30b4-49bf-adb6-8166a8075acd%2Fspring_cloud_gateway_diagram.png)

1. 클라이언트는 Spring Cloud Gateway에 요청한다.
2. 게이트웨이 핸들러 매핑이 요청이 경로와 일치한다고 결정하면 게이트웨이 웹 핸들러로 전송된다.
3. 이 핸들러는 요청과 관련된 필터 체인을 통해 요청을 실행한다. 필터가 점선으로 구분되는 이유는 필터가 프록시 요청을 보내기 전후에 로직을 실행할 수 있기 때문이다.
4. 모든 pre 필터 로직 실행된다. 
5. 프록시 요청 실행된다.
6. post 필터 로직가 실행된다.



## 3.3 Spring Cloud Config

Spring Cloud Config는 분산 시스템에서 외부화된 설정 정보를 서버 및 클라이언트에게 제공하는 시스템이다. 설정 서버는(Config Server)는 외부에서 모든 환경에 대한 정보들을 관리해주는 중앙 서버이다. 기본적으로 설정 정보 저장을 위해 git을 사용하도록 되어있어서 손쉽게 외부 도구들로 접근 가능하고, 버전 관리도 가능하다.

- Spring Cloud Config Server(설정 서버): 버전 관리 레포지토리로 백업된 중앙 집중식 구성 노출을 지원한다.
- Spring Cloud Config Client(설정 클라이언트) : 애플리케이션이 설정 서버에 연결하도록 지원한다.



![img](https://blog.kakaocdn.net/dn/QC4Xs/btrCS0QoktP/JTWsRVzvK4EBGTUbqlbu5K/img.png)







### 3.3.2 Spring Cloud Config의 장점과 단점

Spring Cloud Config 는 여러 서비스 들의 설정 파일을 외부로 분리해 하나의 중앙 설정 저장소 처럼 관리 할 수 있도록 해주며 특정 설정 값이 변경시 각각의 서비스를 재기동 할 필요없이 적용이 가능하도록 도와준다.

- 여러 서버의 설정 파일을 중앙 서버에서 관리할 수 있다. 
- 서버를 재배포 하지 않고 설정 파일의 변경사항을 반영할 수 있다.

하지만 이것이 모든 문제를 해결해주지는 않는다. Spring Cloud Config를 이용하면 다음의 문제들을 겪을 수 있으므로 주의해야 한다.

- Git 서버 또는 설정 서버에 의한 장애가 전파될 수 있다.
- 우선 순위에 의해 설정 정보가 덮어씌워질 수 있다.

이미 서비스가 실행중이라면 메모리에서 설정 정보를 관리해 문제가 없지만, 서비스가 시작될 때 만약 GIT 서버나 설정 서버에 문제가 있다면 서비스들까지 문제가 전파될 수 있다. 또한 설정 서버에 의해 장애 지점이 될 수 있으므로 설정 정보를 관리하기 위한 별도의 서비스 운영이 필요할 수도 있다. 또한 설정 파일이 여러 곳에 있을 수 있어 우선 순위에 주의해야 하는데, 자세히 살펴보도록 하자.



### 3.3.3 Spring Cloud Config 설정 파일 우선 순위 

설정 파일은 크게 다음의 위치에 존재할 수 있으며 다음의 순서대로 읽어진다. 나중에 읽어지는 것이 우선순위가 높다.

- 프로젝트의 application.yaml
- 설정 저장소의 application.yaml
- 프로젝트의 application-{profile}.yaml
- 설정 저장소의 {application name}/{application name}-{profile}

만약 읽어지는 순서대로 읽다가 동일한 값을 지니는 설정 정보가 있다면 덮어 씌워지므로 주의해야 한다. 예를 들어 'hello'이라는 이름의 애플리케이션에 local 프로파일인 환경변수가 로컬의 appliation.yaml, application-local.yaml에 있고, 설정 저장소의 application.yaml, hello/hello-local.yaml에도 있다면 다음의 순서대로 읽어진다.

- 프로젝트의 application.yaml
- 설정 저장소의 application.yaml
- 프로젝트 application-local.yaml
- 설정 저장소의 hello/hello-local.yaml

최종적으로 읽혀 적용되는 환경변수 값은 설정 저장소의 hello/hello-local.yaml 의 값이다. 만약 설정 정보가 산개되어 있다면 오히려 관리가 복잡해질 수 있으며, 동작 과정을 모른다면 장애가 될 수 있으므로 주의하도록 하자.

 

#### 3.3.4 클라이언트 실행 및 확인

설정 클라이언트를 실행해 호출해보면 정상적으로 적용됨을 확인할 수 있다. 하지만 대부분은 private 레포지토리를 사용할 것인데, 이때는 SSL로 연결을 해주어야 한다.

```shell
$ curl -X POST http://127.0.0.1:8081/actuator/refresh -i
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    62    0    62    0     0     12      0 --:--:--  0:00:04 --:--:--    13
HTTP/1.1 200
Content-Type: application/vnd.spring-boot.actuator.v3+json
Transfer-Encoding: chunked
Date: Wed, 17 Aug 2022 08:35:34 GMT

["config.client.version","com.test.region","com.test.profile"]
KTDS@201091253n1k MSYS /usr/bin
$ curl  http://localhost:8081/get -i
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    69    0    69    0     0  15295      0 --:--:-- --:--:-- --:--:-- 23000
HTTP/1.1 200
Vary: Origin
Vary: Access-Control-Request-Method
Vary: Access-Control-Request-Headers
Content-Type: application/json
Transfer-Encoding: chunked
Date: Wed, 17 Aug 2022 08:35:46 GMT

{"code":"200","message":"success","service":"backend1 get","data":""}
KTDS@201091253n1k MSYS /usr/bin
```



### 3.3.4 **ConfigurationProperties**

*.properties , *.yml 파일에 있는 property를 자바 클래스에 값을 가져와서(바인딩) 사용할 수 있게 해주는 어노테이션

Spring boot 에서는 운영에 필요한 설정(DB 정보, LOG설정 등등 )들을 *.properties , *.yml 에 써두고 관리한다.

이 설정은 KEY - VALUE 의 형태로 저장되어 관리하고 있으며 @Value 을 사용하여 바인딩을 할 수 있다.

아래와 같은 properties 파일이 있다고 가정할 때 

```
site-url.naver=https://www.naver.com
site-url.google=https:/google.com
```

@Value 를 사용하여 바인딩을 하면 다음과 같은 자바 코드가 나온다.

```
@Value("${site-url.naver}")
private String naver;

@Value("${site-url.google}")
private String google;
```

@Value를 사용하여 바인딩을 하는 방법은 문자열을 사용하기에 오타가 날 수도 있다.

그래서 클래스 파일로 관리하는 방법을 찾아봤다.

 

**1. properties에서 오토컴플릿을 지원하도록 하기 위한 dependency를 추가**

```
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-configuration-processor</artifactId>
	<optional>true</optional>
</dependency>
```

  

**2. 클래스 파일 생성**

@ConfigurationProperties 이 좋은 이유 여러 표기법에 대해서 오토로 바인딩해 준다. ( 아래 참고 )

| acme.my-project.person.first-name | properties 와 .yml에 **권장**되는 표기 방법                  |
| --------------------------------- | ------------------------------------------------------------ |
| acme.myProject.person.firstName   | 표준 카멜 케이스 문법.                                       |
| acme.my_project.person.first_name | .properties와 .yml 에서 사용가능한 방법 ( - 표기법이 더 표준 ) |
| ACME_MYPROJECT_PERSON_FIRSTNAME   | 시스템 환경 변수를 사용할 때 권장                            |

 @Component로 bean을 등록해야 한다.

@ConfigurationProperties에 prifix를 설정한다.

 properties 파일에 있는 site-url.* 에 대하여 바인딩한다.

```
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.stereotype.Component;

import lombok.Data;

@Component
@ConfigurationProperties(prefix = "site-url")
@Data
public class siteUrlProperties {
	private String naver;
	private String google;
	
}
```

 **3. 확인**

```
@Controller
@RequestMapping("/")
@Slf4j
public class MainController {
	
	@Autowired
	siteUrlProperties siteUrlProperties;
	
	@GetMapping("")
	@ResponseBody
	public String test(Model model) {
		return siteUrlProperties.getNaver();
	}
	
}
```

@ConfiguConfigurationProperties 어노테이션을 사용하여 property 값을 사용하면 매핑을 유연하게 할 수 있다는 장점이 있지만 SpEL를 사용할 수 없다.

SpEL를 사용할 때에는 @Value를 사용해야 한다.

 그 외에는 @ConfiguConfigurationProperties를 사용하는게 코드가 깔끔해진다.



## 3.4 Spring Cloud Stream

## **1. 개요**

**Spring Cloud Stream은 이벤트 기반 또는 메시지 기반 마이크로서비스를 생성하는 데 도움이 되는** Spring Boot 및 Spring Integration을 기반으로 구축된 프레임워크입니다 .

이 기사에서는 몇 가지 간단한 예제와 함께 Spring Cloud Stream의 개념과 구성을 소개합니다.

## **2. 메이븐 종속성**

*시작하려면 pom.xml* 에 메시징 미들웨어로 [브로커 RabbitMQ Maven 종속성을 포함하는 Spring Cloud Starter Stream](https://search.maven.org/classic/#search|gav|1|g%3A"org.springframework.cloud" AND a%3A"spring-cloud-starter-stream-rabbit") 을 추가해야 합니다 .

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-stream-rabbit</artifactId>
    <version>3.1.3</version>
</dependency>
```

그리고 JUnit 지원도 활성화하기 위해 [Maven Central의 모듈 종속성을 추가합니다.](https://search.maven.org/classic/#search|gav|1|g%3A"org.springframework.cloud" AND a%3A"spring-cloud-stream-test-support")

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-stream-test-support</artifactId>
    <version>3.1.3</version>
    <scope>test</scope>
</dependency>
```

## **3. 주요 개념**

마이크로서비스 아키텍처는 " [스마트 엔드포인트 및 덤 파이프](https://martinfowler.com/articles/microservices.html#SmartEndpointsAndDumbPipes) " 원칙을 따릅니다. 끝점 간의 통신은 RabbitMQ 또는 Apache Kafka와 같은 메시징 미들웨어 당사자에 의해 주도됩니다. **서비스는 이러한 끝점 또는 채널을 통해 도메인 이벤트를 게시하여 통신합니다** .

메시지 기반 서비스를 구축하기 위해 알아야 할 필수 패러다임과 함께 Spring Cloud Stream 프레임워크를 구성하는 개념을 살펴보겠습니다.

### **3.1. 구성**

*입력 바인딩을 수신하고* *출력* 바인딩 에 응답을 보내는 Spring Cloud Stream의 간단한 서비스를 살펴보겠습니다 .

```java
@SpringBootApplication
@EnableBinding(Processor.class)
public class MyLoggerServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(MyLoggerServiceApplication.class, args);
    }

    @StreamListener(Processor.INPUT)
    @SendTo(Processor.OUTPUT)
    public LogMessage enrichLogMessage(LogMessage log) {
        return new LogMessage(String.format("[1]: %s", log.getMessage()));
    }
}
```

*@EnableBinding* 주석은 인터페이스 *Processor 내에 정의된* *INPUT* 및 *OUTPUT* 채널을 바인딩하도록 애플리케이션을 구성합니다 . **두 채널 모두 구체적인 메시징 미들웨어 또는 바인더를 사용하도록 구성할 수 있는 바인딩입니다.**

이 모든 개념의 정의를 살펴보겠습니다.

- *바인딩* — 입력 및 출력 채널을 선언적으로 식별하는 인터페이스 모음
- *바인더* — Kafka 또는 RabbitMQ와 같은 메시징 미들웨어 구현
- *채널* — 메시징 미들웨어와 애플리케이션 간의 통신 파이프를 나타냅니다.
- *StreamListeners —* *MessageConverter* 가 미들웨어 특정 이벤트와 도메인 객체 유형/POJO 간의 직렬화/역직렬화를 수행 한 후 채널의 메시지에 대해 자동으로 호출되는 빈의 메시지 처리 메소드
- *메시지* *스키마 - 메시지의* *직렬화* 및 역직렬화에 사용되는 이러한 스키마는 한 위치에서 정적으로 읽거나 동적으로 로드할 수 있어 도메인 개체 유형의 발전을 지원합니다.

### **3.2. 커뮤니케이션 패턴**

**대상에 지정된 메시지는 \*발행-구독\* 메시징 패턴에 의해 전달됩니다.** 게시자는 메시지를 주제로 분류하며 각 주제는 이름으로 식별됩니다. 구독자는 하나 이상의 주제에 관심을 표명합니다. 미들웨어는 메시지를 필터링하여 흥미로운 주제의 메시지를 구독자에게 전달합니다.

이제 가입자를 그룹화할 수 있습니다. *소비자 그룹 은* *그룹 id* 로 식별 되는 가입자 또는 소비자 집합으로, 이 그룹 내에서 주제 또는 주제 파티션의 메시지가 부하 분산 방식으로 전달됩니다.

## **4. 프로그래밍 모델**

이 섹션에서는 Spring Cloud Stream 애플리케이션 빌드의 기본 사항을 설명합니다.

### **4.1. 기능 테스트**

테스트 지원은 채널과 상호 작용하고 메시지를 검사할 수 있는 바인더 구현입니다.

*위의 richLogMessage* 서비스 에 메시지를 보내고 응답 에 메시지 시작 부분에 *"[1]: " 텍스트가 포함되어 있는지 확인합니다.*

```java
@RunWith(SpringJUnit4ClassRunner.class)
@ContextConfiguration(classes = MyLoggerServiceApplication.class)
@DirtiesContext
public class MyLoggerApplicationTests {

    @Autowired
    private Processor pipe;

    @Autowired
    private MessageCollector messageCollector;

    @Test
    public void whenSendMessage_thenResponseShouldUpdateText() {
        pipe.input()
          .send(MessageBuilder.withPayload(new LogMessage("This is my message"))
          .build());

        Object payload = messageCollector.forChannel(pipe.output())
          .poll()
          .getPayload();

        assertEquals("[1]: This is my message", payload.toString());
    }
}
```

### **4.2. 맞춤 채널**

위의 예에서는 하나의 입력과 하나의 출력 채널만 있는 Spring Cloud에서 제공 하는 *Processor 인터페이스를 사용했습니다.*

하나의 입력 채널과 두 개의 출력 채널과 같이 다른 것이 필요한 경우 사용자 지정 프로세서를 만들 수 있습니다.

```java
public interface MyProcessor {
    String INPUT = "myInput";

    @Input
    SubscribableChannel myInput();

    @Output("myOutput")
    MessageChannel anOutput();

    @Output
    MessageChannel anotherOutput();
}
```

Spring은 우리를 위해 이 인터페이스의 적절한 구현을 제공할 것입니다. *채널 이름은 @Output("myOutput")* 과 같은 주석을 사용하여 설정할 수 있습니다 .

그렇지 않으면 Spring은 메소드 이름을 채널 이름으로 사용합니다. 따라서 *myInput* , *myOutput* 및 *anotherOutput* 이라는 세 개의 채널이 있습니다.

이제 값이 10보다 작거나 값이 10보다 크거나 같은 경우 다른 출력으로 메시지를 라우팅한다고 가정해 보겠습니다.

```java
@Autowired
private MyProcessor processor;

@StreamListener(MyProcessor.INPUT)
public void routeValues(Integer val) {
    if (val < 10) {
        processor.anOutput().send(message(val));
    } else {
        processor.anotherOutput().send(message(val));
    }
}

private static final <T> Message<T> message(T val) {
    return MessageBuilder.withPayload(val).build();
}
```

### **4.3. 조건부 디스패치**

*@StreamListener* 어노테이션을 사용 하여 [SpEL 표현식](https://www.baeldung.com/spring-expression-language) 으로 정의한 조건을 사용하여 **소비자에게 기대하는 메시지를 필터링** 할 수도 있습니다 .

예를 들어 메시지를 다른 출력으로 라우팅하는 또 다른 접근 방식으로 조건부 디스패치를 사용할 수 있습니다.

```java
@Autowired
private MyProcessor processor;

@StreamListener(
  target = MyProcessor.INPUT, 
  condition = "payload < 10")
public void routeValuesToAnOutput(Integer val) {
    processor.anOutput().send(message(val));
}

@StreamListener(
  target = MyProcessor.INPUT, 
  condition = "payload >= 10")
public void routeValuesToAnotherOutput(Integer val) {
    processor.anotherOutput().send(message(val));
}
```

이 접근 방식 의 유일한 **제한 사항은 이러한 메서드가 값을 반환하지 않아야 한다는 것입니다.**

## **5. 설정**

RabbitMQ 브로커의 메시지를 처리할 애플리케이션을 설정해 보겠습니다.

### **5.1. 바인더 구성**

*META-INF/spring.binders* 를 통해 기본 바인더 구현을 사용하도록 애플리케이션을 구성할 수 있습니다 .

```plaintext
rabbit:\
org.springframework.cloud.stream.binder.rabbit.config.RabbitMessageChannelBinderConfiguration
```

*[또는 다음 종속성](https://search.maven.org/classic/#search|gav|1|g%3A"org.springframework.cloud" AND a%3A"spring-cloud-stream-binder-rabbit")* 을 포함하여 RabbitMQ용 바인더 라이브러리를 클래스 경로에 추가할 수 있습니다 .

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-stream-binder-rabbit</artifactId>
    <version>1.3.0.RELEASE</version>
</dependency>
```

**바인더 구현이 제공되지 않으면 Spring은 채널 간에 직접 메시지 통신을 사용합니다.**

### **5.2. RabbitMQ 구성**

RabbitMQ 바인더를 사용하도록 섹션 3.1의 예제를 구성하려면 *src/main/resources* 에 있는 *application.yml* 을 업데이트해야 합니다 .

```plaintext
spring:
  cloud:
    stream:
      bindings:
        input:
          destination: queue.log.messages
          binder: local_rabbit
        output:
          destination: queue.pretty.log.messages
          binder: local_rabbit
      binders:
        local_rabbit:
          type: rabbit
          environment:
            spring:
              rabbitmq:
                host: <host>
                port: 5672
                username: <username>
                password: <password>
                virtual-host: /
```

*입력* 바인딩은 queue.log.messages라는 교환 을 *사용* 하고 *출력* 바인딩은 *queue.pretty.log.messages* 교환을 사용합니다 . *두 바인딩 모두 local_rabbit* 이라는 바인더를 사용합니다 .

RabbitMQ 교환 또는 대기열을 미리 만들 필요가 없습니다. 응용 프로그램을 실행하면 **두 교환이 자동으로 생성** 됩니다.

애플리케이션을 테스트하기 위해 RabbitMQ 관리 사이트를 사용하여 메시지를 게시할 수 있습니다. *exchange queue.log.messages* 의 *Publish Message* 패널 에서 요청을 JSON 형식으로 입력해야 합니다.

### **5.3. 메시지 변환 사용자 정의**

Spring Cloud Stream을 사용하면 특정 콘텐츠 유형에 대한 메시지 변환을 적용할 수 있습니다. 위의 예에서는 JSON 형식을 사용하는 대신 일반 텍스트를 제공하려고 합니다.

이렇게 하려면 ***MessageConverter\*** **를 사용하여** ***LogMessage\*** **에 사용자 지정 변환을 적용합니다** .

```java
@SpringBootApplication
@EnableBinding(Processor.class)
public class MyLoggerServiceApplication {
    //...

    @Bean
    public MessageConverter providesTextPlainMessageConverter() {
        return new TextPlainMessageConverter();
    }

    //...
}
public class TextPlainMessageConverter extends AbstractMessageConverter {

    public TextPlainMessageConverter() {
        super(new MimeType("text", "plain"));
    }

    @Override
    protected boolean supports(Class<?> clazz) {
        return (LogMessage.class == clazz);
    }

    @Override
    protected Object convertFromInternal(Message<?> message, 
        Class<?> targetClass, Object conversionHint) {
        Object payload = message.getPayload();
        String text = payload instanceof String 
          ? (String) payload 
          : new String((byte[]) payload);
        return new LogMessage(text);
    }
}
```

이러한 변경 사항을 적용한 후 *Publish Message* 패널로 돌아가서 헤더 " *contentTypes* "를 " *text/plain* "으로 설정하고 페이로드를 " *Hello World* "로 설정하면 이전과 같이 작동해야 합니다.

### **5.4. 소비자 그룹**

애플리케이션의 여러 인스턴스를 실행할 때 **입력 채널에 새 메시지가 있을 때마다 모든 구독자에게 알림이 전송** 됩니다.

대부분의 경우 메시지는 한 번만 처리되어야 합니다. Spring Cloud Stream은 소비자 그룹을 통해 이 동작을 구현합니다.

이 동작을 활성화하기 위해 각 소비자 바인딩은 *spring.cloud.stream.bindings.<CHANNEL>.group* 속성을 사용하여 그룹 이름을 지정할 수 있습니다.

```plaintext
spring:
  cloud:
    stream:
      bindings:
        input:
          destination: queue.log.messages
          binder: local_rabbit
          group: logMessageConsumers
          ...
```

## **6. 메시지 기반 마이크로서비스**

이 섹션에서는 마이크로서비스 컨텍스트에서 Spring Cloud Stream 애플리케이션을 실행하는 데 필요한 모든 기능을 소개합니다.

### **6.1. 확장**

여러 응용 프로그램이 실행 중인 경우 데이터가 소비자 간에 적절하게 분할되는지 확인하는 것이 중요합니다. 이를 위해 Spring Cloud Stream은 두 가지 속성을 제공합니다.

- ***spring.cloud.stream.instanceCount\*** — 실행 중인 애플리케이션의 수
- ***spring.cloud.stream.instanceIndex\*** — 현재 애플리케이션의 인덱스

예를 들어 위의 *MyLoggerServiceApplication* 응용 프로그램의 두 인스턴스를 배포한 경우 두 응용 프로그램에 대해 spring.cloud.stream.instanceCount 속성 *은* 2가 되어야 하고 *spring.cloud.stream.instanceIndex* 속성 은 각각 0과 1이 되어야 합니다.

[이 속성은 이 기사](https://www.baeldung.com/spring-cloud-data-flow-stream-processing) 에서 설명한 대로 Spring Data Flow를 사용하여 Spring Cloud Stream 애플리케이션을 배포하면 자동으로 설정됩니다 .

### **6.2. 파티셔닝**

도메인 이벤트는 *분할* 된 메시지일 수 있습니다. **이는 스토리지를 확장하고 애플리케이션 성능을 개선** 할 때 도움이 됩니다 .

도메인 이벤트에는 일반적으로 파티션 키가 있으므로 관련 메시지가 있는 동일한 파티션으로 끝납니다.

로그 메시지를 메시지의 첫 번째 문자(파티션 키)로 분할하고 두 개의 파티션으로 그룹화하기를 원한다고 가정해 보겠습니다.

*AM* 으로 시작하는 로그 메시지용 파티션이 하나 있고 *NZ* 용 파티션이 하나 있습니다. 이것은 두 가지 속성을 사용하여 구성할 수 있습니다.

- *spring.cloud.stream.bindings.output.producer.partitionKeyExpression* — 페이로드를 분할하는 표현식
- *spring.cloud.stream.bindings.output.producer.partitionCount* — 그룹 수

**때로는 파티션에 대한 표현식이 너무 복잡하여 한 줄에 쓰기가 어렵습니다.** 이러한 경우 *spring.cloud.stream.bindings.output.producer.partitionKeyExtractorClass* 속성을 사용하여 사용자 지정 파티션 전략을 작성할 수 있습니다 .

### **6.3. 건강 표시기**

마이크로서비스 컨텍스트에서 우리는 **서비스가 다운되거나 실패하기 시작할 때 감지** 해야 합니다 . Spring Cloud Stream은 바인더의 상태 표시기를 활성화하기 위해 *management.health.binders.enabled 속성을 제공합니다.*

애플리케이션을 실행할 때 *http://<host>:<port>/health* 에서 상태를 쿼리할 수 있습니다 .

## **7. 결론**

이 튜토리얼에서는 Spring Cloud Stream의 주요 개념을 제시하고 RabbitMQ에 대한 몇 가지 간단한 예제를 통해 이를 사용하는 방법을 보여주었습니다. Spring Cloud Stream에 대한 자세한 정보는 [여기](https://docs.spring.io/spring-cloud-stream/docs/current/reference/htmlsingle/) 에서 찾을 수 있습니다 .

이 기사의 소스 코드는 [GitHub](https://github.com/eugenp/tutorials/tree/master/spring-cloud-modules/spring-cloud-stream/spring-cloud-stream-rabbit) 에서 찾을 수 있습니다 .

## 3.5 Spring Cloud Eureka

## **1. 개요**

이 튜토리얼에서는 " *Spring Cloud Netflix Eureka* *.* "

***클라이언트 측 서비스 검색\* 을 사용하면 호스트 이름과 포트를 하드 코딩하지 않고도 서비스가 서로를 찾고 통신할 수 있습니다.** 이러한 아키텍처에서 유일한 '고정 지점'은각 서비스가 등록해야 하는 *서비스 레지스트리 입니다.*

한 가지 단점은 모든 클라이언트가 이 고정 소수점과 상호 작용하기 위해 특정 논리를 구현해야 한다는 것입니다. 이것은 실제 요청 전에 추가 네트워크 왕복을 가정합니다.

Netflix Eureka를 사용하면 각 클라이언트가 동시에 서버 역할을 하여 연결된 피어에 상태를 복제할 수 있습니다. 즉, 클라이언트는 *서비스 레지스트리* 에서 연결된 모든 피어 목록을 검색 하고 로드 밸런싱 알고리즘을 통해 다른 서비스에 모든 추가 요청을 합니다.

클라이언트의 존재에 대한 정보를 받으려면 레지스트리에 하트비트 신호를 보내야 합니다.

이 자습서의 목표를 달성하기 위해 세 가지 *마이크로서비스* 를 구현합니다 .

- 서비스 *레지스트리* ( ***Eureka Server*** )

- 레지스트리에 자신을 등록 하는 *REST 서비스(* ***Eureka Client*** )

- 

  REST

   서비스를 레지스트리 인식 클라이언트로 사용 하는 웹 애플리케이션 ( 

  Spring Cloud Netflix **Feign Client**

   )

  ## 추가 읽기:

  ## [Spring Cloud Netflix 가이드 – Hystrix](https://www.baeldung.com/spring-cloud-netflix-hystrix)

  이 기사는 Spring Cloud Hystrix를 사용하여 애플리케이션 로직에서 폴백을 설정하는 방법을 보여줍니다.

  [더 읽기](https://www.baeldung.com/spring-cloud-netflix-hystrix) →

  ## [Zuul 프록시가 있는 Spring REST](https://www.baeldung.com/spring-rest-with-zuul-proxy)

  Spring REST API에 대한 Zuul 프록시 사용 탐색, CORS 및 브라우저의 동일 출처 정책 제약을 해결합니다.

  [더 읽기](https://www.baeldung.com/spring-rest-with-zuul-proxy) →

## **2. 유레카 서버**

*서비스 레지스트리를 위해 Eureka Server* 를 구현하는 것은 다음과 같이 쉽습니다.

1. 종속성 에 *[spring-cloud-starter-netflix-eureka-server](https://search.maven.org/search?q=spring-cloud-starter-netflix-eureka-server)* 추가
2. [*@EnableEurekaServer*](https://www.baeldung.com/spring-boot-application-configuration) 로 주석을 달아 *@SpringBootApplication* 에서 Eureka 서버 활성화
3. 일부 속성 구성

차근차근 해봅시다.

먼저, 새로운 Maven 프로젝트를 만들고 의존성을 넣을 것입니다. 이 튜토리얼에서 설명하는 모든 프로젝트에 *[spring-cloud-starter-parent](https://search.maven.org/classic/#search|gav|1|g%3A"org.springframework.cloud" AND a%3A"spring-cloud-starter-parent")* 를 가져오고 있습니다.

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
</dependency>

<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-parent</artifactId>
            <version>Greenwich.RELEASE</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>
```

[Spring의 프로젝트 문서](https://spring.io/projects/spring-cloud#learn) 에서 최신 Spring Cloud 릴리스를 확인할 수 있습니다 .

그런 다음 기본 응용 프로그램 클래스를 만듭니다.

```java
@SpringBootApplication
@EnableEurekaServer
public class EurekaServerApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaServerApplication.class, args);
    }
}
```

마지막으로 속성을 *YAML* 형식으로 구성하므로 *application.yml* 이 구성 파일이 됩니다.

```plaintext
server:
  port: 8761
eureka:
  client:
    registerWithEureka: false
    fetchRegistry: false
```

**여기에서 애플리케이션 포트를 구성하고 있습니다. \*Eureka\* 서버 의 기본값 은 \*8761\* 입니다.** 애플리케이션이 서버 역할을 해야 하기 때문에 내장된 *Eureka Client 에 자체적으로 등록하지 말라고 지시하고 있습니다.*

이제 브라우저를 [http://localhost:8761](http://localhost:8761/) 로 지정하여 *Eureka* 대시보드를 보고 나중에 등록된 인스턴스를 검사할 것입니다.

현재 상태 및 건강 지표와 같은 기본 지표를 볼 수 있습니다.

[![스크린샷_20160819_073151](https://www.baeldung.com/wp-content/uploads/2016/08/Screenshot_20160819_073151.png)](https://www.baeldung.com/wp-content/uploads/2016/08/Screenshot_20160819_073151.png)

## **3. 유레카 클라이언트**

@SpringBootApplication 이 검색을 인식하려면 클래스 경로에 *Spring* *Discovery Client* (예: [*spring-cloud-starter-netflix-eureka-client*](https://search.maven.org/search?q=spring-cloud-starter-netflix-eureka-client) )를 포함해야 *합니다.*

그런 다음 *@EnableDiscoveryClient* 또는 @EnableEurekaClient로 *@Configuration* 에 주석을 *달아야 합니다.* 이 주석은 클래스 경로에 *spring-cloud-starter-netflix-eureka-client* 종속성이 있는 경우 선택 사항입니다.

후자는 *Spring Boot* 에게 명시적으로 서비스 검색을 위해 Spring Netflix Eureka를 사용하도록 지시합니다. 클라이언트 애플리케이션을 샘플 수명으로 채우기 위해 *pom.xml 에* [*spring-boot-starter-web*](https://search.maven.org/classic/#search|gav|1|g%3A"org.springframework.boot" AND a%3A"spring-boot-starter-web") 패키지 도 포함하고 *REST* 컨트롤러 를 구현합니다 .

그러나 먼저 종속성을 추가합니다. 다시 말하지만, 우리 를 위한 아티팩트 버전을 파악하기 위해 *spring-cloud-starter-parent* 종속성에 맡길 수 있습니다 .

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-starter</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
```

여기서 우리는 메인 애플리케이션 클래스를 구현할 것입니다:

```java
@SpringBootApplication
@RestController
public class EurekaClientApplication implements GreetingController {

    @Autowired
    @Lazy
    private EurekaClient eurekaClient;

    @Value("${spring.application.name}")
    private String appName;

    public static void main(String[] args) {
        SpringApplication.run(EurekaClientApplication.class, args);
    }

    @Override
    public String greeting() {
        return String.format(
          "Hello from '%s'!", eurekaClient.getApplication(appName).getName());
    }
}
```

그리고 *GreetingController* 인터페이스:

```java
public interface GreetingController {
    @RequestMapping("/greeting")
    String greeting();
}
```

인터페이스 대신 *EurekaClientApplication* 클래스 내에서 매핑을 간단히 선언할 수도 있습니다. 인터페이스는 서버와 클라이언트 간에 공유하려는 경우 유용할 수 있습니다.

다음으로, 등록된 애플리케이션 목록에서 클라이언트를 고유하게 식별하기 위해 구성된 *Spring* 애플리케이션 이름으로 *application.yml 을 설정해야 합니다.*

**나중에 우리가 그 이름으로 이 서비스에 접근할 것이기 때문에 우리는 Spring Boot가 우리를 위해 임의의 포트를 선택하도록 할 수 \*있습니다 .\***

마지막으로 클라이언트에게 레지스트리를 찾아야 하는 위치를 알려야 합니다.

```plaintext
spring:
  application:
    name: spring-cloud-eureka-client
server:
  port: 0
eureka:
  client:
    serviceUrl:
      defaultZone: ${EUREKA_URI:http://localhost:8761/eureka}
  instance:
    preferIpAddress: true
```

이러한 종류의 서비스는 나중에 쉽게 확장할 수 있어야 하기 때문에 이러한 방식으로 Eureka 클라이언트를 설정하기로 결정했습니다.

이제 클라이언트를 실행하고 브라우저를 다시 [*http://localhost:8761*](https://localhost:8761/) 로 지정하여 Eureka 대시보드에서 등록 상태를 확인합니다. 대시보드를 사용하여 등록된 클라이언트의 홈페이지를 관리 목적으로 대시보드와 연결하는 것과 같은 추가 구성을 수행할 수 있습니다. 그러나 구성 옵션은 이 문서의 범위를 벗어납니다.

[![스크린샷_20160819_101810](https://www.baeldung.com/wp-content/uploads/2016/08/Screenshot_20160819_101810.png)](https://www.baeldung.com/wp-content/uploads/2016/08/Screenshot_20160819_101810.png)

## **4. 클라이언트 척**

세 가지 종속 마이크로 서비스로 프로젝트를 마무리하기 위해 이제 *Spring Netflix Feign Client 를 사용하여* *REST* 를 소비하는 웹 애플리케이션을 구현합니다 .

***Feign\* 을 엔드포인트와 통신하기 위해 인터페이스를 사용 하는 발견 인식 [\*Spring\* \*RestTemplate\*](https://www.baeldung.com/rest-template) 으로 생각하십시오 . 이러한 인터페이스는 런타임에 자동으로 구현되며 \*service-urls 대신\* \*service-names\* 를 사용 합니다 .**

Feign 이 없으면 *EurekaClient* 의 인스턴스를 컨트롤러에 *자동 연결해야 하며, 이를 통해* *서비스 이름* 으로 서비스 정보를 *Application* 객체 로 수신할 수 있습니다.

우리는 이 *애플리케이션* 을 사용하여 이 서비스의 모든 인스턴스 목록을 가져오고 적절한 인스턴스를 선택한 다음 이 *InstanceInfo* 를 사용하여 호스트 이름과 포트를 가져옵니다. *이를 통해 모든 http 클라이언트* 에 대해 표준 요청을 수행할 수 있습니다 .

```java
@Autowired
private EurekaClient eurekaClient;

@RequestMapping("/get-greeting-no-feign")
public String greeting(Model model) {

    InstanceInfo service = eurekaClient
      .getApplication(spring-cloud-eureka-client)
      .getInstances()
      .get(0);

    String hostName = service.getHostName();
    int port = service.getPort();

    // ...
}
```

*RestTemplate 을 사용하여 이름으로* *Eureka* 클라이언트 서비스 에 액세스할 수도 있지만 이 항목은 이 기사를 벗어납니다.

*Feign Client* 프로젝트 를 설정하기 위해 *pom.xml* 에 다음 네 가지 종속성을 추가합니다 .

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-feign</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-thymeleaf</artifactId>
</dependency>
```

Feign *클라이언트* 는 *[spring-cloud-starter-feign](https://search.maven.org/classic/#search|gav|1|g%3A"org.springframework.cloud" AND a%3A"spring-cloud-starter-feign")* 패키지에 있습니다. 이를 활성화하려면 *@EnableFeignClients 로* *@Configuration* 에 주석을 달아야 합니다. 그것을 사용하기 위해 우리는 단순히 *@FeignClient("service-name")* 로 인터페이스에 주석을 달고 그것을 컨트롤러에 자동 연결합니다.

*이러한 Feign* *클라이언트* 를 생성하는 좋은 방법은 [*@RequestMapping*](https://www.baeldung.com/spring-requestmapping) 주석 메서드 를 사용하여 인터페이스를 만들고 별도의 모듈에 넣는 것입니다. 이런 식으로 서버와 클라이언트 간에 공유할 수 있습니다. 서버 측에서는 *@Controller 로 구현할 수 있고 클라이언트 측에서는* *@FeignClient* 로 확장하고 주석을 달 수 있습니다 .

또한 [*spring-cloud-starter-eureka 패키지*](https://search.maven.org/classic/#search|gav|1|g%3A"org.springframework.cloud" AND a%3A"spring-cloud-starter-eureka") 는 프로젝트에 포함되어야 하고 메인 애플리케이션 클래스에 *@EnableEurekaClient* 주석을 달아 활성화해야 합니다.

[*spring-boot-starter-web*](https://search.maven.org/classic/#search|gav|1|g%3A"org.springframework.boot" AND a%3A"spring-boot-starter-web") 및 [*spring-boot-starter-thymeleaf*](https://search.maven.org/classic/#search|gav|1|g%3A"org.springframework.boot" AND a%3A"spring-boot-starter-thymeleaf") 종속성은 *REST* 서비스 에서 가져온 데이터를 포함 [하는 보기](https://www.baeldung.com/spring-mvc-form-tutorial) 를 표시하는 데 사용됩니다.

이것은 우리의 *Feign 클라이언트* 인터페이스가 될 것입니다:

```java
@FeignClient("spring-cloud-eureka-client")
public interface GreetingClient {
    @RequestMapping("/greeting")
    String greeting();
}
```

여기에서 동시에 컨트롤러 역할을 하는 기본 애플리케이션 클래스를 구현합니다.

```java
@SpringBootApplication
@EnableFeignClients
@Controller
public class FeignClientApplication {
    @Autowired
    private GreetingClient greetingClient;

    public static void main(String[] args) {
        SpringApplication.run(FeignClientApplication.class, args);
    }

    @RequestMapping("/get-greeting")
    public String greeting(Model model) {
        model.addAttribute("greeting", greetingClient.greeting());
        return "greeting-view";
    }
}
```

이것은 우리 보기의 HTML 템플릿이 될 것입니다:

```html
<!DOCTYPE html>
<html xmlns:th="http://www.thymeleaf.org">
    <head>
        <title>Greeting Page</title>
    </head>
    <body>
        <h2 th:text="${greeting}"/>
    </body>
</html>
```

*application.yml* 구성 파일 은 이전 단계와 거의 동일합니다.

```plaintext
spring:
  application:
    name: spring-cloud-eureka-feign-client
server:
  port: 8080
eureka:
  client:
    serviceUrl:
      defaultZone: ${EUREKA_URI:http://localhost:8761/eureka}
```

이제 이 서비스를 빌드하고 실행할 수 있습니다. 마지막으로 브라우저가 [*http://localhost:8080/get-greeting*](http://localhost:8080/get-greeting) 을 가리키도록 하고 다음과 같이 표시되어야 합니다.

```plaintext
Hello from SPRING-CLOUD-EUREKA-CLIENT!
```

## 5. ' *TransportException:* 알려진 서버에서 요청을 실행할 수 없음'

Eureka 서버를 실행하는 동안 종종 다음과 같은 예외가 발생합니다.

```java
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
```

*기본적으로 이것은 application.properties* 또는 *application.yml* 의 잘못된 구성으로 인해 발생 합니다 . *Eureka* 는 구성할 수 있는 클라이언트에 대해 두 가지 속성을 제공합니다.

- *registerWithEureka:* 이 속성을 *true* 로 설정 하면 서버가 시작되는 동안 내장 클라이언트가 Eureka 서버에 자신을 등록하려고 합니다.
- *fetchRegistry:* 이 속성을 true로 구성하면 내장 클라이언트가 *Eureka* 레지스트리를 가져오려고 합니다.

이제 **Eureka 서버를 시작할 때 내장 클라이언트를 등록하여 서버에 구성하고 싶지 않습니다** .

위의 속성을 *true 로 표시하면(또는 기본적으로* *true* 이므로 구성하지 않음 ) 서버를 시작하는 동안 내장 클라이언트는 *Eureka* 서버에 자신을 등록하려고 시도하고 레지스트리도 가져오려고 시도합니다. , 아직 사용할 수 없습니다. 결과적으로 *TransportException* 이 발생 합니다.

*따라서 Eureka* 서버 응용 프로그램 에서 이러한 속성을 *true* 로 구성해서는 안 됩니다. *application.yml* 에 넣어야 하는 올바른 설정 은 다음과 같습니다.

```java
eureka:
  client:
    registerWithEureka: false
    fetchRegistry: fals
```

## 3.6 Spring Cloud OpenFeign

- ## **1. 개요**

  이 튜토리얼에서는 Spring Boot 앱을 위한 선언적 REST 클라이언트인 [Spring Cloud OpenFeign 에 대해 설명합니다.](https://spring.io/projects/spring-cloud-openfeign)

  [Feign](https://www.baeldung.com/intro-to-feign) 은 Feign 주석 및 JAX-RS 주석을 포함하는 플러그형 주석 지원으로 웹 서비스 클라이언트 작성을 더 쉽게 만듭니다.

  또한 [Spring Cloud 는 ](https://www.baeldung.com/spring-cloud-series)[Spring MVC 주석](https://www.baeldung.com/spring-mvc-annotations) 에 대한 지원을 추가 하고 Spring Web에서 사용되는 것과 동일한 [*HttpMessageConverters 를 사용합니다.*](https://www.baeldung.com/spring-httpmessageconverter-rest)

  Feign 사용의 한 가지 좋은 점은 인터페이스 정의 외에 서비스를 호출하기 위한 코드를 작성할 필요가 없다는 것입니다.

  ## **2. 종속성**

  먼저 Spring Boot 웹 프로젝트를 만들고 *pom.xml* 파일 에 *spring-cloud-starter-openfeign* 종속성을 추가하여 시작하겠습니다.

  ```xml
  <dependency>
      <groupId>org.springframework.cloud</groupId>
      <artifactId>spring-cloud-starter-openfeign</artifactId>
  </dependency>
  ```

  또한 *spring-cloud-dependencies* 를 추가해야 합니다 .

  ```xml
   <dependencyManagement>
       <dependencies>
           <dependency>
              <groupId>org.springframework.cloud</groupId>
              <artifactId>spring-cloud-dependencies</artifactId>
              <version>${spring-cloud.version}</version>
              <type>pom</type>
              <scope>import</scope>
          </dependency>
      </dependencies>
  </dependencyManagement>
  ```

  Maven Central 에서 최신 버전의 *[spring-cloud-starter-openfeign](https://search.maven.org/search?q=g:org.springframework.cloud AND a:spring-cloud-starter-openfeign)* 및 [*spring-cloud-dependencies 를 찾을 수 있습니다.*](https://search.maven.org/search?q=g:org.springframework.cloud AND a:spring-cloud-dependencies)

  ## **3. 가장 클라이언트**

  다음으로 메인 클래스 에 *@EnableFeignClients 를 추가해야 합니다.*

  ```java
  @SpringBootApplication
  @EnableFeignClients
  public class ExampleApplication {
  
      public static void main(String[] args) {
          SpringApplication.run(ExampleApplication.class, args);
      }
  }
  ```

  이 주석을 사용하여 Feign 클라이언트임을 선언하는 인터페이스에 대한 구성 요소 스캔을 활성화합니다.

  그런 다음 ***@FeignClient\*** **주석** **을 사용하여 Feign 클라이언트를 선언합니다** .

  ```java
  @FeignClient(value = "jplaceholder", url = "https://jsonplaceholder.typicode.com/")
  public interface JSONPlaceHolderClient {
  
      @RequestMapping(method = RequestMethod.GET, value = "/posts")
      List<Post> getPosts();
  
      @RequestMapping(method = RequestMethod.GET, value = "/posts/{postId}", produces = "application/json")
      Post getPostById(@PathVariable("postId") Long postId);
  }
  ```

  이 예에서는 클라이언트가 [JSONPlaceholder API](https://jsonplaceholder.typicode.com/) 에서 읽도록 구성했습니다 .

  *@FeignClient* 주석에 전달 된 *값* 인수 는 필수 임의 클라이언트 이름이며 *url* 인수를 사용하여 API 기본 URL을 지정합니다.

  또한 이 인터페이스는 Feign 클라이언트이므로 Spring 웹 주석을 사용하여 도달하려는 API를 선언할 수 있습니다.

  ## **4. 구성**

  이제 **각 Feign 클라이언트가 사용자 지정 가능한 구성 요소 집합으로 구성되어 있음을 이해하는 것이 매우 중요합니다.**

  Spring Cloud 는 다음 섹션에서 설명하는 대로 사용자 정의할 수 있는 *FeignClientsConfiguration 클래스를 사용하여 각 명명된 클라이언트에 대해 요청 시 새로운 기본 세트를 생성합니다.*

  위의 클래스에는 다음 빈이 포함되어 있습니다.

  - Decoder – *ResponseEntityDecoder ,* *SpringDecoder* 를 래핑 하여 *Response* 를 디코딩하는 데 사용됩니다.
  - 인코더 – *SpringEncoder 는* *RequestBody* 를 인코딩하는 데 사용됩니다 .
  - 로거 – *Slf4jLogger* 는 Feign에서 사용하는 기본 로거입니다.
  - Contract – 주석 처리를 제공하는 *SpringMvcContract*
  - Feign-Builder – *HystrixFeign.Builder* 는 구성 요소를 구성하는 데 사용됩니다.
  - 클라이언트 – *LoadBalancerFeignClient* 또는 기본 Feign 클라이언트

  ### **4.1. 사용자 정의 빈 구성**

  **이러한 bean 중 하나 이상을 사용자 정의하려면** *@Configuration* 클래스를 사용하여 이를 재정의할 수 있으며 *FeignClient* 주석에 추가합니다.

  ```java
  @FeignClient(value = "jplaceholder",
    url = "https://jsonplaceholder.typicode.com/",
    configuration = MyClientConfiguration.class)
  @Configuration
  public class MyClientConfiguration {
  
      @Bean
      public OkHttpClient client() {
          return new OkHttpClient();
      }
  }
  ```

  이 예에서 우리는 HTTP/2를 지원하기 위해 기본값 대신 OkHttpClient를 사용하도록 [*Feign 에 지시합니다.*](https://www.baeldung.com/guide-to-okhttp)

  Feign은 요청과 함께 더 많은 헤더를 보내는 *ApacheHttpClient* 를 포함하여 다양한 사용 사례에 대해 여러 클라이언트를 지원합니다( 예: 일부 서버에서 예상하는 *Content-Length ).*

  *이러한 클라이언트를 사용하려면 pom.xml* 파일 에 필수 종속성을 추가하는 것을 잊지 마십시오 .

  ```xml
  <dependency>
      <groupId>io.github.openfeign</groupId>
      <artifactId>feign-okhttp</artifactId>
  </dependency>
  
  <dependency>
      <groupId>io.github.openfeign</groupId>
      <artifactId>feign-httpclient</artifactId>
  </dependency>
  ```

  최신 버전의 [*feign-okhttp*](https://search.maven.org/search?q=g:io.github.openfeign AND a:feign-okhttp) 및 [*feign-httpclient*](https://search.maven.org/search?q=g:io.github.openfeign AND a:feign-httpclient) 는 Maven Central에서 찾을 수 있습니다.

  ### **4.2. 속성을 사용한 구성**

  *@Configuration* 클래스를 사용하는 대신 이 *application.yaml* 예제 와 같이 **애플리케이션 속성을 사용하여 Feign 클라이언트를 구성할 수 있습니다 .**

  ```xml
  feign:
    client:
      config:
        default:
          connectTimeout: 5000
          readTimeout: 5000
          loggerLevel: basic
  ```

  이 구성을 사용 하여 애플리케이션에서 선언된 각 클라이언트에 대해 시간 제한을 5초로 설정하고 로거 수준을 *기본 으로 설정합니다.*

  마지막으로 모든 *@FeignClient* 개체 를 구성하기 위해 *기본 클라이언트 이름으로 구성을 만들거나 구성에 대해 가상 클라이언트 이름을 선언할 수 있습니다.*

  ```yaml
  feign:
    client:
      config:
        jplaceholder:
  ```

  *@Configuration* 빈과 구성 속성 이 모두 있는 경우 구성 속성이 *@Configuration* 값을 재정의합니다.

  ## **5. 인터셉터**

  **인터셉터를 추가하는 것은 Feign에서 제공하는 또 다른 유용한 기능입니다.**

  인터셉터는 모든 HTTP 요청/응답에 대해 인증에서 로깅에 이르기까지 다양한 암시적 작업을 수행할 수 있습니다.

  이 섹션에서는 자체 인터셉터를 구현하고 즉시 사용 가능한 Spring Cloud OpenFeign에서 제공하는 인터셉터를 사용합니다. 둘 다 **각 요청에 기본 인증 헤더를 추가합니다.**

  ### 5.1. *RequestInterceptor* 구현

  사용자 지정 요청 인터셉터를 구현해 보겠습니다.

  ```java
  @Bean
  public RequestInterceptor requestInterceptor() {
    return requestTemplate -> {
        requestTemplate.header("user", username);
        requestTemplate.header("password", password);
        requestTemplate.header("Accept", ContentType.APPLICATION_JSON.getMimeType());
    };
  }
  ```

  또한 요청 체인에 인터셉터를 추가하려면 이 빈을 *@Configuration* 클래스에 추가하거나 이전에 본 것처럼 속성 파일에서 선언하면 됩니다.

  ```xml
  feign:
    client:
      config:
        default:
          requestInterceptors:
            com.baeldung.cloud.openfeign.JSONPlaceHolderInterceptor
  ```

  ### 5.2. *BasicAuthRequestInterceptor* 사용

  또는 Spring Cloud OpenFeign이 제공하는 *BasicAuthRequestInterceptor 클래스를 사용할 수 있습니다.*

  ```java
  @Bean
  public BasicAuthRequestInterceptor basicAuthRequestInterceptor() {
      return new BasicAuthRequestInterceptor("username", "password");
  }
  ```

  간단합니다. 이제 모든 요청에 기본 인증 헤더가 포함됩니다.

  ## **6. 히스트릭스 지원**

  Feign은 [Hystrix](https://www.baeldung.com/spring-cloud-netflix-hystrix) 를 지원하므로 활성화했다면 **폴백 패턴을 구현할 수 있습니다.**

  대체 패턴을 사용하면 원격 서비스 호출이 실패할 때 예외를 생성하는 대신 서비스 소비자가 대체 코드 경로를 실행하여 다른 수단을 통해 작업을 수행하려고 합니다.

  목표를 달성하려면 속성 파일에 *feign.hystrix.enabled=true 를 추가하여 Hystrix를 활성화해야 합니다.*

  이를 통해 서비스가 실패할 때 호출되는 폴백 메서드를 구현할 수 있습니다.

  ```java
  @Component
  public class JSONPlaceHolderFallback implements JSONPlaceHolderClient {
  
      @Override
      public List<Post> getPosts() {
          return Collections.emptyList();
      }
  
      @Override
      public Post getPostById(Long postId) {
          return null;
      }
  }
  ```

  *대체 방법이 제공되었음을 Feign에 알리려면 @FeignClient* 주석 에서 대체 클래스도 설정해야 합니다 .

  ```java
  @FeignClient(value = "jplaceholder",
    url = "https://jsonplaceholder.typicode.com/",
    fallback = JSONPlaceHolderFallback.class)
  public interface JSONPlaceHolderClient {
      // APIs
  }
  ```

  ## **7. 로깅**

  각 Feign 클라이언트에 대해 로거가 기본적으로 생성됩니다.

  로깅을 활성화하려면 클라이언트 인터페이스의 패키지 이름을 사용하여 *application.propertie* 파일 에 선언해야 합니다 .

  ```xml
  logging.level.com.baeldung.cloud.openfeign.client: DEBUG
  ```

  또는 패키지의 특정 클라이언트에 대해서만 로깅을 활성화하려면 전체 클래스 이름을 사용할 수 있습니다.

  ```xml
  logging.level.com.baeldung.cloud.openfeign.client.JSONPlaceHolderClient: DEBUG
  ```

  **Feign 로깅은 \*DEBUG\* 수준에만 응답합니다.**

  클라이언트별로 구성할 수 있는 *Logger.Level 은 로깅할 양을 나타냅니다.*

  ```java
  @Configuration
  public class ClientConfiguration {
      
      @Bean
      Logger.Level feignLoggerLevel() {
          return Logger.Level.BASIC;
      }
  }
  ```

  다음 네 가지 로깅 수준 중에서 선택할 수 있습니다.

  - *NONE* – 기본값인 로깅 없음
  - *BASIC* – 요청 방법, URL 및 응답 상태만 기록
  - *HEADERS* – 요청 및 응답 헤더와 함께 기본 정보를 기록합니다.
  - *FULL* - 요청 및 응답 모두에 대한 본문, 헤더 및 메타데이터를 기록합니다.

  ## **8. 오류 처리**

  Feign의 기본 오류 핸들러인 *ErrorDecoder.default* 는 항상 *FeignException* 을 발생시킵니다 .

  이제 이 동작이 항상 가장 유용한 것은 아닙니다. 따라서 **발생한 예외를 사용자 지정하려면 \*CustomErrorDecoder\*** 를 사용할 수 있습니다 .

  ```java
  public class CustomErrorDecoder implements ErrorDecoder {
      @Override
      public Exception decode(String methodKey, Response response) {
  
          switch (response.status()){
              case 400:
                  return new BadRequestException();
              case 404:
                  return new NotFoundException();
              default:
                  return new Exception("Generic error");
          }
      }
  }
  ```

  그런 다음 이전에 했던 것처럼 *@Configuration* 클래스 에 빈을 추가하여 기본 *ErrorDecoder 를 교체해야 합니다.*

  ```java
  @Configuration
  public class ClientConfiguration {
  
      @Bean
      public ErrorDecoder errorDecoder() {
          return new CustomErrorDecoder();
      }
  }
  ```

  ## **9. 결론**

  이 기사에서는 Spring Cloud OpenFeign과 간단한 샘플 애플리케이션에서의 구현에 대해 논의했습니다.

  *또한 Hystrix* 및 *ErrorDecoder* 를 사용하여 클라이언트를 구성하고, 요청에 인터셉터를 추가하고, 오류를 처리하는 방법을 보았습니다 .

  평소와 같이 이 자습서에 표시된 모든 코드 샘플은 [GitHub에서](https://github.com/eugenp/tutorials/tree/master/spring-cloud-modules/spring-cloud-openfeign) 사용할 수 있습니다 .

  

## 3.7  Spring Data JDBC

## 1. 개요

Spring Data JDBC는 Spring Data JPA만큼 복잡하지 않은 지속성 프레임워크입니다. JPA의 캐시, 지연 로딩, write-behind 또는 기타 여러 기능을 제공하지 않습니다. 그럼에도 불구하고 자체 ORM이 있으며 **매핑된 엔터티, 저장소, 쿼리 주석 및 \*JdbcTemplate\*** 과 같이 Spring Data JPA와 함께 사용되는 대부분의 기능을 제공합니다 .

명심해야 할 중요한 점은 **Spring Data JDBC는 스키마 생성을 제공하지 않는다는 것** 입니다. 결과적으로 우리는 스키마를 명시적으로 생성할 책임이 있습니다.

## 2. 프로젝트에 Spring Data JDBC 추가하기

Spring Data JDBC는 JDBC 종속성 스타터가 있는 Spring Boot 애플리케이션에서 사용할 수 있습니다. **그러나 이 종속성 스타터는 데이터베이스 드라이버를 가져오지 않습니다** . 그 결정은 개발자가 해야 합니다. Spring Data JPA에 대한 종속성 스타터를 추가해 보겠습니다.

```xml
<dependency> 
    <groupId>org.springframework.boot</groupId> 
    <artifactId>spring-boot-starter-data-jdbc</artifactId>
</dependency> 
```

이 예에서는 H2 데이터베이스를 사용하고 있습니다. 앞서 언급했듯이 Spring Data JDBC는 스키마 생성을 제공하지 않습니다. 이러한 경우 스키마 개체를 만들기 위한 SQL DDL 명령이 있는 사용자 지정 *schema.sql 파일을 만들 수 있습니다.* 자동으로 Spring Boot는 이 파일을 선택하여 데이터베이스 객체를 생성하는 데 사용합니다.

## 3. 엔티티 추가

다른 Spring Data 프로젝트와 마찬가지로 주석을 사용하여 POJO를 데이터베이스 테이블과 매핑합니다. Spring Data JDBC 에서 엔티티는 ***@Id\*** **가 있어야 합니다 .** Spring Data JDBC는 *@Id* 주석을 사용하여 엔티티를 식별합니다.

Spring Data JPA와 유사하게 Spring Data JDBC는 기본적으로 Java 엔티티를 관계형 데이터베이스 테이블에 매핑하고 속성을 열 이름에 매핑하는 명명 전략을 사용합니다. 기본적으로 엔터티 및 속성의 Camel Case 이름은 테이블 및 열의 스네이크 케이스 이름에 각각 매핑됩니다. *예를 들어, AddressBook* 이라는 Java 엔터티 는 *address_book* 이라는 데이터베이스 테이블에 매핑됩니다 .

또한 *@Table* 및 *@Column* 주석을 사용하여 엔티티 및 속성을 테이블 및 열과 명시적으로 매핑할 수 있습니다. 예를 들어 아래에서 이 예제에서 사용할 엔터티를 정의했습니다.

```java
public class Person {
    @Id
    private long id;
    private String firstName;
    private String lastName;
    // constructors, getters, setters
}
```

*Person* 클래스 에서 *@Table* 또는 *@Column* 주석을 사용할 필요가 없습니다 . Spring Data JDBC의 기본 명명 전략은 엔터티와 테이블 간의 모든 매핑을 암시적으로 수행합니다.

## 4. JDBC 저장소 선언

Spring Data JDBC는 Spring Data JPA와 유사한 구문을 사용합니다. *Repository* , *CrudRepository 또는 PagingAndSortingRepository* 인터페이스 를 확장하여 Spring Data JDBC 저장소를 생성할 수 있습니다 . *CrudRepository* 를 구현함으로써 우리는 특히 *save* , *delete* , *findById* 와 같은 가장 일반적으로 사용되는 메소드의 구현을 받습니다 .

예제에서 사용할 JDBC 저장소를 만들어 보겠습니다.

```java
@Repository 
public interface PersonRepository extends CrudRepository<Person, Long> {
}
```

페이지 매김 및 정렬 기능이 필요한 경우 가장 좋은 선택은 *PagingAndSortingRepository* 인터페이스를 확장하는 것입니다.

## 5. JDBC 저장소 사용자 정의

*CrudRepository* 의 내장 메소드 에도 불구하고 특정 경우에 대한 메소드를 생성해야 합니다.

이제 수정하지 않는 쿼리와 수정하는 쿼리를 사용하여 *PersonRepository 를 사용자 지정해 보겠습니다.*

```java
@Repository
public interface PersonRepository extends CrudRepository<Person, Long> {

    List<Person> findByFirstName(String firstName);

    @Modifying
    @Query("UPDATE person SET first_name = :name WHERE id = :id")
    boolean updateByFirstName(@Param("id") Long id, @Param("name") String name);
}
```

버전 2.0부터 Spring Data JDBC는 [쿼리 메소드](https://docs.spring.io/spring-data/jdbc/docs/current/reference/html/#jdbc.query-methods) 를 지원합니다 . 즉, 예를 들어 *findByFirstName과* 같은 키워드를 포함하는 쿼리 메서드의 이름을 지정하면 Spring Data JDBC는 쿼리 객체를 자동으로 생성합니다.

그러나 수정 쿼리의 경우 *@Modifying* 주석을 사용하여 엔터티를 수정하는 쿼리 메서드에 주석을 추가합니다. *또한 @Query* 주석 으로 장식합니다 .

*@Query* 주석 내부에 SQL 명령을 추가합니다. **Spring Data JDBC에서는 일반 SQL로 쿼리를 작성합니다.** 우리는 JPQL과 같은 고급 쿼리 언어를 사용하지 않습니다. 결과적으로 응용 프로그램은 데이터베이스 공급업체와 긴밀하게 연결됩니다.

이러한 이유로 다른 데이터베이스로 변경하는 것도 더 어려워집니다.

우리가 염두에 두어야 할 한 가지는 **Spring Data JDBC가 인덱스 번호가 있는 매개변수 참조를 지원하지 않는다는 것입니다** . **매개변수는 이름으로만 참조할 수** 있습니다.

## 6. 데이터베이스 채우기

마지막으로 위에서 생성한 Spring Data JDBC 저장소를 테스트하는 데 사용할 데이터로 데이터베이스를 채워야 합니다. 따라서 더미 데이터를 삽입할 데이터베이스 시더를 만들 것입니다. 이 예에 대한 데이터베이스 시더 구현을 추가해 보겠습니다.

```java
@Component
public class DatabaseSeeder {

    @Autowired
    private JdbcTemplate jdbcTemplate;
    public void insertData() {
        jdbcTemplate.execute("INSERT INTO Person(first_name,last_name) VALUES('Victor', 'Hugo')");
        jdbcTemplate.execute("INSERT INTO Person(first_name,last_name) VALUES('Dante', 'Alighieri')");
        jdbcTemplate.execute("INSERT INTO Person(first_name,last_name) VALUES('Stefan', 'Zweig')");
        jdbcTemplate.execute("INSERT INTO Person(first_name,last_name) VALUES('Oscar', 'Wilde')");
    }
}
```

위에서 보았듯이 *INSERT* 문을 실행하기 위해 Spring JDBC를 사용하고 있습니다. *특히 Spring JDBC는 데이터베이스와의 연결을 처리하고 JdbcTemplate* 을 사용하여 SQL 명령을 실행할 수 있습니다 . 이 솔루션은 실행된 쿼리를 완벽하게 제어할 수 있기 때문에 매우 유연합니다.

## 7. 결론

요약하자면, Spring Data JDBC는 Spring JDBC를 사용하는 것처럼 간단한 솔루션을 제공합니다. 그럼에도 불구하고 Spring Data JPA를 사용하는 데 익숙한 대부분의 기능을 제공합니다.

Spring Data JDBC의 가장 큰 장점 중 하나는 Spring Data JPA에 비해 데이터베이스에 접근할 때 향상된 성능입니다. 이것은 Spring Data JDBC **가 데이터베이스와 직접 통신하기 때문** 입니다. **Spring Data JDBC는 데이터베이스를 쿼리할 때 대부분의 Spring Data 매직을 포함하지 않습니다** .

Spring Data JDBC를 사용할 때 가장 큰 단점 중 하나는 데이터베이스 벤더에 의존한다는 것입니다. 데이터베이스를 MySQL에서 Oracle로 변경하기로 결정한 경우 **다른 방언을 사용하는 데이터베이스에서 발생하는 문제를 처리해야 할 수 있습니다** .



## 3.8 Caching Data with Spring

## **1. The Cache Abstraction?**

In this tutorial, we're going to learn how to **use the Caching Abstraction in Spring**, and generally improve the performance of our system.

We’ll enable simple caching for some real-world method examples, and we'll discuss how we can practically improve the performance of these calls through smart cache management.

## Further reading:

## [Spring Boot Ehcache Example](https://www.baeldung.com/spring-boot-ehcache)

A quick and practical guide to using Spring with Ehcache.

[Read more](https://www.baeldung.com/spring-boot-ehcache) →

## [Cache Eviction in Spring Boot](https://www.baeldung.com/spring-boot-evict-cache)

Learn how to invalidate caches with Spring Boot.

[Read more](https://www.baeldung.com/spring-boot-evict-cache) →

## **2. Getting Started**

The core caching abstraction provided by Spring resides in the *[spring-context](https://search.maven.org/search?q=g:org.springframework a:spring-context)* module. So when using Maven, our *pom.xml* should contain the following dependency:

```xml
<dependency>
    <groupId>org.springframework</groupId>
    <artifactId>spring-context</artifactId>
    <version>5.3.3</version>
</dependency>
```

Interestingly, there is another module named *[spring-context-support](https://search.maven.org/search?q=g:org.springframework a:spring-context-support),* which sits on top of the *spring-context* module and provides a few more *CacheManagers* backed by the likes of [EhCache](https://www.baeldung.com/spring-boot-ehcache) or [Caffeine](https://www.baeldung.com/java-caching-caffeine). If we want to use those as our cache storage, then we need to use the *spring-context-support* module instead:

```xml
<dependency>
    <groupId>org.springframework</groupId>
    <artifactId>spring-context-support</artifactId>
    <version>5.3.3</version>
</dependency>
```

Since the *spring-context-support* module transitively depends on the *spring-context* module, there is no need for a separate dependency declaration for the *spring-context.*

### **2.1. Spring Boot**

If we use Spring Boot, then we can utilize the *[spring-boot-starter-cache](https://search.maven.org/search?q=g:org.springframework.boot a:spring-boot-starter-cache)* starter package to easily add the caching dependencies:

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-cache</artifactId>
    <version>2.4.0</version>
</dependency>
```

Under the hood, the starter brings the *spring-context-support* module.

## **3. Enable Caching**

To enable caching, Spring makes good use of annotations, much like enabling any other configuration level feature in the framework.

We can enable the caching feature simply by adding the *@EnableCaching* annotation to any of the configuration classes:

```java
@Configuration
@EnableCaching
public class CachingConfig {

    @Bean
    public CacheManager cacheManager() {
        return new ConcurrentMapCacheManager("addresses");
    }
}
```

We can, of course, **enable cache management with XML** configuration as well:

```xml
<beans>
    <cache:annotation-driven />

    <bean id="cacheManager" class="org.springframework.cache.support.SimpleCacheManager">
        <property name="caches">
            <set>
                <bean 
                  class="org.springframework.cache.concurrent.ConcurrentMapCacheFactoryBean" 
                  name="addresses"/>
            </set>
        </property>
    </bean>
</beans>
```

Note: **After we enable caching, for the minimal setup, we must register a \*cacheManager\*.**

### **3.1. Using Spring Boot**

When using Spring Boot, the mere presence of the starter package on the classpath alongside the *EnableCaching* annotation would register the same *ConcurrentMapCacheManager.* So there is no need for a separate bean declaration.

Also, we can customize the [auto-configured](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/cache/CacheAutoConfiguration.java) *CacheManager* using one or more *CacheManagerCustomizer<T>* beans:

```java
@Component
public class SimpleCacheCustomizer 
  implements CacheManagerCustomizer<ConcurrentMapCacheManager> {

    @Override
    public void customize(ConcurrentMapCacheManager cacheManager) {
        cacheManager.setCacheNames(asList("users", "transactions"));
    }
}
```

The *[CacheAutoConfiguration](https://github.com/spring-projects/spring-boot/blob/master/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/cache/CacheAutoConfiguration.java)* auto-configuration picks up these customizers and applies them to the current *CacheManager* before its complete initialization.

## **4. Use Caching With Annotations**

Once we’ve enabled caching, the next step is to bind the caching behavior to the methods with declarative annotations.

### **4.1. @\*Cacheable\***

The simplest way to enable caching behavior for a method is to demarcate it with *@Cacheable*, and parameterize it with the name of the cache where the results would be stored:

```java
@Cacheable("addresses")
public String getAddress(Customer customer) {...}
```

The *getAddress()* call will first check the cache *addresses* before actually invoking the method and then caching the result.

While in most cases one cache is enough, the Spring framework also supports multiple caches to be passed as parameters:

```java
@Cacheable({"addresses", "directory"})
public String getAddress(Customer customer) {...}
```

In this case, if any of the caches contain the required result, the result is returned and the method is not invoked.

### **4.2.** **@\*CacheEvict\*** 

Now, what would be the problem with making all methods *@Cacheable*?

The problem is size. **W****e don't want to populate the cache with values that we don't need often**. Caches can grow quite large, quite fast, and we could be holding on to a lot of stale or unused data.

We can use the *@CacheEvict* annotation to indicate the removal of one or more/all values so that fresh values can be loaded into the cache again:

```java
@CacheEvict(value="addresses", allEntries=true)
public String getAddress(Customer customer) {...}
```

Here we're using the additional parameter *allEntries* in conjunction with the cache to be emptied; this will clear all the entries in the cache *addresses* and prepare it for new data.

### **4.3. @\*CachePut\***

While *@CacheEvict* reduces the overhead of looking up entries in a large cache by removing stale and unused entries, we want to **avoid evicting too much data out of the cache**.

Instead, we selectively update the entries whenever we alter them.

With the *@CachePut* annotation, we can update the content of the cache without interfering with the method execution. That is, the method will always be executed and the result cached:

```java
@CachePut(value="addresses")
public String getAddress(Customer customer) {...}
```

The difference between *@Cacheable* and *@CachePut* is that *@Cacheable* will **skip running the method**, whereas *@CachePut* will **actually run the method** and then put its results in the cache.

### **4.4. @\*Caching\***

What if we want to use multiple annotations of the same type for caching a method? Let's look at an incorrect example:

```java
@CacheEvict("addresses")
@CacheEvict(value="directory", key=customer.name)
public String getAddress(Customer customer) {...}
```

The above code would fail to compile since Java does not allow multiple annotations of the same type to be declared for a given method.

The workaround to the above issue would be:

```java
@Caching(evict = { 
  @CacheEvict("addresses"), 
  @CacheEvict(value="directory", key="#customer.name") })
public String getAddress(Customer customer) {...}
```

As shown in the code snippet above, we can **group multiple caching annotations** with *@Caching*, and use it to implement our own customized caching logic.

### **4.5. @\*CacheConfig\***

With the *@CacheConfig* annotation, we can **streamline some of the cache configuration into a single place at the class level,** so that we don't have to declare things multiple times:

```java
@CacheConfig(cacheNames={"addresses"})
public class CustomerDataService {

    @Cacheable
    public String getAddress(Customer customer) {...}
```

## **5. Conditional Caching**

Sometimes, caching might not work well for a method in all situations.

Reusing our example from the *@CachePut* annotation, this will both execute the method as well as cache the results each and every time:

```java
@CachePut(value="addresses")
public String getAddress(Customer customer) {...}
```

### **5.1. Condition Parameter**

If we want more control over when the annotation is active, we can parameterize *@CachePut* with a condition parameter that takes a SpEL expression and ensures that the results are cached based on evaluating that expression:

```java
@CachePut(value="addresses", condition="#customer.name=='Tom'")
public String getAddress(Customer customer) {...}
```

### **5.2. Unless Parameter**

We can also control the caching **based on the output of the method rather than the input** via the *unless* parameter:

```java
@CachePut(value="addresses", unless="#result.length()<64")
public String getAddress(Customer customer) {...}
```

The above annotation would cache addresses unless they were shorter than 64 characters.

It's important to know that the *condition* and *unless* parameters can be used in conjunction with all the caching annotations.

This kind of conditional caching can prove quite effective for managing large results. It's also useful for customizing behavior based on input parameters instead of enforcing a generic behavior to all operations.

## **6. Declarative XML-Based Caching**

If we don't have access to our application's source code, or want to inject the caching behavior externally, we can also use declarative XML- based caching.

Here is our XML configuration:

```xml
<!-- the service that you wish to make cacheable -->
<bean id="customerDataService" 
  class="com.your.app.namespace.service.CustomerDataService"/>

<bean id="cacheManager" 
  class="org.springframework.cache.support.SimpleCacheManager"> 
    <property name="caches"> 
        <set> 
            <bean 
              class="org.springframework.cache.concurrent.ConcurrentMapCacheFactoryBean" 
              name="directory"/> 
            <bean 
              class="org.springframework.cache.concurrent.ConcurrentMapCacheFactoryBean" 
              name="addresses"/> 
        </set> 
    </property> 
</bean>
<!-- define caching behavior -->
<cache:advice id="cachingBehavior" cache-manager="cacheManager">
    <cache:caching cache="addresses">
        <cache:cacheable method="getAddress" key="#customer.name"/>
    </cache:caching>
</cache:advice>

<!-- apply the behavior to all the implementations of CustomerDataService interface->
<aop:config>
    <aop:advisor advice-ref="cachingBehavior"
      pointcut="execution(* com.your.app.namespace.service.CustomerDataService.*(..))"/>
</aop:config>
```

## **7. Java-Based Caching**

Here is the equivalent Java Configuration:

```java
@Configuration
@EnableCaching
public class CachingConfig {

    @Bean
    public CacheManager cacheManager() {
        SimpleCacheManager cacheManager = new SimpleCacheManager();
        cacheManager.setCaches(Arrays.asList(
          new ConcurrentMapCache("directory"), 
          new ConcurrentMapCache("addresses")));
        return cacheManager;
    }
}
```

And here is our *CustomerDataService*:

```java
@Component
public class CustomerDataService {
 
    @Cacheable(value = "addresses", key = "#customer.name")
    public String getAddress(Customer customer) {
        return customer.getAddress();
    }
}
```

## **8. Summary**

In this article, we discussed the basics of Caching in Spring, and how to make good use of that abstraction with annotations.

The full implementation of this article can be found in [the GitHub project](https://github.com/eugenp/tutorials/tree/master/spring-caching).

## 3.9  Spring with kafka

## **1. 개요**

[Apache Kafka](https://kafka.apache.org/) 는 분산 및 내결함성 스트림 처리 시스템입니다.

이 튜토리얼에서는 Kafka에 대한 Spring 지원과 기본 Kafka Java 클라이언트 API를 통해 제공하는 추상화 수준을 다룰 것입니다.

*Spring Kafka는 @KafkaListener* 어노테이션 을 통해 *KafkaTemplate* 및 Message-driven POJO 가 있는 단순하고 일반적인 Spring 템플릿 프로그래밍 모델을 제공합니다 .

## 추가 읽기:

## [Flink 및 Kafka로 데이터 파이프라인 구축](https://www.baeldung.com/kafka-flink-data-pipeline)

Flink 및 Kafka로 스트림 데이터를 처리하는 방법 알아보기

[더 읽기](https://www.baeldung.com/kafka-flink-data-pipeline) →

## [MQTT 및 MongoDB를 사용한 Kafka Connect 예제](https://www.baeldung.com/kafka-connect-mqtt-mongodb)

Kafka 커넥터를 사용하는 실제 예를 살펴보십시오.

[더 읽기](https://www.baeldung.com/kafka-connect-mqtt-mongodb) →

## **2. 설치 및 설정**

[Kafka를 다운로드하고 설치하려면 여기](https://kafka.apache.org/quickstart) 에서 공식 가이드를 참조 하십시오 .

*또한 pom.xml 에* *spring-kafka* 종속성을 추가해야 합니다 .

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
    <version>2.7.2</version>
</dependency>
```

이 아티팩트의 최신 버전은 [여기](https://search.maven.org/classic/#search|ga|1|g%3A"org.springframework.kafka" AND a%3A"spring-kafka") 에서 찾을 수 있습니다 .

예제 애플리케이션은 Spring Boot 애플리케이션이 될 것입니다.

이 문서에서는 서버가 기본 구성을 사용하여 시작되고 서버 포트가 변경되지 않는다고 가정합니다.

## 3. 주제 구성

이전에는 명령줄 도구를 실행하여 Kafka에서 주제를 생성했습니다.

```bash
$ bin/kafka-topics.sh --create \
  --zookeeper localhost:2181 \
  --replication-factor 1 --partitions 1 \
  --topic mytopic
```

그러나 Kafka에 *AdminClient* 가 도입되면서 이제 프로그래밍 방식으로 주제를 만들 수 있습니다.

***NewTopic\* 유형의 모든 빈에 대한 주제를 자동으로 추가 하는 \*KafkaAdmin\* Spring 빈 을 추가해야 합니다** .

```java
@Configuration
public class KafkaTopicConfig {
    
    @Value(value = "${kafka.bootstrapAddress}")
    private String bootstrapAddress;

    @Bean
    public KafkaAdmin kafkaAdmin() {
        Map<String, Object> configs = new HashMap<>();
        configs.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
        return new KafkaAdmin(configs);
    }
    
    @Bean
    public NewTopic topic1() {
         return new NewTopic("baeldung", 1, (short) 1);
    }
}
```

## **4. 메시지 생성**

메시지를 생성하려면 먼저 [*ProducerFactory*](https://docs.spring.io/spring-kafka/api/org/springframework/kafka/core/ProducerFactory.html) 를 구성해야 합니다 . [*이것은 Kafka Producer*](https://kafka.apache.org/0100/javadoc/org/apache/kafka/clients/producer/Producer.html) 인스턴스 를 생성하기 위한 전략을 설정합니다 .

**그런 다음 \*Producer\* 인스턴스 를 래핑하고 Kafka 주제에 메시지를 보내기 위한 편리한 방법을 제공 하는 [\*KafkaTemplate 이 필요합니다.\*](https://docs.spring.io/spring-kafka/api/org/springframework/kafka/core/KafkaTemplate.html)**

*생산자* 인스턴스는 스레드로부터 안전합니다. 따라서 애플리케이션 컨텍스트 전체에서 단일 인스턴스를 사용하면 더 높은 성능을 얻을 수 있습니다. 따라서 *KakfaTemplate* 인스턴스도 스레드로부터 안전하며 하나의 인스턴스를 사용하는 것이 좋습니다.

### **4.1. 생산자 구성**

```java
@Configuration
public class KafkaProducerConfig {

    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(
          ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, 
          bootstrapAddress);
        configProps.put(
          ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, 
          StringSerializer.class);
        configProps.put(
          ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, 
          StringSerializer.class);
        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
```

### **4.2. 메시지 게시**

*KafkaTemplate* 클래스 를 사용하여 메시지를 보낼 수 있습니다 .

```java
@Autowired
private KafkaTemplate<String, String> kafkaTemplate;

public void sendMessage(String msg) {
    kafkaTemplate.send(topicName, msg);
}
```

***send\* API는 ListenableFuture \*객체\* 를 반환합니다.** 보내는 스레드를 차단하고 보낸 메시지에 대한 결과를 얻으려면 *ListenableFuture* 객체 의 *get* API를 호출할 수 있습니다. 스레드는 결과를 기다리지만 생산자 속도가 느려집니다.

Kafka는 빠른 스트림 처리 플랫폼입니다. 따라서 후속 메시지가 이전 메시지의 결과를 기다리지 않도록 결과를 비동기적으로 처리하는 것이 좋습니다.

콜백을 통해 이 작업을 수행할 수 있습니다.

```java
public void sendMessage(String message) {
            
    ListenableFuture<SendResult<String, String>> future = 
      kafkaTemplate.send(topicName, message);
	
    future.addCallback(new ListenableFutureCallback<SendResult<String, String>>() {

        @Override
        public void onSuccess(SendResult<String, String> result) {
            System.out.println("Sent message=[" + message + 
              "] with offset=[" + result.getRecordMetadata().offset() + "]");
        }
        @Override
        public void onFailure(Throwable ex) {
            System.out.println("Unable to send message=[" 
              + message + "] due to : " + ex.getMessage());
        }
    });
}
```

## **5. 메시지 소비**

### **5.1. 소비자 구성**

*[메시지를 사용하려면 ConsumerFactory](https://docs.spring.io/autorepo/docs/spring-kafka-dist/1.1.3.RELEASE/api/org/springframework/kafka/core/ConsumerFactory.html)* 및 [*KafkaListenerContainerFactory*](https://docs.spring.io/autorepo/docs/spring-kafka-dist/1.1.3.RELEASE/api/org/springframework/kafka/config/KafkaListenerContainerFactory.html) 를 구성해야 합니다 . [*이러한 Bean이 Spring Bean 팩토리에서 사용 가능하게 되면 @KafkaListener*](https://docs.spring.io/autorepo/docs/spring-kafka-dist/1.1.3.RELEASE/api/org/springframework/kafka/annotation/KafkaListener.html) 어노테이션 을 사용하여 POJO 기반 소비자를 구성할 수 있습니다 .

**[\*@EnableKafka\*](https://docs.spring.io/autorepo/docs/spring-kafka-dist/1.1.3.RELEASE/api/org/springframework/kafka/annotation/EnableKafka.html) 주석은 스프링 관리 Bean에서 \*@KafkaListener\* 주석 감지를 활성화하기 위해 구성 클래스에 필요합니다**.

```java
@EnableKafka
@Configuration
public class KafkaConsumerConfig {

    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        Map<String, Object> props = new HashMap<>();
        props.put(
          ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, 
          bootstrapAddress);
        props.put(
          ConsumerConfig.GROUP_ID_CONFIG, 
          groupId);
        props.put(
          ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, 
          StringDeserializer.class);
        props.put(
          ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, 
          StringDeserializer.class);
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> 
      kafkaListenerContainerFactory() {
   
        ConcurrentKafkaListenerContainerFactory<String, String> factory =
          new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        return factory;
    }
}
```

### **5.2. 메시지 소비**

```java
@KafkaListener(topics = "topicName", groupId = "foo")
public void listenGroupFoo(String message) {
    System.out.println("Received Message in group foo: " + message);
}
```

주제 에 대해 각각 다른 그룹 ID를 가진 **여러 리스너를 구현할 수 있습니다 .** 또한 한 소비자는 다양한 주제의 메시지를 들을 수 있습니다.

```java
@KafkaListener(topics = "topic1, topic2", groupId = "foo")
```

[*Spring은 또한 리스너에서 @Header*](https://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/messaging/handler/annotation/Header.html) 주석을 사용하여 하나 이상의 메시지 헤더 검색을 지원합니다 .

```java
@KafkaListener(topics = "topicName")
public void listenWithHeaders(
  @Payload String message, 
  @Header(KafkaHeaders.RECEIVED_PARTITION_ID) int partition) {
      System.out.println(
        "Received Message: " + message"
        + "from partition: " + partition);
}
```

### **5.3. 특정 파티션의 메시지 사용**

하나의 파티션으로 *baeldung* 토픽을 생성했음을 주목하십시오 .

그러나 여러 파티션이 있는 주제의 경우 *@KafkaListener* 는 초기 오프셋이 있는 주제의 특정 파티션을 명시적으로 구독할 수 있습니다.

```java
@KafkaListener(
  topicPartitions = @TopicPartition(topic = "topicName",
  partitionOffsets = {
    @PartitionOffset(partition = "0", initialOffset = "0"), 
    @PartitionOffset(partition = "3", initialOffset = "0")}),
  containerFactory = "partitionsKafkaListenerContainerFactory")
public void listenToPartition(
  @Payload String message, 
  @Header(KafkaHeaders.RECEIVED_PARTITION_ID) int partition) {
      System.out.println(
        "Received Message: " + message"
        + "from partition: " + partition);
}
```

이 리스너 에서 *initialOffset* 이 0으로 설정되었으므로 이 리스너가 초기화될 때마다 파티션 0과 3에서 이전에 사용된 모든 메시지가 다시 사용됩니다.

오프셋을 설정할 필요가 없다면 *@TopicPartition 주석의* *partitions* 속성을 사용 하여 오프셋 없이 파티션만 설정할 수 있습니다.

```java
@KafkaListener(topicPartitions 
  = @TopicPartition(topic = "topicName", partitions = { "0", "1" }))
```

### **5.4. 리스너에 대한 메시지 필터 추가**

사용자 지정 필터를 추가하여 특정 메시지 콘텐츠를 사용하도록 수신기를 구성할 수 있습니다. 이것은 *[RecordFilterStrategy](https://docs.spring.io/spring-kafka/api/org/springframework/kafka/listener/adapter/RecordFilterStrategy.html)* 를 *KafkaListenerContainerFactory* 로 설정하여 수행할 수 있습니다 .

```java
@Bean
public ConcurrentKafkaListenerContainerFactory<String, String>
  filterKafkaListenerContainerFactory() {

    ConcurrentKafkaListenerContainerFactory<String, String> factory =
      new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(consumerFactory());
    factory.setRecordFilterStrategy(
      record -> record.value().contains("World"));
    return factory;
}
```

그런 다음 이 컨테이너 팩토리를 사용하도록 리스너를 구성할 수 있습니다.

```java
@KafkaListener(
  topics = "topicName", 
  containerFactory = "filterKafkaListenerContainerFactory")
public void listenWithFilter(String message) {
    System.out.println("Received Message in filtered listener: " + message);
}
```

이 수신기 **에서 필터와 일치하는 모든 메시지는 삭제됩니다.**

## **6. 사용자 정의 메시지 변환기**

지금까지는 문자열을 메시지로 보내고 받는 것에 대해서만 다루었습니다. 그러나 사용자 정의 Java 객체를 보내고 받을 수도 있습니다. *이를 위해서는 ProducerFactory* 에서 적절한 직렬 변환기를 구성 하고 *ConsumerFactory* 에서 역 직렬 변환기를 구성해야 합니다 .

메시지로 보낼 간단한 빈 클래스 *를* 살펴보겠습니다 .

```java
public class Greeting {

    private String msg;
    private String name;

    // standard getters, setters and constructor
}
```

### **6.1. 맞춤형 메시지 생성**

이 예에서는 *[JsonSerializer](https://docs.spring.io/spring-kafka/api/org/springframework/kafka/support/serializer/JsonSerializer.html)* 를 사용합니다 .

*ProducerFactory* 및 *KafkaTemplate* 의 코드를 살펴보겠습니다 .

```java
@Bean
public ProducerFactory<String, Greeting> greetingProducerFactory() {
    // ...
    configProps.put(
      ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, 
      JsonSerializer.class);
    return new DefaultKafkaProducerFactory<>(configProps);
}

@Bean
public KafkaTemplate<String, Greeting> greetingKafkaTemplate() {
    return new KafkaTemplate<>(greetingProducerFactory());
}
```

이 새로운 *KafkaTemplate 을 사용하여* *인사말* 메시지 를 보낼 수 있습니다.

```java
kafkaTemplate.send(topicName, new Greeting("Hello", "World"));
```

### **6.2. 사용자 지정 메시지 사용**

마찬가지로, 인사말 메시지를 올바르게 역직렬화하도록 *ConsumerFactory* 및 *KafkaListenerContainerFactory 를 수정해 보겠습니다.*

```java
@Bean
public ConsumerFactory<String, Greeting> greetingConsumerFactory() {
    // ...
    return new DefaultKafkaConsumerFactory<>(
      props,
      new StringDeserializer(), 
      new JsonDeserializer<>(Greeting.class));
}

@Bean
public ConcurrentKafkaListenerContainerFactory<String, Greeting> 
  greetingKafkaListenerContainerFactory() {

    ConcurrentKafkaListenerContainerFactory<String, Greeting> factory =
      new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(greetingConsumerFactory());
    return factory;
}
```

spring-kafka JSON 직렬 변환기 및 역직렬 변환기는 spring-kafka 프로젝트에 대한 선택적 Maven 종속성이기도 한 [Jackson 라이브러리를 사용합니다.](https://www.baeldung.com/jackson)

*pom.xml* 에 추가해 보겠습니다 .

```java
<dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
    <version>2.9.7</version>
</dependency>
```

최신 버전의 Jackson을 사용하는 대신 spring-kafka 의 *pom.xml* 에 추가된 버전을 사용하는 것이 좋습니다 .

*마지막으로 인사말* 메시지 를 사용하는 리스너를 작성해야 합니다.

```java
@KafkaListener(
  topics = "topicName", 
  containerFactory = "greetingKafkaListenerContainerFactory")
public void greetingListener(Greeting greeting) {
    // process greeting message
}
```

## 7. 다중 메소드 리스너

이제 다양한 종류의 개체를 동일한 주제로 보낸 다음 소비하도록 애플리케이션을 구성하는 방법을 살펴보겠습니다.

먼저 새 클래스인 *Farewell* 을 추가합니다 .

```java
public class Farewell {

    private String message;
    private Integer remainingMinutes;

    // standard getters, setters and constructor
}
```

*Greeting* 및 *Farewell* 개체를 동일한 주제 로 보낼 수 있으려면 몇 가지 추가 구성이 필요합니다 .

### 7.1. 생산자에서 매핑 유형 설정

생산자에서 [JSON](https://www.baeldung.com/java-json) 유형 매핑을 구성해야 합니다.

```java
configProps.put(JsonSerializer.TYPE_MAPPINGS, "greeting:com.baeldung.spring.kafka.Greeting, farewell:com.baeldung.spring.kafka.Farewell");
```

이런 식으로 라이브러리는 해당 클래스 이름으로 유형 헤더를 채웁니다.

결과적으로 *ProducerFactory* 및 *KafkaTemplate* 은 다음과 같습니다.

```java
@Bean
public ProducerFactory<String, Object> multiTypeProducerFactory() {
    Map<String, Object> configProps = new HashMap<>();
    configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
    configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
    configProps.put(JsonSerializer.TYPE_MAPPINGS, 
      "greeting:com.baeldung.spring.kafka.Greeting, farewell:com.baeldung.spring.kafka.Farewell");
    return new DefaultKafkaProducerFactory<>(configProps);
}

@Bean
public KafkaTemplate<String, Object> multiTypeKafkaTemplate() {
    return new KafkaTemplate<>(multiTypeProducerFactory());
}
```

이 KafkaTemplate을 사용하여 *Greeting* , *Farewell* 또는 모든 [*객체*](https://www.baeldung.com/java-classes-objects) 를 주제로 보낼 수 있습니다.

```java
multiTypeKafkaTemplate.send(multiTypeTopicName, new Greeting("Greetings", "World!"));
multiTypeKafkaTemplate.send(multiTypeTopicName, new Farewell("Farewell", 25));
multiTypeKafkaTemplate.send(multiTypeTopicName, "Simple string message");
```

### 7.2. 소비자에서 사용자 지정 *MessageConverter 사용*

들어오는 메시지를 역직렬화하려면 *소비자* 에게 사용자 지정 *MessageConverter* 를 제공해야 합니다 .

무대 뒤에서 *MessageConverter 는* *Jackson2JavaTypeMapper* 에 의존합니다 . 기본적으로 매퍼는 수신된 객체의 유형을 유추합니다. 반대로, 역직렬화를 위한 대상 클래스를 결정하기 위해 유형 헤더를 사용하도록 명시적으로 알려야 합니다.

```java
typeMapper.setTypePrecedence(Jackson2JavaTypeMapper.TypePrecedence.TYPE_ID);
```

역방향 매핑 정보도 제공해야 합니다. 유형 헤더에서 *"greeting"* 을 찾으면 *Greeting* 개체를 식별하는 반면 *"farewell" 은* *Farewell* 개체 에 해당 합니다.

```java
Map<String, Class<?>> mappings = new HashMap<>(); 
mappings.put("greeting", Greeting.class);
mappings.put("farewell", Farewell.class);
typeMapper.setIdClassMapping(mappings);
```

마지막으로 매퍼가 신뢰하는 패키지를 구성해야 합니다. 대상 클래스의 위치가 포함되어 있는지 확인해야 합니다.

```java
typeMapper.addTrustedPackages("com.baeldung.spring.kafka");
```

결과적으로 이 MessageConverter의 최종 정의는 다음과 같습니다.

```java
@Bean
public RecordMessageConverter multiTypeConverter() {
    StringJsonMessageConverter converter = new StringJsonMessageConverter();
    DefaultJackson2JavaTypeMapper typeMapper = new DefaultJackson2JavaTypeMapper();
    typeMapper.setTypePrecedence(Jackson2JavaTypeMapper.TypePrecedence.TYPE_ID);
    typeMapper.addTrustedPackages("com.baeldung.spring.kafka");
    Map<String, Class<?>> mappings = new HashMap<>();
    mappings.put("greeting", Greeting.class);
    mappings.put("farewell", Farewell.class);
    typeMapper.setIdClassMapping(mappings);
    converter.setTypeMapper(typeMapper);
    return converter;
}
```

이제 *ConcurrentKafkaListenerContainerFactory 에게* *MessageConverter* 와 다소 기본적인 *ConsumerFactory* 를 사용하도록 지시 해야 합니다 .

```java
@Bean
public ConsumerFactory<String, Object> multiTypeConsumerFactory() {
    HashMap<String, Object> props = new HashMap<>();
    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
    return new DefaultKafkaConsumerFactory<>(props);
}

@Bean
public ConcurrentKafkaListenerContainerFactory<String, Object> multiTypeKafkaListenerContainerFactory() {
    ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(multiTypeConsumerFactory());
    factory.setMessageConverter(multiTypeConverter());
    return factory;
}
```

### 7.3. 리스너에서 *@KafkaHandler* 사용

마지막으로 *KafkaListener* 에서 가능한 모든 종류의 객체를 검색하는 핸들러 메서드를 생성합니다. 각 핸들러는 *@KafkaHandler* 로 주석을 달아야 합니다.

*마지막으로 Greeting* 또는 *Farewell* 클래스 중 하나에 바인딩할 수 없는 개체에 대한 기본 처리기를 정의할 수도 있다는 점을 지적해 보겠습니다 .

```java
@Component
@KafkaListener(id = "multiGroup", topics = "multitype")
public class MultiTypeKafkaListener {

    @KafkaHandler
    public void handleGreeting(Greeting greeting) {
        System.out.println("Greeting received: " + greeting);
    }

    @KafkaHandler
    public void handleF(Farewell farewell) {
        System.out.println("Farewell received: " + farewell);
    }

    @KafkaHandler(isDefault = true)
    public void unknown(Object object) {
        System.out.println("Unkown type received: " + object);
    }
}
```

## **8. 결론**

이 기사에서는 Apache Kafka에 대한 Spring 지원의 기본 사항을 다뤘습니다. 메시지를 보내고 받는 데 사용되는 클래스를 간략하게 살펴보았습니다.

## 3.10  Spring Cloud Sleuth

### **1. Sleuth와 Zipkin 이해**

**1) WHY ?**

마이크로서비스로 큰 서비스를 잘게 쪼개어 개발하게 되면 자연스럽게 마이크로서비스간에 연결이 많아지고 복잡하게 됩니다.

예를 들어 고객 '홍길동'이 2021-02-01 13:33:33에 피자 3개를 주문했다고 가정해 봅시다.

그 주문이 처리되기 위해서는 아래와 같이 여러가지 마이크로서비스들이 서로 호출하게 됩니다.

| 마이크로서비스 (consumer) | 마이크로서비스 (producer) | API                              |
| ------------------------- | ------------------------- | -------------------------------- |
| 주문접수                  | 주문등록                  | /order/register/{order id}       |
| 주문등록                  | 고객체크                  | /customer/validate/{customer id} |
| 주문접수                  | 결제                      | /pay/{order id}                  |
| 주문접수                  | 조리요청                  | /restaurant/{order id}           |
| 조리요청                  | 배달요청                  | /deliver/{order id}              |

주문 처리가 되지 않거나 매우 느려진다면 어느 지점이 문제인지 빠르게 찾을 수 있어야 합니다.

Sleuth는 분산된 마이크로서비스간에 트래픽의 흐름을 추적(Tracing)할 수 있도록

Trace기록을 로그에 자동 삽입해 줍니다.

다시말해,

Sleuth와 Zipkin이 필요한 이유는 **분산된 마이크로서비스간의 트래픽을 추적하여 문제를 사전에 방지하거나 해결하기 위해**서입니다.



**2) HOW ?**

어떻게 하면 연관된 트래픽의 흐름을 추적할 수 있을까요 ?

**동일한 트랙잰션에 해당하는 트래픽들에 동일한 TraceID를 부여**하면 됩니다.

위 주문 트랜잭션에서 모든 트래픽이 동일한 Trace ID를 갖고 있다면 쉽게 추적할 수 있을것입니다.

Sleuth를 적용한 후 Log4j, Logback, SLF4J(Simple Logging Facade for Java)등을 사용하여 로깅하면, 

자동으로 로그에 Service명, Trace ID, Span ID가 삽입됩니다.

아래는 Sleuth에 의해 로그에 자동으로 Trace정보가 주입된 예제입니다.

service명이 hystrix-consumer이고 Trace ID가 7d84c8618a10307f이며 Span ID는 e25a40b90acb4e5b입니다.

Span ID는 각 트래픽의 고유 ID입니다.

```
2021-02-02 11:58:58.969  INFO [hystrix-consumer,7d84c8618a10307f,e25a40b90acb4e5b,true] 1 --- [nio-8003-exec-7] com.springcloud.CafeController           : ### Received: /delay/pass

2021-02-02 11:58:58.990  INFO [hystrix-consumer,7d84c8618a10307f,e25a40b90acb4e5b,true] 1 --- [nio-8003-exec-7] com.springcloud.CafeController           : ### Sent: [Americano, Latte, Mocha]
```

위 주문 트랜잭션의 예를 든다면 아래와 같이 부여됩니다.

| 마이크로서비스 (consumer) | 마이크로서비스 (producer) | API                              | Trace ID | Span ID |
| ------------------------- | ------------------------- | -------------------------------- | -------- | ------- |
| 주문접수                  | 주문등록                  | /order/register/{order id}       | 1000     | 1000    |
| 주문등록                  | 고객체크                  | /customer/validate/{customer id} | 1000     | 1100    |
| 주문접수                  | 결제                      | /pay/{order id}                  | 1000     | 1200    |
| 주문접수                  | 조리요청                  | /restaurant/{order id}           | 1000     | 1300    |
| 조리요청                  | 배달요청                  | /deliver/{order id}              | 1000     | 1400    |

그림으로 표현하면 아래와 같습니다.

![img](.\assets\trace.png)



또한, 이러한 Tracing정보에는 4가지 종류의 timestamp가 있어 소요된 시간까지 측정할 수 있습니다.

CS(Client Start) -> SR(Server Received) => SS(Server Sent) => CR(Client Received)

 

이러한 Trace정보를 Zipkin과 같은 분산 트랜잭션 추적 시스템으로 송부하면 그래픽하게 트래픽의 흐름을 볼 수 있습니다.

Trace정보를 Zipkin에 송부하기 위해서는 Zipkin client를 적용해야 합니다.



![img](.\assets\img2.png)

 

### 2. Zipkin 설치

**1) Zipkin 이해**

Zipkin은 분산 트랜잭션 추적을 위한 오픈소스소프트웨어입니다. 트위터에서 제공하였습니다.

비슷한 제품으로는 Jaeger가 있습니다.

Zipkin 아키텍처는 아래와 같습니다.



![img](https://blog.kakaocdn.net/dn/o0y9z/btqXgoJFibK/qmSiVsKsNVvPtyr1daNZ21/img.png)



\- Zipkin client library: 각 어플리케이션에 설치되어 Zipkin collector로 Trace정보를 송부함

\- Collector: Trace정보 수집기

\- Storge: In-memory(테스트 목적), 소규모는 MySQL, 운영환경에는 ElasticSearch나 Cassandra를 사용

\- API(Query Service): Web UI의 요청을 받아 Storage를 검색하여 결과를 리턴

\- Web UI: 대시보드 UI 제공

 

### 3. Sleuth와 Zipkin 실습

**1) sleuth, zipkin dependency 추가**

zuul, webhook, consumer, HystrixConsumer, HystrixProducer 어플리케이션의 pom.xml에 추가 합니다.

```
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-starter-sleuth</artifactId>
		</dependency>
		<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-starter-zipkin</artifactId>
		</dependency>	
```

 

**2) sleuth, zipkin configuration**

configmng의 zuul-common.yaml, webhook-common.yaml, consumer-common.yaml, hystrix-consumer-common.yaml, hystrix-producer-common.yaml에 아래 설정을 추가합니다.

probability는 트래픽의 몇%를 zipkin으로 보낼것인지를 정의합니다. 0.5면 50%만 보내는것입니다.

```
spring:
  sleuth: 
    sampler:
      probability: 1.0
  zipkin:
    base-url: http://zipkin:9411
```

zipkin.base-url은 zipkin service의 서비스명과 포트입니다. 



# 4. Demo Application

## 4.1  개요

네이티브 아키텍처의 기술 스택을 이용한 Pilot Application을 구현하려고 한다. Pilot Application은 카탈로그 서비스, 사용자 서비스, 주문 서비스라는 3개의 마이크로서비스로 구성되어 있는 간단한 E-commerce 애플리케이션이다.

구현의 간단함을 위해 각 마이크로서비스는 RESTful API를 제공하는 비즈니스 로직만 구현하였다. 제공하는 비즈니스 로직은 다음과 같다.

◾  카탈로그 서비스: 상품의 목록을 확인, 상품의 재고수량 업데이트

◾  사용자 서비스: 사용자 등록, 상품의 정보를 확인 후 상품 주문

◾  주문 서비스: 상품의 주문과 주문된 상품 확인

다음은 Pilot Application의 서비스 흐름을 나타낸 그림이다.

 

![image-20220817110036458](.\assets\image-20220817110036458.png)

[그림 5-1] Pilot Application의 서비스 흐름





## 4.2  사전 준비 작업

### 4.2.1  기술 스택

이번 장에서 구현하는 Pilot Application은 도커 컨테이너 기반의 마이크로서비스로서 Kubernetes Orchestration 도구를 사용하여 3대의 Cluster로 구성된 네트워크에 배포할 예정이다. 애플리케이션을 구성하는 마이크로서비스와 메시징 서비스, 모니터링 서비스가 Kubernetes에서 관리될 예정이다. 각 구성요소는 IV장에서 소개한 기술 스택을 사용하여 구성하였으며, 애플리케이션을 구성하는 솔루션 및 서비스는 다음과 같다.

| 기술 스택            | 참고 |
| -------------------- | ---- |
| Spring Web MVC       |      |
| Spring Cloud Config  |      |
| Spring Cloud Gateway |      |
| Spring Cloud Eureka  |      |
| Spring Data JDBC     |      |
| Spring Data Redis    |      |
| Spring with Kafka    |      |
| Spring Cloud Stream  |      |
| Docker               |      |

 

## 4.2.2  마이크로서비스

마이크로서비스는 카탈로그 서비스, 사용자 서비스, 주문 서비스 3개로 구성되어 있으며, Java 언어를 이용한 Spring Boot(v2.3.4) + Spring Cloud(v2.2.2) API를 이용하여 개발되었다.



| 서비스 명       | URI                                                       | HTTP  Method | 설명           |
| --------------- | --------------------------------------------------------- | ------------ | -------------- |
| User service    | http://localhost:50001/user-ms/users                      | POST         | 사용자 추가    |
|                 | http://localhost:50001/user-ms/users/**{userId}**         | GET          | 사용자 확인    |
| Catalog Service | http://localhost:50003/catalog-ms/catalogs                | GET          | 카테고리 목록  |
| Order service   | http://localhost:50002/order-ms/users/**{userId}**/orders | GET          | 상품 주문 확인 |
|                 | http://localhost:50002/order-ms/users/**{userId}**/orders | POST         | 상품 주문      |

 

 

## 4.3  시스템 구성도

 

![](.\assets\demo-archi.png)

 

##  4.4 미들웨어 구동

### 4.4.1 Zookeeper 실행

```shell
cd D:\cloudnative\infra\kafka_2.13-3.2.1\bin\windows
.\zookeeper-server-start.bat ..\..\config\zookeeper.properties
```

### 4.4.2 Kafka 실행

```shell
cd D:\cloudnative\infra\kafka_2.13-3.2.1\bin\windows
.\kafka-server-start.bat ..\..\config\server.properties
#.\kafka-topics.bat --create --bootstrap-server localhost:9092 --topic example-kafka-test
```

### 4.4.3 Redis 실행

```shell
cd D:\cloudnative\infra\Redis-x64-3.2.100
.\redis-server.exe .\redis.windows.conf
```

### 4.4.4 Zipkin 실행

```shell
cd D:\cloudnative\infra\zipkin
java -jar zipkin.jar
```





## 4.5  상품 주문 프로세스

### 4.5.1 사용자 등록

◾  http://172.20.10.12:30304/users-ms/users

먼저, 사용자 정보를 등록하도록 하자. 사용자 서비스에 다음과 같은 정보를 HTTP Post Method로 전달하도록 하자. Kubernetes의 서비스를 NodePort로 설정하였고 각 Node에 설치된 컨테이너의 포트는 다를 수 있기 때문에 직접 확인 후에 접속하도록 하자.

```json
{
“name”: “tta-cloud”, “email”: “tta-cloud@tta.or.kr”, “pwd”: “test1234”
}
```

 ![image-20220823095439646](.\assets\image-20220823095439646.png)



### 4.5.2 사용자 조회

◾  http://172.20.10.12:30304/users-ms/users/a3af7fbc-b06c-4edb-95e9-b0efa0abc94b/

사용자 정보가 성공적으로 등록 되었다면, Response Body에서 “userId”를 확인할 수 있다. 반환된 “userId” 값을 이용하여 등록된 사용자의 정보를 확인해 보도록 하자. 

아직 사용자가 주문한 상품이 없기 때문에, “orders” 항목은 비어 있는 것을 확인할 수 있다.

![image-20220823095520646](.\assets\image-20220823095520646.png)



### 4.5.3 상품 목록 조회

◾  http://172.20.10.13:31670/catalogs-ms/catalogs

다음으로 카탈로그 서비스로부터 등록된 상품의 목록을 가져오도록 하자.

![image-20220823095529925](.\assets\image-20220823095529925.png)

 

### 4.5.4 상품 주문

◾  http://172.20.10.12:30304/orders-ms/users/a3af7fbc-b06c-4edb-95e9- b0efa0abc94b/orders

상품 조회를 통해 “productId(상품 코드)”, “unitPrice(상품 단가)”와 “qty(수량)”을 확인 한 다음, 주문하고자 하는 상품의 정보를 전달하여 상품 주문 요청을 하도록 하자.

```
{
“productId”: “CATALOG-0001”,
“qty”: 10,
“unitPrice”: 1500
}
```

 ![image-20220823095605044](.\assets\image-20220823095605044.png)

주문한 상품의 내용을 주문 서비스가 사용하고 있는 데이터베이스에서 확인해 보면 다음과 같다.

 ![image-20220823095613029](.\assets\image-20220823095613029.png)

[그림 5-16] 주문 서비스의 H2 데이터베이스 조회 화면



### 4.5.5 상품 주문 조회

◾  http://172.20.10.12:30304/orders-ms/users/a3af7fbc-b06c-4edb-95e9- b0efa0abc94b/orders

조금 전에 주문했던 내용은 상품 주문 조회 서비스를 통해 확인할 수 있다. 각 사용자 별로 주문한 내용을 확인해 볼 수 있다.

 ![image-20220823095640224](.\assets\image-20220823095640224.png)

 

 

## 4.6  MicroService간 통신

3.1절에서 테스트한 Pilot Application은 상품 주문이 요청되었을 때, 주문 서비스로 사용자가 요청한 주문 정보를 전달하게 된다. 그리고 사용자 서비스에서 사용자의 정보 확인 시, 해당 사용자가 주문한 상품의 목록을 확인할 수 있는데 여기에서 사용자 마이크로서비스로부터 주문 마이크로서비스로 주문 상품 목록을 요청하게 된다. 이 작업을 위해, Pilot Application에서는 Spring Cloud의 FeignClient를 이용하여 사용자 서비스에서 주문 서비스로 정보를 요청하고 있다. 

 <img src=".\assets\image-20220823095858586.png" alt="image-20220823095858586" style="zoom:150%;" />



## 4.7  Messaging Service를 통한 데이터 동기화

사용자가 상품을 주문할 때 입력했던 주문 수량의 정보는 Kafka Messaging Service를 통해 카탈로그 서비스에 전달된다. 주문 서비스에서 직접 카탈로그 서비스로 정보를 전달하는 것이 아니라, Kafka Messaging Service를 통해 메시지가 전달되며, 이 때 메시지를 전달하는 측을 Publisher, 메시지를 받는 측을 Consumer라고 한다.

Publisher는 어떤 Consumer가 메시지를 받는지 상관하지 않고 Kafka Messaging Service에게만 메시지를 전달하면되고, Consumer도 어떤 Publisher가 보냈는지 상관하지 않고 Kafka Messaging Service로부터 메시지를 받게 된다.

![image-20220823095917308](.\assets\image-20220823095917308.png)

![image-20220823095934001](.\assets\image-20220823095934001.png)

 Consumer에서는 Kafka Messaging Service에 메시지가 전달되면 이벤트에 의해 메시지를 전달 받게 된다. 카탈로그 서비스에서 KafkaListener라는 어노테이션을 등록하여 Kafka Messaging Service로부터 메시지를 받겠다고 선언하면, Kafka의 토픽에 전달된 메시지가 있을 경우 바로 전달 받을 수 있게 된다.

 ![image-20220823095943587](.\assets\image-20220823095943587.png)

![image-20220823095952822](.\assets\image-20220823095952822.png)

카탈로그 서비스에서는 Kafka Messaging Service로부터 전달 받은 주문 상품의 수량만큼 해당 상품의 수량을 업데이트 하게 된다.

다시 한 번 카탈로그 서비스의 상품 목록을 확인해 보면 다음과 같이 수량이 변경된 것을 확인할 수 있다.

 ![image-20220823100009787](.\assets\image-20220823100009787.png)



## 4.8 Cache Service를 통한 데이터 조회

카탈로그 서비스는 사용자가 상품을 주문할때 수량이 업데이트 된다. 카탈로그 서비스는  E-commerce 애플리케이션에서 가장 많이 호출되는 서비스이다.

모노리틱 환경에서 카탈로그 서비스에 대량으로 조회 시 애플리케이션 전체에 영향을 끼치는 SPOF(*single point* of *failure*)가 된다.

MSA 환경에는 카탈로그 서비스에 대량으로 조회가 발생하더라고 해당 서비스에 대한 장애 발생되고 애플리케이션 전체로 전파되는것이 차단된다.

이 부분이 MSA가 가지는 주요 장점 중에 하나이다.

또한 카탈로그 서비스에 부하발생 시 Cahce 등을 활용하여 해당 서비스의 성능을 향상시킬 수 있다.

* 컨테이너환경에서는 Replica 를 활용하여 성능향상을 할 수 도 있다.



## 4.9 테스트



| 서비스 명       | URI                                                          | 설명                   |
| --------------- | ------------------------------------------------------------ | ---------------------- |
| User service    | http://localhost:50001/swagger-ui/index.html                 | API 테스트             |
|                 | http://localhost:50001/h2-console/                           | H2 DB 콘솔             |
|                 | curl -X 'POST' 'http://localhost:50001/actuator/refresh' -H 'accept: */*' | 프로퍼티 갱신          |
| Catalog Service | http://localhost:50003/swagger-ui/index.html                 | API 테스트             |
|                 | http://localhost:50003/h2-console/                           | H2 DB 콘솔             |
|                 | curl -X 'POST' 'http://localhost:50003/actuator/refresh' -H 'accept: */*' | 프로퍼티 갱신          |
| Order service   | http://localhost:50002/swagger-ui/index.html                 | API 테스트             |
|                 | http://localhost:50002/h2-console/                           | H2 DB 콘솔             |
|                 | curl -X 'POST' 'http://localhost:50002/actuator/refresh' -H 'accept: */*' | 프로퍼티 갱신          |
| API Gateway     | curl -X 'GET' 'http://localhost/user-ms/users' -H 'accept: */*'<br/>curl -X 'GET' 'http://localhost/catalog-ms/catalogs' -H 'accept: */*'<br />curl -X 'GET' 'http://localhost/order-ms/orders' -H 'accept: */*' | API 테스트             |
| Eureka          | http://localhost:8761/                                       | 서비스 디스커버리 확인 |
| Zipkin          | http://localhost:9411/                                       | 서비스 추적            |
| Config          | http://localhost:8888/order-ws/local<br />http://localhost:8888/catalog-ws/local<br />http://localhost:8888/user-ws/local | 프로퍼티 조회          |
| Redis           | cd D:\cloudnative\infra\Redis-x64-3.2.100<br/>.\redis-server.exe .\redis.windows.conf<br />.\redis-cli.exe<br />keys *<br />del key "catalogs::SimpleKey []" | Redis 키 조회/삭제     |

 

## 4.10 리펙토링

### 3.10.1 Hexagonal 아키텍처(Port and Adapter 패턴)에 맞게 서비스를 리펙토링 해 보세요.



### 4.10.2 성능을 고려하여 서비스를 개선해 보세요.



### 4.10.3 JUNIT을 활용한 테스트코드를 작성해 보세요.

# SpringBoot Service와 Repository의 단위 테스트 방법

지난 포스팅에서 API(Controller)만 따로 단위 테스트하는 방법을 정리했다.
[SpringBoot API 단위테스트](https://jiminidaddy.github.io/dev/2021/05/18/dev-spring-단위테스트-API/)

이번엔 Repository와 Service에 대한 단위 테스트를 진행해보려고 한다.

API의 단위 테스트를 위해 Controller와 Service의 결합을 제거하여 테스트를 진행했다면
Service와 Repository는 어떻게 다른 영역과의 결합을 제거할 수 있을까?

------

## Repository Test

Repository는 엔티티를 영속화하기위해 사용된다.
엔티티의 영속화 요구는 서비스에서 발생한다.
표현 계층은 Client와 맞닿은 영역이므로 Client의 요청/응답을 처리하며, 필요한 기능을 서비스 계층으로 위임하게 된다.
서비스 계층은 요구사항을 처리하는 영역으로, 도메인을 통해 비즈니스 로직을 수행한다.
(주문을 하거나, 주문 취소를 하거나, 결제를 하거나, 회원 가입을 한다던가, 상품 등록을 한다던가 등등…)
비즈니스 로직을 수행하고 난 도메인을 영속화해야하는데 이 기능을 저장소 영역으로 위임한다.
**따라서 Repository의 기능만 테스트를 하려면 Service와의 결합을 끊어야 한다.**

SpringBoot 테스트는 **@DataJpaTest** Annottation을 제공하는데, 이것을 통해 Repository의 단위 테스트가 가능하다.
@DataJpaTest을 사용할경우 아래와 같은 기능이 수행된다.

- JPA 관련된 설정만 로드한다. (WebMVC와 관련된 Bean이나 기능은 로드되지 않는다)
- JPA를 사용해서 생성/조회/수정/삭제 기능의 테스트가 가능하다.
- @Transactional을 기본적으로 내장하고 있으므로, 매 테스트 코드가 종료되면 자동으로 DB가 롤백된다.
- 기본적으로 내장 DB를 사용하는데, 설정을 통해 실제 DB로 테스트도 가능하다. (권장하지 않는다)
- @Entity가 선언된 클래스를 스캔하여 저장소를 구성한다.

------

회원 가입과 회원 조회에 대한 테스트를 진행했다.
테스트할 MemberRepository는 Bean으로 등록되므로 @Autowiried를 통해 의존성을 주입받았다.
Repository 외에 다른 Bean은 필요없으므로 별다른 설정할 게 없다.

```
@DataJpaTest
public class MemberTest {
    @Autowired
    private MemberRepository memberRepository;

    @Test
    @DisplayName("멤버가 DB에 저장이 잘 되는지 확인")
    void saveMember() {
        // given
        Member member = new MemberJoinRequestDto("chpark", 34).toEntity();
        // when
        Member savedMember = memberRepository.save(member);
        // then
        Assertions.assertThat(member).isSameAs(savedMember);
        Assertions.assertThat(member.getName()).isEqualTo(savedMember.getName());
        Assertions.assertThat(savedMember.getId()).isNotNull();
        Assertions.assertThat(memberRepository.count()).isEqualTo(1);
    }

    @Test
    @DisplayName("저장된 멤버가 제대로 조회되는지 확인")
    void findMember() {
        // given
        Member savedMember = memberRepository.save(new MemberJoinRequestDto("chpark", 34).toEntity());
        Member savedMember2 = memberRepository.save(new MemberJoinRequestDto("tester", 20).toEntity());
        // when
        Member findMember = memberRepository.findById(savedMember.getId())
                .orElseThrow(() -> new IllegalArgumentException("Wrong MemberId:<" + savedMember.getId() + ">"));
        Member findMember2 = memberRepository.findById(savedMember2.getId())
                .orElseThrow(() -> new IllegalArgumentException("Wrong MemberId:<" + savedMember2.getId() + ">"));
        // then
        Assertions.assertThat(memberRepository.count()).isEqualTo(2);
        Assertions.assertThat(findMember.getName()).isEqualTo("chpark");
        Assertions.assertThat(findMember.getAge()).isEqualTo(34);
        Assertions.assertThat(findMember2.getName()).isEqualTo("tester");
        Assertions.assertThat(findMember2.getAge()).isEqualTo(20);
    }
```

------

## Service Test

API, Repository, Service Test 중 개인적으로 Service Test가 제일 어려웠었다.
물론 내가 테스트코드에 그만큼 숙련되지 않은게 가장 큰 문제였고, JUnit에서 제공되는 기능들도 제대로 다 파악하지 못했기 때문이다.
기본적인 것들은 테스트코드를 작성해보면서 사용했는데, JUnit5기준으로 제공하는 기능들을 한번 싹 정리해봐야겠다.
~~(매번 필요할때마다 구글링하는것도 힘드니 그냥 내 블로그에 직접 작성해봐야겠다!)~~

Service는 위로는 Controller, 아래로는 Domain에 의존하고 있다.
따라서 결합을 두 군데나 끊어야 한다. (이것때문에 어려웠던 것 같다.)

먼저 Controller와의 연결을 끊어야한다.

Controller는 Web모듈이므로 Service Test를 진행하려면 Web에 대한 의존성을 받으면 안된다. 따라서 @WebMvcTest, @SpringBootTest와 같은 테스트를 사용하면 Service만을 테스트하기가 어려워진다.

두 번째로 Repository와의 연결을 끊어야 한다.

Domain을 통해 비즈니스 로직은 수행해야하지만, 실제로 DB에 저장할 건 아니기 때문에 이 부분을 제거할 방법이 필요하다.
SpringBoot 테스트는 특정 객체를 가짜로 대체할 Mocking을 제공하고 있고, 아래와 같은 Annotation을 제공한다.
@Mock, @MockBean, @Spy, @SpyBean

@Mock으로 선언한 객체는 의존하고 있는 실제 객체 대신에 @Mock으로 선언한 객체로 바꿔치기된다.
**따라서 Service 내에 의존하고 있는 Repository를 @Mock으로 선언하면 Repository Bean에 의존하지 않고 테스트가 가능해진다.**
그리고 Service 클래스를 @InjectMocks로 선언함으로써, @Mock으로 선언된 가짜 객체들을 의존한 Service 객체가 생성된다.

회원가입과 회원조회 기능에 대해 Service 테스트 코드를 아래와 같이 작성해보았다.

```
@ExtendWith(MockitoExtension.class)
public class MemberServiceTest {
    @Mock
    private MemberRepository memberRepository;

    @InjectMocks
    private MemberService memberService;

    @Test
    @DisplayName("join기능이 제대로 동작하는지 확인")
    void join() {
        // given
        MemberJoinRequestDto requestDto = new MemberJoinRequestDto("chpark", 34);
        when(memberRepository.save(any())).thenReturn(requestDto.toEntity());
        MemberJoinRequestDto requestDto2 = new MemberJoinRequestDto("tester", 20);
        when(memberRepository.save(any())).thenReturn(requestDto2.toEntity());

        // when
        memberService.join(requestDto);
        memberService.join(requestDto);

        // then
        // Id 생성 전략을 Identity를 사용하므로, 실제 DBd에 저장되야만 Id가 생성된다. 따라서 테스트에서 Id를 검증할 수 없다.
        // 만약 Id를 검증하려면 Repository를 Mock이 아니라 실제 Bean으로 사용해야 가능할 듯 싶다.
    }

    @Test
    @DisplayName("find기능이 제대로 동작하는지 확인")
    void find() {
        // given
        MemberJoinRequestDto requestDto = new MemberJoinRequestDto("chpark", 34);
        when(memberRepository.save(any())).thenReturn(requestDto.toEntity());
        memberService.join(requestDto);
        when(memberRepository.findById(1L)).thenReturn(Optional.of(requestDto.toEntity()));

        // when
        MemberFindResponseDto responseDto = memberService.find(1L);

        // then
        Assertions.assertThat(responseDto).isNotNull();
        Assertions.assertThat(responseDto.getName()).isEqualTo("chpark");
        Assertions.assertThat(responseDto.getAge()).isEqualTo(34);
    }
```

Service Test는 비즈니스 로직 처리가 제대로 되는지만 검증하면 되므로 Spring과 연관될 이유가 없다.
따라서 SpringContaianer가 로드되지 않도록 SpringExtension.class를 사용하지 않고,
@ExtendWith(MockitoExtension.class) 을 추가하여 단위 테스트를 작성했다.
두 Annotation 사용에 차이는 아래에 간단히 기술했다.

### @ExtendWith(SpringExtension.class)

SpringContainer를 로드하므로 Test 객체에 @Autowired를 통해 Bean 의존성을 주입시킬 수 있다.
또한 Bean을 Mocking하기위한 @MockBean 기능을 사용할 수 있다.
테스트를 위해 Spring이 필요하다면 위 코드가 필요하다.

### @ExtendWith(MockitoExtension.class)

SpringContainer를 로드하지않고 테스트를 위한 기능만 제공한다.
@Mock, @Spy 기능을 사용할 수 있다.
테스트에 Spring이 필요없이 순수한 단위 테스트만 필요하다면 위 코드를 추가하면 된다.

Controller, Service, Repository 및 HelloWorld에 대한 테스트 코드 전체를 실행했는데 모두 통과했다.
![Alt](D:\GitHub\cloudnative\doc\assets\dev-spring-unittest-success.png)

### 3.8.4 컨테이너 환경에서 서비스를 실행해 보세요.

Docker Network는 Docker 컨테이너 끼리의 네트워크를 만들고, 그 네트워크 안에 속한 컨테이너끼리는 Private 통신을 할 수 있도록 자동으로 연결해줍니다. 아래의 명령어를 이용해서 Network를 생성해보도록 하겠습니다.

```
docker network create <네트워크 이름>
```



![img](https://blog.kakaocdn.net/dn/bs8bCU/btqBD13W2Ba/8rubJoaO8VnSs5O4ULgkG0/img.png)



create 이후 **docker network ls** 명령어를 통해 fluff라는 이름의 network가 생성된 것을 알 수 있습니다.

 

이제 fluff 네트워크 안에 docker image를 이용해서 private망으로 배포를 해보도록 하겠다. 명령어는 이전 포스팅에서 나왔던 포스팅과 크게 다르지 않습니다.

 

※ 해당 실습은 Redis Image와 Node.js Image가 만들어져 있는 상태에서 시작됩니다. 만약 Image가 없다면 이전 포스팅을 참고해 주세요.

```
docker run -d --name <컨테이너 이름> -p <Port 번호> --network <네트워크 이름> <이미지 이름>
```



![img](https://blog.kakaocdn.net/dn/bQVBX8/btqBDa1mP1c/DIyam1COfMbACnaIvodJE1/img.png)



위의 예시에선 redis와 fluff_server 두개의 컨테이너를 배포하였습니다.

(예시에선 -p로 포트번호를 열어주었지만, 만약 Network내에서만 통신을 할 경우 --name으로 선언한 컨테이너 이름으로 ip나 포트번호를 대신해서 사용할 수 있습니다.)

 

정리하자면 redis는 가상 네트워크 안에서 접근이 가능하고, public에서는 접근이 불가능하다. 반면에 fluff_server는 3000번 포트를 바인딩 하였기 때문에 3000번 포트로 접근이 가능하게 됩니다.